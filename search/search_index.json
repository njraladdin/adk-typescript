{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Agent Development Kit (ADK) for TypeScript <p> An open-source AI agent framework integrated with Gemini and Google, built for TypeScript/Node.js </p> <p>   \u26a0\ufe0f This is a Work-in-Progress TypeScript port of the original Python ADK. Features and stability may vary. </p>"},{"location":"#what-is-adk-typescript","title":"What is ADK TypeScript?","text":"<p>Agent Development Kit (ADK) for TypeScript is a flexible and modular framework for developing and deploying AI agents using TypeScript. ADK can be used with popular LLMs like Google's Gemini and is designed with a focus on tight integration with the Google ecosystem. ADK TypeScript makes it easy to get started with simple agents powered by Gemini models and Google tools, while providing the control and structure needed for more complex agent architectures and orchestration within the Node.js environment.</p> <p>     Get started:      <code>npm install -g adk-typescript</code> (This installs the CLI tool for creating and running agents) </p> <p> Quickstart Tutorial Sample Agents (Python) Contribute \u2764\ufe0f </p>"},{"location":"#learn-more","title":"Learn more","text":"<ul> <li> <p> Flexible Orchestration</p> <p>Define workflows using workflow agents (<code>SequentialAgent</code>, <code>ParallelAgent</code>, <code>LoopAgent</code>) for predictable pipelines, or leverage LLM-driven dynamic routing (<code>LlmAgent</code> with <code>AutoFlow</code>) for adaptive behavior.</p> <p> Learn about agents</p> </li> <li> <p> Multi-Agent Architecture</p> <p>Build modular and scalable applications by composing multiple specialized agents (<code>LlmAgent</code>, <code>BaseAgent</code>) in a hierarchy using <code>subAgents</code>. Enable complex coordination and delegation.</p> <p> Explore multi-agent systems</p> </li> <li> <p> Rich Tool Ecosystem</p> <p>Equip agents with diverse capabilities: use pre-built tools (<code>googleSearch</code>, <code>codeExecutionTool</code>), create custom functions (<code>FunctionTool</code>), integrate 3rd-party libraries (LangChain via <code>LangchainTool</code>, CrewAI via <code>CrewaiTool</code>), or use other agents as tools (<code>AgentTool</code>).</p> <p> Browse tools</p> </li> <li> <p> Deployment Ready</p> <p>Containerize and deploy your TypeScript agents anywhere \u2013 run locally, scale with Vertex AI Agent Engine (check compatibility), or integrate into custom infrastructure using Cloud Run or Docker.</p> <p> Deploy agents</p> </li> <li> <p> Built-in Evaluation</p> <p>Systematically assess agent performance using the <code>evaluation</code> module (<code>AgentEvaluator</code>) by evaluating both final responses and execution trajectories against test datasets (<code>.test.json</code>).</p> <p> Evaluate agents</p> </li> </ul> <p>Preview</p> <p>This feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section of the Service Specific Terms. Pre-GA features are available \"as is\" and might have limited support. For more information, see the launch stage descriptions.</p>"},{"location":"agents/","title":"Agents","text":"<p>In the Agent Development Kit (ADK), an Agent is a self-contained execution unit designed to act autonomously to achieve specific goals. Agents can perform tasks, interact with users, utilize external tools, and coordinate with other agents.</p> <p>The foundation for all agents in ADK is the <code>BaseAgent</code> class. It serves as the fundamental blueprint. To create functional agents, you typically extend <code>BaseAgent</code> in one of three main ways, catering to different needs \u2013 from intelligent reasoning to structured process control.</p> <p></p>"},{"location":"agents/#core-agent-categories","title":"Core Agent Categories","text":"<p>ADK provides distinct agent categories to build sophisticated applications:</p> <ol> <li> <p>LLM Agents (<code>LlmAgent</code>, <code>Agent</code>): These agents utilize Large Language Models (LLMs) as their core engine to understand natural language, reason, plan, generate responses, and dynamically decide how to proceed or which tools to use, making them ideal for flexible, language-centric tasks. Learn more about LLM Agents...</p> </li> <li> <p>Workflow Agents (<code>SequentialAgent</code>, <code>ParallelAgent</code>, <code>LoopAgent</code>): These specialized agents control the execution flow of other agents in predefined, deterministic patterns (sequence, parallel, or loop) without using an LLM for the flow control itself, perfect for structured processes needing predictable execution. Explore Workflow Agents...</p> </li> <li> <p>Custom Agents: Created by extending <code>BaseAgent</code> directly, these agents allow you to implement unique operational logic, specific control flows, or specialized integrations not covered by the standard types, catering to highly tailored application requirements. Discover how to build Custom Agents...</p> </li> </ol>"},{"location":"agents/#choosing-the-right-agent-type","title":"Choosing the Right Agent Type","text":"<p>The following table provides a high-level comparison to help distinguish between the agent types. As you explore each type in more detail in the subsequent sections, these distinctions will become clearer.</p> Feature LLM Agent (<code>LlmAgent</code>) Workflow Agent Custom Agent (<code>BaseAgent</code> subclass) Primary Function Reasoning, Generation, Tool Use Controlling Agent Execution Flow Implementing Unique Logic/Integrations Core Engine Large Language Model (LLM) Predefined Logic (Sequence, Parallel, Loop) Custom Python Code Determinism Non-deterministic (Flexible) Deterministic (Predictable) Can be either, based on implementation Primary Use Language tasks, Dynamic decisions Structured processes, Orchestration Tailored requirements, Specific workflows"},{"location":"agents/#agents-working-together-multi-agent-systems","title":"Agents Working Together: Multi-Agent Systems","text":"<p>While each agent type serves a distinct purpose, the true power often comes from combining them. Complex applications frequently employ multi-agent architectures where:</p> <ul> <li>LLM Agents handle intelligent, language-based task execution.</li> <li>Workflow Agents manage the overall process flow using standard patterns.</li> <li>Custom Agents provide specialized capabilities or rules needed for unique integrations.</li> </ul> <p>Understanding these core types is the first step toward building sophisticated, capable AI applications with ADK.</p>"},{"location":"agents/#whats-next","title":"What's Next?","text":"<p>Now that you have an overview of the different agent types available in ADK, dive deeper into how they work and how to use them effectively:</p> <ul> <li>LLM Agents: Explore how to configure agents powered by large language models, including setting instructions, providing tools, and enabling advanced features like planning and code execution.</li> <li>Workflow Agents: Learn how to orchestrate tasks using <code>SequentialAgent</code>, <code>ParallelAgent</code>, and <code>LoopAgent</code> for structured and predictable processes.</li> <li>Custom Agents: Discover the principles of extending <code>BaseAgent</code> to build agents with unique logic and integrations tailored to your specific needs.</li> <li>Multi-Agents: Understand how to combine different agent types to create sophisticated, collaborative systems capable of tackling complex problems.</li> <li>Models: Learn about the different LLM integrations available and how to select the right model for your agents.</li> </ul>"},{"location":"agents/custom-agents/","title":"Custom agents","text":"<p>Advanced Concept</p> <p>Building custom agents by directly implementing <code>_run_async_impl</code> provides powerful control but is more complex than using the predefined <code>LlmAgent</code> or standard <code>WorkflowAgent</code> types. We recommend understanding those foundational agent types first before tackling custom orchestration logic.</p>"},{"location":"agents/custom-agents/#custom-agents","title":"Custom agents","text":"<p>Custom agents provide the ultimate flexibility in ADK, allowing you to define arbitrary orchestration logic by inheriting directly from <code>BaseAgent</code> and implementing your own control flow. This goes beyond the predefined patterns of <code>SequentialAgent</code>, <code>LoopAgent</code>, and <code>ParallelAgent</code>, enabling you to build highly specific and complex agentic workflows.</p>"},{"location":"agents/custom-agents/#introduction-beyond-predefined-workflows","title":"Introduction: Beyond Predefined Workflows","text":""},{"location":"agents/custom-agents/#what-is-a-custom-agent","title":"What is a Custom Agent?","text":"<p>A Custom Agent is essentially any class you create that inherits from <code>google.adk.agents.BaseAgent</code> and implements its core execution logic within the <code>_run_async_impl</code> asynchronous method. You have complete control over how this method calls other agents (sub-agents), manages state, and handles events.</p>"},{"location":"agents/custom-agents/#why-use-them","title":"Why Use Them?","text":"<p>While the standard Workflow Agents (<code>SequentialAgent</code>, <code>LoopAgent</code>, <code>ParallelAgent</code>) cover common orchestration patterns, you'll need a Custom agent when your requirements include:</p> <ul> <li>Conditional Logic: Executing different sub-agents or taking different paths based on runtime conditions or the results of previous steps.</li> <li>Complex State Management: Implementing intricate logic for maintaining and updating state throughout the workflow beyond simple sequential passing.</li> <li>External Integrations: Incorporating calls to external APIs, databases, or custom Python libraries directly within the orchestration flow control.</li> <li>Dynamic Agent Selection: Choosing which sub-agent(s) to run next based on dynamic evaluation of the situation or input.</li> <li>Unique Workflow Patterns: Implementing orchestration logic that doesn't fit the standard sequential, parallel, or loop structures.</li> </ul> <p></p>"},{"location":"agents/custom-agents/#implementing-custom-logic","title":"Implementing Custom Logic:","text":"<p>The heart of any custom agent is the <code>_run_async_impl</code> method. This is where you define its unique behavior.</p> <ul> <li>Signature: <code>async def _run_async_impl(self, ctx: InvocationContext) -&gt; AsyncGenerator[Event, None]:</code></li> <li>Asynchronous Generator: It must be an <code>async def</code> function and return an <code>AsyncGenerator</code>. This allows it to <code>yield</code> events produced by sub-agents or its own logic back to the runner.</li> <li><code>ctx</code> (InvocationContext): Provides access to crucial runtime information, most importantly <code>ctx.session.state</code>, which is the primary way to share data between steps orchestrated by your custom agent.</li> </ul> <p>Key Capabilities within <code>_run_async_impl</code>:</p> <ol> <li> <p>Calling Sub-Agents: You invoke sub-agents (which are typically stored as instance attributes like <code>self.my_llm_agent</code>) using their <code>run_async</code> method and yield their events:</p> <pre><code>async for event in self.some_sub_agent.run_async(ctx):\n    # Optionally inspect or log the event\n    yield event # Pass the event up\n</code></pre> </li> <li> <p>Managing State: Read from and write to the session state dictionary (<code>ctx.session.state</code>) to pass data between sub-agent calls or make decisions:     <pre><code># Read data set by a previous agent\nprevious_result = ctx.session.state.get(\"some_key\")\n\n# Make a decision based on state\nif previous_result == \"some_value\":\n    # ... call a specific sub-agent ...\nelse:\n    # ... call another sub-agent ...\n\n# Store a result for a later step (often done via a sub-agent's output_key)\n# ctx.session.state[\"my_custom_result\"] = \"calculated_value\"\n</code></pre></p> </li> <li> <p>Implementing Control Flow: Use standard Python constructs (<code>if</code>/<code>elif</code>/<code>else</code>, <code>for</code>/<code>while</code> loops, <code>try</code>/<code>except</code>) to create sophisticated, conditional, or iterative workflows involving your sub-agents.</p> </li> </ol>"},{"location":"agents/custom-agents/#managing-sub-agents-and-state","title":"Managing Sub-Agents and State","text":"<p>Typically, a custom agent orchestrates other agents (like <code>LlmAgent</code>, <code>LoopAgent</code>, etc.).</p> <ul> <li>Initialization: You usually pass instances of these sub-agents into your custom agent's <code>__init__</code> method and store them as instance attributes (e.g., <code>self.story_generator = story_generator_instance</code>). This makes them accessible within <code>_run_async_impl</code>.</li> <li><code>sub_agents</code> List: When initializing the <code>BaseAgent</code> using <code>super().__init__(...)</code>, you should pass a <code>sub_agents</code> list. This list tells the ADK framework about the agents that are part of this custom agent's immediate hierarchy. It's important for framework features like lifecycle management, introspection, and potentially future routing capabilities, even if your <code>_run_async_impl</code> calls the agents directly via <code>self.xxx_agent</code>. Include the agents that your custom logic directly invokes at the top level.</li> <li>State: As mentioned, <code>ctx.session.state</code> is the standard way sub-agents (especially <code>LlmAgent</code>s using <code>output_key</code>) communicate results back to the orchestrator and how the orchestrator passes necessary inputs down.</li> </ul>"},{"location":"agents/custom-agents/#design-pattern-example-storyflowagent","title":"Design Pattern Example: <code>StoryFlowAgent</code>","text":"<p>Let's illustrate the power of custom agents with an example pattern: a multi-stage content generation workflow with conditional logic.</p> <p>Goal: Create a system that generates a story, iteratively refines it through critique and revision, performs final checks, and crucially, regenerates the story if the final tone check fails.</p> <p>Why Custom? The core requirement driving the need for a custom agent here is the conditional regeneration based on the tone check. Standard workflow agents don't have built-in conditional branching based on the outcome of a sub-agent's task. We need custom Python logic (<code>if tone == \"negative\": ...</code>) within the orchestrator.</p>"},{"location":"agents/custom-agents/#part-1-simplified-custom-agent-initialization","title":"Part 1: Simplified custom agent Initialization","text":"<p>We define the <code>StoryFlowAgent</code> inheriting from <code>BaseAgent</code>. In <code>__init__</code>, we store the necessary sub-agents (passed in) as instance attributes and tell the <code>BaseAgent</code> framework about the top-level agents this custom agent will directly orchestrate.</p> <pre><code>\n</code></pre>"},{"location":"agents/custom-agents/#part-2-defining-the-custom-execution-logic","title":"Part 2: Defining the Custom Execution Logic","text":"<p>This method orchestrates the sub-agents using standard Python async/await and control flow.</p> <p>Explanation of Logic:</p> <ol> <li>The initial <code>story_generator</code> runs. Its output is expected to be in <code>ctx.session.state[\"current_story\"]</code>.</li> <li>The <code>loop_agent</code> runs, which internally calls the <code>critic</code> and <code>reviser</code> sequentially for <code>max_iterations</code> times. They read/write <code>current_story</code> and <code>criticism</code> from/to the state.</li> <li>The <code>sequential_agent</code> runs, calling <code>grammar_check</code> then <code>tone_check</code>, reading <code>current_story</code> and writing <code>grammar_suggestions</code> and <code>tone_check_result</code> to the state.</li> <li>Custom Part: The <code>if</code> statement checks the <code>tone_check_result</code> from the state. If it's \"negative\", the <code>story_generator</code> is called again, overwriting the <code>current_story</code> in the state. Otherwise, the flow ends.</li> </ol>"},{"location":"agents/custom-agents/#part-3-defining-the-llm-sub-agents","title":"Part 3: Defining the LLM Sub-Agents","text":"<p>These are standard <code>LlmAgent</code> definitions, responsible for specific tasks. Their <code>output_key</code> parameter is crucial for placing results into the <code>session.state</code> where other agents or the custom orchestrator can access them.</p> <pre><code>GEMINI_2_FLASH = \"gemini-2.0-flash\" # Define model constant\n</code></pre>"},{"location":"agents/custom-agents/#part-4-instantiating-and-running-the-custom-agent","title":"Part 4: Instantiating and Running the custom agent","text":"<p>Finally, you instantiate your <code>StoryFlowAgent</code> and use the <code>Runner</code> as usual.</p> <pre><code>\n</code></pre> <p>(Note: The full runnable code, including imports and execution logic, can be found linked below.)</p>"},{"location":"agents/custom-agents/#full-code-example","title":"Full Code Example","text":"Storyflow Agent <pre><code># Full runnable code for the StoryFlowAgent example\n</code></pre>"},{"location":"agents/llm-agents/","title":"LLM Agent","text":"<p>The <code>LlmAgent</code> (often aliased simply as <code>Agent</code>) is a core component in ADK, acting as the \"thinking\" part of your application. It leverages the power of a Large Language Model (LLM) for reasoning, understanding natural language, making decisions, generating responses, and interacting with tools.</p> <p>Unlike deterministic Workflow Agents that follow predefined execution paths, <code>LlmAgent</code> behavior is non-deterministic. It uses the LLM to interpret instructions and context, deciding dynamically how to proceed, which tools to use (if any), or whether to transfer control to another agent.</p> <p>Building an effective <code>LlmAgent</code> involves defining its identity, clearly guiding its behavior through instructions, and equipping it with the necessary tools and capabilities.</p>"},{"location":"agents/llm-agents/#defining-the-agents-identity-and-purpose","title":"Defining the Agent's Identity and Purpose","text":"<p>First, you need to establish what the agent is and what it's for.</p> <ul> <li> <p><code>name</code> (Required): Every agent needs a unique string identifier. This <code>name</code> is crucial for internal operations, especially in multi-agent systems where agents need to refer to or delegate tasks to each other. Choose a descriptive name that reflects the agent's function (e.g., <code>customer_support_router</code>, <code>billing_inquiry_agent</code>). Avoid reserved names like <code>user</code>.</p> </li> <li> <p><code>description</code> (Optional, Recommended for Multi-Agent): Provide a concise summary of the agent's capabilities. This description is primarily used by other LLM agents to determine if they should route a task to this agent. Make it specific enough to differentiate it from peers (e.g., \"Handles inquiries about current billing statements,\" not just \"Billing agent\").</p> </li> <li> <p><code>model</code> (Required): Specify the underlying LLM that will power this agent's reasoning. This is a string identifier like <code>\"gemini-2.0-flash\"</code>. The choice of model impacts the agent's capabilities, cost, and performance. See the Models page for available options and considerations.</p> </li> </ul> <pre><code># Example: Defining the basic identity\ncapital_agent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"capital_agent\",\n    description=\"Answers user questions about the capital city of a given country.\"\n    # instruction and tools will be added next\n)\n</code></pre>"},{"location":"agents/llm-agents/#guiding-the-agent-instructions-instruction","title":"Guiding the Agent: Instructions (<code>instruction</code>)","text":"<p>The <code>instruction</code> parameter is arguably the most critical for shaping an <code>LlmAgent</code>'s behavior. It's a string (or a function returning a string) that tells the agent:</p> <ul> <li>Its core task or goal.</li> <li>Its personality or persona (e.g., \"You are a helpful assistant,\" \"You are a witty pirate\").</li> <li>Constraints on its behavior (e.g., \"Only answer questions about X,\" \"Never reveal Y\").</li> <li>How and when to use its <code>tools</code>. You should explain the purpose of each tool and the circumstances under which it should be called, supplementing any descriptions within the tool itself.</li> <li>The desired format for its output (e.g., \"Respond in JSON,\" \"Provide a bulleted list\").</li> </ul> <p>Tips for Effective Instructions:</p> <ul> <li>Be Clear and Specific: Avoid ambiguity. Clearly state the desired actions and outcomes.</li> <li>Use Markdown: Improve readability for complex instructions using headings, lists, etc.</li> <li>Provide Examples (Few-Shot): For complex tasks or specific output formats, include examples directly in the instruction.</li> <li>Guide Tool Use: Don't just list tools; explain when and why the agent should use them.</li> </ul> <pre><code># Example: Adding instructions\ncapital_agent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"capital_agent\",\n    description=\"Answers user questions about the capital city of a given country.\",\n    instruction=\"\"\"You are an agent that provides the capital city of a country.\nWhen a user asks for the capital of a country:\n1. Identify the country name from the user's query.\n2. Use the `get_capital_city` tool to find the capital.\n3. Respond clearly to the user, stating the capital city.\nExample Query: \"What's the capital of France?\"\nExample Response: \"The capital of France is Paris.\"\n\"\"\",\n    # tools will be added next\n)\n</code></pre> <p>(Note: For instructions that apply to all agents in a system, consider using <code>global_instruction</code> on the root agent, detailed further in the Multi-Agents section.)</p>"},{"location":"agents/llm-agents/#equipping-the-agent-tools-tools","title":"Equipping the Agent: Tools (<code>tools</code>)","text":"<p>Tools give your <code>LlmAgent</code> capabilities beyond the LLM's built-in knowledge or reasoning. They allow the agent to interact with the outside world, perform calculations, fetch real-time data, or execute specific actions.</p> <ul> <li><code>tools</code> (Optional): Provide a list of tools the agent can use. Each item in the list can be:<ul> <li>A Python function (automatically wrapped as a <code>FunctionTool</code>).</li> <li>An instance of a class inheriting from <code>BaseTool</code>.</li> <li>An instance of another agent (<code>AgentTool</code>, enabling agent-to-agent delegation - see Multi-Agents).</li> </ul> </li> </ul> <p>The LLM uses the function/tool names, descriptions (from docstrings or the <code>description</code> field), and parameter schemas to decide which tool to call based on the conversation and its instructions.</p> <pre><code># Define a tool function\ndef get_capital_city(country: str) -&gt; str:\n  \"\"\"Retrieves the capital city for a given country.\"\"\"\n  # Replace with actual logic (e.g., API call, database lookup)\n  capitals = {\"france\": \"Paris\", \"japan\": \"Tokyo\", \"canada\": \"Ottawa\"}\n  return capitals.get(country.lower(), f\"Sorry, I don't know the capital of {country}.\")\n\n# Add the tool to the agent\ncapital_agent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"capital_agent\",\n    description=\"Answers user questions about the capital city of a given country.\",\n    instruction=\"\"\"You are an agent that provides the capital city of a country... (previous instruction text)\"\"\",\n    tools=[get_capital_city] # Provide the function directly\n)\n</code></pre> <p>Learn more about Tools in the Tools section.</p>"},{"location":"agents/llm-agents/#advanced-configuration-control","title":"Advanced Configuration &amp; Control","text":"<p>Beyond the core parameters, <code>LlmAgent</code> offers several options for finer control:</p>"},{"location":"agents/llm-agents/#fine-tuning-llm-generation-generate_content_config","title":"Fine-Tuning LLM Generation (<code>generate_content_config</code>)","text":"<p>You can adjust how the underlying LLM generates responses using <code>generate_content_config</code>.</p> <ul> <li> <p><code>generate_content_config</code> (Optional): Pass an instance of <code>google.genai.types.GenerateContentConfig</code> to control parameters like <code>temperature</code> (randomness), <code>max_output_tokens</code> (response length), <code>top_p</code>, <code>top_k</code>, and safety settings.</p> <pre><code>from google.genai import types\n\nagent = LlmAgent(\n    # ... other params\n    generate_content_config=types.GenerateContentConfig(\n        temperature=0.2, # More deterministic output\n        max_output_tokens=250\n    )\n)\n</code></pre> </li> </ul>"},{"location":"agents/llm-agents/#structuring-data-input_schema-output_schema-output_key","title":"Structuring Data (<code>input_schema</code>, <code>output_schema</code>, <code>output_key</code>)","text":"<p>For scenarios requiring structured data exchange, you can use Pydantic models.</p> <ul> <li> <p><code>input_schema</code> (Optional): Define a Pydantic <code>BaseModel</code> class representing the expected input structure. If set, the user message content passed to this agent must be a JSON string conforming to this schema. Your instructions should guide the user or preceding agent accordingly.</p> </li> <li> <p><code>output_schema</code> (Optional): Define a Pydantic <code>BaseModel</code> class representing the desired output structure. If set, the agent's final response must be a JSON string conforming to this schema.</p> <ul> <li>Constraint: Using <code>output_schema</code> enables controlled generation within the LLM but disables the agent's ability to use tools or transfer control to other agents. Your instructions must guide the LLM to produce JSON matching the schema directly.</li> </ul> </li> <li> <p><code>output_key</code> (Optional): Provide a string key. If set, the text content of the agent's final response will be automatically saved to the session's state dictionary under this key (e.g., <code>session.state[output_key] = agent_response_text</code>). This is useful for passing results between agents or steps in a workflow.</p> </li> </ul> <pre><code>from pydantic import BaseModel, Field\n\nclass CapitalOutput(BaseModel):\n    capital: str = Field(description=\"The capital of the country.\")\n\nstructured_capital_agent = LlmAgent(\n    # ... name, model, description\n    instruction=\"\"\"You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\"capital\": \"capital_name\"}\"\"\",\n    output_schema=CapitalOutput, # Enforce JSON output\n    output_key=\"found_capital\"  # Store result in state['found_capital']\n    # Cannot use tools=[get_capital_city] effectively here\n)\n</code></pre>"},{"location":"agents/llm-agents/#managing-context-include_contents","title":"Managing Context (<code>include_contents</code>)","text":"<p>Control whether the agent receives the prior conversation history.</p> <ul> <li> <p><code>include_contents</code> (Optional, Default: <code>'default'</code>): Determines if the <code>contents</code> (history) are sent to the LLM.</p> <ul> <li><code>'default'</code>: The agent receives the relevant conversation history.</li> <li><code>'none'</code>: The agent receives no prior <code>contents</code>. It operates based solely on its current instruction and any input provided in the current turn (useful for stateless tasks or enforcing specific contexts).</li> </ul> <pre><code>stateless_agent = LlmAgent(\n    # ... other params\n    include_contents='none'\n)\n</code></pre> </li> </ul>"},{"location":"agents/llm-agents/#planning-code-execution","title":"Planning &amp; Code Execution","text":"<p>For more complex reasoning involving multiple steps or executing code:</p> <ul> <li><code>planner</code> (Optional): Assign a <code>BasePlanner</code> instance to enable multi-step reasoning and planning before execution. (See Multi-Agents patterns).</li> <li><code>code_executor</code> (Optional): Provide a <code>BaseCodeExecutor</code> instance to allow the agent to execute code blocks (e.g., Python) found in the LLM's response. (See Tools/Built-in tools).</li> </ul>"},{"location":"agents/llm-agents/#putting-it-together-example","title":"Putting It Together: Example","text":"Code <p>Here's the complete basic <code>capital_agent</code>:</p> <pre><code># Full example code for the basic capital agent\n</code></pre> <p>(This example demonstrates the core concepts. More complex agents might incorporate schemas, context control, planning, etc.)</p>"},{"location":"agents/llm-agents/#related-concepts-deferred-topics","title":"Related Concepts (Deferred Topics)","text":"<p>While this page covers the core configuration of <code>LlmAgent</code>, several related concepts provide more advanced control and are detailed elsewhere:</p> <ul> <li>Callbacks: Intercepting execution points (before/after model calls, before/after tool calls) using <code>before_model_callback</code>, <code>after_model_callback</code>, etc. See Callbacks.</li> <li>Multi-Agent Control: Advanced strategies for agent interaction, including planning (<code>planner</code>), controlling agent transfer (<code>disallow_transfer_to_parent</code>, <code>disallow_transfer_to_peers</code>), and system-wide instructions (<code>global_instruction</code>). See Multi-Agents.</li> </ul>"},{"location":"agents/models/","title":"Using Different Models with ADK","text":"<p>The Agent Development Kit (ADK) is designed for flexibility, allowing you to integrate various Large Language Models (LLMs) into your agents. While the setup for Google Gemini models is covered in the Setup Foundation Models guide, this page details how to leverage Gemini effectively and integrate other popular models, including those hosted externally or running locally.</p> <p>ADK primarily uses two mechanisms for model integration:</p> <ol> <li>Direct String / Registry: For models tightly integrated with Google Cloud    (like Gemini models accessed via Google AI Studio or Vertex AI) or models    hosted on Vertex AI endpoints. You typically provide the model name or    endpoint resource string directly to the <code>LlmAgent</code>. ADK's internal registry    resolves this string to the appropriate backend client, often utilizing the    <code>google-genai</code> library.</li> <li>Wrapper Classes: For broader compatibility, especially with models    outside the Google ecosystem or those requiring specific client    configurations (like models accessed via LiteLLM). You instantiate a specific    wrapper class (e.g., <code>LiteLlm</code>) and pass this object as the <code>model</code> parameter    to your <code>LlmAgent</code>.</li> </ol> <p>The following sections guide you through using these methods based on your needs.</p>"},{"location":"agents/models/#using-google-gemini-models","title":"Using Google Gemini Models","text":"<p>This is the most direct way to use Google's flagship models within ADK.</p> <p>Integration Method: Pass the model's identifier string directly to the <code>model</code> parameter of <code>LlmAgent</code> (or its alias, <code>Agent</code>).</p> <p>Backend Options &amp; Setup:</p> <p>The <code>google-genai</code> library, used internally by ADK for Gemini, can connect through either Google AI Studio or Vertex AI.</p> <p>Model support for voice/video streaming</p> <p>In order to use voice/video streaming in ADK, you will need to use Gemini models that support the Live API. You can find the model ID(s) that support the Gemini Live API in the documentation:</p> <ul> <li>Google AI Studio: Gemini Live API</li> <li>Vertex AI: Gemini Live API</li> </ul>"},{"location":"agents/models/#google-ai-studio","title":"Google AI Studio","text":"<ul> <li>Use Case: Google AI Studio is the easiest way to get started with Gemini.   All you need is the API key. Best   for rapid prototyping and development.</li> <li>Setup: Typically requires an API key set as an environment variable:</li> </ul> <pre><code>export GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\"\nexport GOOGLE_GENAI_USE_VERTEXAI=FALSE\n</code></pre> <ul> <li>Models: Find all available models on the   Google AI for Developers site.</li> </ul>"},{"location":"agents/models/#vertex-ai","title":"Vertex AI","text":"<ul> <li>Use Case: Recommended for production applications, leveraging Google Cloud   infrastructure. Gemini on Vertex AI supports enterprise-grade features,   security, and compliance controls.</li> <li> <p>Setup:</p> <ul> <li> <p>Authenticate using Application Default Credentials (ADC):</p> <pre><code>gcloud auth application-default login\n</code></pre> </li> <li> <p>Set your Google Cloud project and location:</p> <pre><code>export GOOGLE_CLOUD_PROJECT=\"YOUR_PROJECT_ID\"\nexport GOOGLE_CLOUD_LOCATION=\"YOUR_VERTEX_AI_LOCATION\" # e.g., us-central1\n</code></pre> </li> <li> <p>Explicitly tell the library to use Vertex AI:</p> <pre><code>export GOOGLE_GENAI_USE_VERTEXAI=TRUE\n</code></pre> </li> </ul> </li> <li> <p>Models: Find available model IDs in the   Vertex AI documentation.</p> </li> </ul> <p>Example:</p> <pre><code>from google.adk.agents import LlmAgent\n\n# --- Example using a stable Gemini Flash model ---\nagent_gemini_flash = LlmAgent(\n    # Use the latest stable Flash model identifier\n    model=\"gemini-2.0-flash\",\n    name=\"gemini_flash_agent\",\n    instruction=\"You are a fast and helpful Gemini assistant.\",\n    # ... other agent parameters\n)\n\n# --- Example using a powerful Gemini Pro model ---\n# Note: Always check the official Gemini documentation for the latest model names,\n# including specific preview versions if needed. Preview models might have\n# different availability or quota limitations.\nagent_gemini_pro = LlmAgent(\n    # Use the latest generally available Pro model identifier\n    model=\"gemini-2.5-pro-preview-03-25\",\n    name=\"gemini_pro_agent\",\n    instruction=\"You are a powerful and knowledgeable Gemini assistant.\",\n    # ... other agent parameters\n)\n</code></pre>"},{"location":"agents/models/#using-cloud-proprietary-models-via-litellm","title":"Using Cloud &amp; Proprietary Models via LiteLLM","text":"<p>To access a vast range of LLMs from providers like OpenAI, Anthropic (non-Vertex AI), Cohere, and many others, ADK offers integration through the LiteLLM library.</p> <p>Integration Method: Instantiate the <code>LiteLlm</code> wrapper class and pass it to the <code>model</code> parameter of <code>LlmAgent</code>.</p> <p>LiteLLM Overview: LiteLLM acts as a translation layer, providing a standardized, OpenAI-compatible interface to over 100+ LLMs.</p> <p>Setup:</p> <ol> <li>Install LiteLLM: <pre><code>pip install litellm\n</code></pre></li> <li> <p>Set Provider API Keys: Configure API keys as environment variables for    the specific providers you intend to use.</p> <ul> <li> <p>Example for OpenAI:</p> <pre><code>export OPENAI_API_KEY=\"YOUR_OPENAI_API_KEY\"\n</code></pre> </li> <li> <p>Example for Anthropic (non-Vertex AI):</p> <pre><code>export ANTHROPIC_API_KEY=\"YOUR_ANTHROPIC_API_KEY\"\n</code></pre> </li> <li> <p>Consult the   LiteLLM Providers Documentation   for the correct environment variable names for other providers.</p> <p>Example:</p> <pre><code>from google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\n\n# --- Example Agent using OpenAI's GPT-4o ---\n# (Requires OPENAI_API_KEY)\nagent_openai = LlmAgent(\n    model=LiteLlm(model=\"openai/gpt-4o\"), # LiteLLM model string format\n    name=\"openai_agent\",\n    instruction=\"You are a helpful assistant powered by GPT-4o.\",\n    # ... other agent parameters\n)\n\n# --- Example Agent using Anthropic's Claude Haiku (non-Vertex) ---\n# (Requires ANTHROPIC_API_KEY)\nagent_claude_direct = LlmAgent(\n    model=LiteLlm(model=\"anthropic/claude-3-haiku-20240307\"),\n    name=\"claude_direct_agent\",\n    instruction=\"You are an assistant powered by Claude Haiku.\",\n    # ... other agent parameters\n)\n</code></pre> </li> </ul> </li> </ol>"},{"location":"agents/models/#using-open-local-models-via-litellm","title":"Using Open &amp; Local Models via LiteLLM","text":"<p>For maximum control, cost savings, privacy, or offline use cases, you can run open-source models locally or self-host them and integrate them using LiteLLM.</p> <p>Integration Method: Instantiate the <code>LiteLlm</code> wrapper class, configured to point to your local model server.</p>"},{"location":"agents/models/#ollama-integration","title":"Ollama Integration","text":"<p>Ollama allows you to easily run open-source models locally.</p>"},{"location":"agents/models/#model-choice","title":"Model choice","text":"<p>If your agent is relying on tools, please make sure that you select a model with tool support from Ollama website.</p> <p>For reliable results, we recommend using a decent-sized model with tool support.</p> <p>The tool support for the model can be checked with the following command:</p> <pre><code>ollama show mistral-small3.1\n  Model\n    architecture        mistral3\n    parameters          24.0B\n    context length      131072\n    embedding length    5120\n    quantization        Q4_K_M\n\n  Capabilities\n    completion\n    vision\n    tools\n</code></pre> <p>You are supposed to see <code>tools</code> listed under capabilities.</p> <p>You can also look at the template the model is using and tweak it based on your needs.</p> <pre><code>ollama show --modelfile llama3.2 &gt; model_file_to_modify\n</code></pre> <p>For instance, the default template for the above model inherently suggests that the model shall call a function all the time. This may result in an infinite loop of function calls.</p> <pre><code>Given the following functions, please respond with a JSON for a function call\nwith its proper arguments that best answers the given prompt.\n\nRespond in the format {\"name\": function name, \"parameters\": dictionary of\nargument name and its value}. Do not use variables.\n</code></pre> <p>You can swap such prompts with a more descriptive one to prevent infinite tool call loops.</p> <p>For instance:</p> <pre><code>Review the user's prompt and the available functions listed below.\nFirst, determine if calling one of these functions is the most appropriate way to respond. A function call is likely needed if the prompt asks for a specific action, requires external data lookup, or involves calculations handled by the functions. If the prompt is a general question or can be answered directly, a function call is likely NOT needed.\n\nIf you determine a function call IS required: Respond ONLY with a JSON object in the format {\"name\": \"function_name\", \"parameters\": {\"argument_name\": \"value\"}}. Ensure parameter values are concrete, not variables.\n\nIf you determine a function call IS NOT required: Respond directly to the user's prompt in plain text, providing the answer or information requested. Do not output any JSON.\n</code></pre> <p>Then you can create a new model with the following command:</p> <pre><code>ollama create llama3.2-modified -f model_file_to_modify\n</code></pre>"},{"location":"agents/models/#using-ollama_chat-provider","title":"Using ollama_chat provider","text":"<p>Our LiteLLM wrapper can be used to create agents with Ollama models.</p> <pre><code>root_agent = Agent(\n    model=LiteLlm(model=\"ollama_chat/mistral-small3.1\"),\n    name=\"dice_agent\",\n    description=(\n        \"hello world agent that can roll a dice of 8 sides and check prime\"\n        \" numbers.\"\n    ),\n    instruction=\"\"\"\n      You roll dice and answer questions about the outcome of the dice rolls.\n    \"\"\",\n    tools=[\n        roll_die,\n        check_prime,\n    ],\n)\n</code></pre> <p>It is important to set the provider <code>ollama_chat</code> instead of <code>ollama</code>. Using <code>ollama</code> will result in unexpected behaviors such as infinite tool call loops and ignoring previous context.</p> <p>While <code>api_base</code> can be provided inside LiteLLM for generation, LiteLLM library is calling other APIs relying on the env variable instead as of v1.65.5 after completion. So at this time, we recommend setting the env variable <code>OLLAMA_API_BASE</code> to point to the ollama server.</p> <pre><code>export OLLAMA_API_BASE=\"http://localhost:11434\"\nadk web\n</code></pre>"},{"location":"agents/models/#using-openai-provider","title":"Using openai provider","text":"<p>Alternatively, <code>openai</code> can be used as the provider name. But this will also require setting the <code>OPENAI_API_BASE=http://localhost:11434/v1</code> and <code>OPENAI_API_KEY=anything</code> env variables instead of <code>OLLAMA_API_BASE</code>. Please note that api base now has <code>/v1</code> at the end.</p> <pre><code>root_agent = Agent(\n    model=LiteLlm(model=\"openai/mistral-small3.1\"),\n    name=\"dice_agent\",\n    description=(\n        \"hello world agent that can roll a dice of 8 sides and check prime\"\n        \" numbers.\"\n    ),\n    instruction=\"\"\"\n      You roll dice and answer questions about the outcome of the dice rolls.\n    \"\"\",\n    tools=[\n        roll_die,\n        check_prime,\n    ],\n)\n</code></pre> <pre><code>export OPENAI_API_BASE=http://localhost:11434/v1\nexport OPENAI_API_KEY=anything\nadk web\n</code></pre>"},{"location":"agents/models/#debugging","title":"Debugging","text":"<p>You can see the request sent to the Ollama server by adding the following in your agent code just after imports.</p> <pre><code>import litellm\nlitellm._turn_on_debug()\n</code></pre> <p>Look for a line like the following:</p> <pre><code>Request Sent from LiteLLM:\ncurl -X POST \\\nhttp://localhost:11434/api/chat \\\n-d '{'model': 'mistral-small3.1', 'messages': [{'role': 'system', 'content': ...\n</code></pre>"},{"location":"agents/models/#self-hosted-endpoint-eg-vllm","title":"Self-Hosted Endpoint (e.g., vLLM)","text":"<p>Tools such as vLLM allow you to host models efficiently and often expose an OpenAI-compatible API endpoint.</p> <p>Setup:</p> <ol> <li>Deploy Model: Deploy your chosen model using vLLM (or a similar tool).    Note the API base URL (e.g., <code>https://your-vllm-endpoint.run.app/v1</code>).<ul> <li>Important for ADK Tools: When deploying, ensure the serving tool   supports and enables OpenAI-compatible tool/function calling. For vLLM,   this might involve flags like <code>--enable-auto-tool-choice</code> and potentially   a specific <code>--tool-call-parser</code>, depending on the model. Refer to the vLLM   documentation on Tool Use.</li> </ul> </li> <li> <p>Authentication: Determine how your endpoint handles authentication (e.g.,    API key, bearer token).</p> <p>Integration Example:</p> <pre><code>import subprocess\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\n\n# --- Example Agent using a model hosted on a vLLM endpoint ---\n\n# Endpoint URL provided by your vLLM deployment\napi_base_url = \"https://your-vllm-endpoint.run.app/v1\"\n\n# Model name as recognized by *your* vLLM endpoint configuration\nmodel_name_at_endpoint = \"hosted_vllm/google/gemma-3-4b-it\" # Example from vllm_test.py\n\n# Authentication (Example: using gcloud identity token for a Cloud Run deployment)\n# Adapt this based on your endpoint's security\ntry:\n    gcloud_token = subprocess.check_output(\n        [\"gcloud\", \"auth\", \"print-identity-token\", \"-q\"]\n    ).decode().strip()\n    auth_headers = {\"Authorization\": f\"Bearer {gcloud_token}\"}\nexcept Exception as e:\n    print(f\"Warning: Could not get gcloud token - {e}. Endpoint might be unsecured or require different auth.\")\n    auth_headers = None # Or handle error appropriately\n\nagent_vllm = LlmAgent(\n    model=LiteLlm(\n        model=model_name_at_endpoint,\n        api_base=api_base_url,\n        # Pass authentication headers if needed\n        extra_headers=auth_headers\n        # Alternatively, if endpoint uses an API key:\n        # api_key=\"YOUR_ENDPOINT_API_KEY\"\n    ),\n    name=\"vllm_agent\",\n    instruction=\"You are a helpful assistant running on a self-hosted vLLM endpoint.\",\n    # ... other agent parameters\n)\n</code></pre> </li> </ol>"},{"location":"agents/models/#using-hosted-tuned-models-on-vertex-ai","title":"Using Hosted &amp; Tuned Models on Vertex AI","text":"<p>For enterprise-grade scalability, reliability, and integration with Google Cloud's MLOps ecosystem, you can use models deployed to Vertex AI Endpoints. This includes models from Model Garden or your own fine-tuned models.</p> <p>Integration Method: Pass the full Vertex AI Endpoint resource string (<code>projects/PROJECT_ID/locations/LOCATION/endpoints/ENDPOINT_ID</code>) directly to the <code>model</code> parameter of <code>LlmAgent</code>.</p> <p>Vertex AI Setup (Consolidated):</p> <p>Ensure your environment is configured for Vertex AI:</p> <ol> <li> <p>Authentication: Use Application Default Credentials (ADC):</p> <pre><code>gcloud auth application-default login\n</code></pre> </li> <li> <p>Environment Variables: Set your project and location:</p> <pre><code>export GOOGLE_CLOUD_PROJECT=\"YOUR_PROJECT_ID\"\nexport GOOGLE_CLOUD_LOCATION=\"YOUR_VERTEX_AI_LOCATION\" # e.g., us-central1\n</code></pre> </li> <li> <p>Enable Vertex Backend: Crucially, ensure the <code>google-genai</code> library    targets Vertex AI:</p> <pre><code>export GOOGLE_GENAI_USE_VERTEXAI=TRUE\n</code></pre> </li> </ol>"},{"location":"agents/models/#model-garden-deployments","title":"Model Garden Deployments","text":"<p>You can deploy various open and proprietary models from the Vertex AI Model Garden to an endpoint.</p> <p>Example:</p> <pre><code>from google.adk.agents import LlmAgent\nfrom google.genai import types # For config objects\n\n# --- Example Agent using a Llama 3 model deployed from Model Garden ---\n\n# Replace with your actual Vertex AI Endpoint resource name\nllama3_endpoint = \"projects/YOUR_PROJECT_ID/locations/us-central1/endpoints/YOUR_LLAMA3_ENDPOINT_ID\"\n\nagent_llama3_vertex = LlmAgent(\n    model=llama3_endpoint,\n    name=\"llama3_vertex_agent\",\n    instruction=\"You are a helpful assistant based on Llama 3, hosted on Vertex AI.\",\n    generate_content_config=types.GenerateContentConfig(max_output_tokens=2048),\n    # ... other agent parameters\n)\n</code></pre>"},{"location":"agents/models/#fine-tuned-model-endpoints","title":"Fine-tuned Model Endpoints","text":"<p>Deploying your fine-tuned models (whether based on Gemini or other architectures supported by Vertex AI) results in an endpoint that can be used directly.</p> <p>Example:</p> <pre><code>from google.adk.agents import LlmAgent\n\n# --- Example Agent using a fine-tuned Gemini model endpoint ---\n\n# Replace with your fine-tuned model's endpoint resource name\nfinetuned_gemini_endpoint = \"projects/YOUR_PROJECT_ID/locations/us-central1/endpoints/YOUR_FINETUNED_ENDPOINT_ID\"\n\nagent_finetuned_gemini = LlmAgent(\n    model=finetuned_gemini_endpoint,\n    name=\"finetuned_gemini_agent\",\n    instruction=\"You are a specialized assistant trained on specific data.\",\n    # ... other agent parameters\n)\n</code></pre>"},{"location":"agents/models/#third-party-models-on-vertex-ai-eg-anthropic-claude","title":"Third-Party Models on Vertex AI (e.g., Anthropic Claude)","text":"<p>Some providers, like Anthropic, make their models available directly through Vertex AI.</p> <p>Integration Method: Uses the direct model string (e.g., <code>\"claude-3-sonnet@20240229\"</code>), but requires manual registration within ADK.</p> <p>Why Registration? ADK's registry automatically recognizes <code>gemini-*</code> strings and standard Vertex AI endpoint strings (<code>projects/.../endpoints/...</code>) and routes them via the <code>google-genai</code> library. For other model types used directly via Vertex AI (like Claude), you must explicitly tell the ADK registry which specific wrapper class (<code>Claude</code> in this case) knows how to handle that model identifier string with the Vertex AI backend.</p> <p>Setup:</p> <ol> <li> <p>Vertex AI Environment: Ensure the consolidated Vertex AI setup (ADC, Env    Vars, <code>GOOGLE_GENAI_USE_VERTEXAI=TRUE</code>) is complete.</p> </li> <li> <p>Install Provider Library: Install the necessary client library configured    for Vertex AI.</p> <pre><code>pip install \"anthropic[vertex]\"\n</code></pre> </li> <li> <p>Register Model Class: Add this code near the start of your application,    before creating an agent using the Claude model string:</p> <pre><code># Required for using Claude model strings directly via Vertex AI with LlmAgent\nfrom google.adk.models.anthropic_llm import Claude\nfrom google.adk.models.registry import LLMRegistry\n\nLLMRegistry.register(Claude)\n</code></pre> <p>Example:</p> <pre><code>from google.adk.agents import LlmAgent\nfrom google.adk.models.anthropic_llm import Claude # Import needed for registration\nfrom google.adk.models.registry import LLMRegistry # Import needed for registration\nfrom google.genai import types\n\n# --- Register Claude class (do this once at startup) ---\nLLMRegistry.register(Claude)\n\n# --- Example Agent using Claude 3 Sonnet on Vertex AI ---\n\n# Standard model name for Claude 3 Sonnet on Vertex AI\nclaude_model_vertexai = \"claude-3-sonnet@20240229\"\n\nagent_claude_vertexai = LlmAgent(\n    model=claude_model_vertexai, # Pass the direct string after registration\n    name=\"claude_vertexai_agent\",\n    instruction=\"You are an assistant powered by Claude 3 Sonnet on Vertex AI.\",\n    generate_content_config=types.GenerateContentConfig(max_output_tokens=4096),\n    # ... other agent parameters\n)\n</code></pre> </li> </ol>"},{"location":"agents/multi-agents/","title":"Multi-Agent Systems in ADK","text":"<p>As agentic applications grow in complexity, structuring them as a single, monolithic agent can become challenging to develop, maintain, and reason about. The Agent Development Kit (ADK) supports building sophisticated applications by composing multiple, distinct <code>BaseAgent</code> instances into a Multi-Agent System (MAS).</p> <p>In ADK, a multi-agent system is an application where different agents, often forming a hierarchy, collaborate or coordinate to achieve a larger goal. Structuring your application this way offers significant advantages, including enhanced modularity, specialization, reusability, maintainability, and the ability to define structured control flows using dedicated workflow agents.</p> <p>You can compose various types of agents derived from <code>BaseAgent</code> to build these systems:</p> <ul> <li>LLM Agents: Agents powered by large language models. (See LLM Agents)</li> <li>Workflow Agents: Specialized agents (<code>SequentialAgent</code>, <code>ParallelAgent</code>, <code>LoopAgent</code>) designed to manage the execution flow of their sub-agents. (See Workflow Agents)</li> <li>Custom agents: Your own agents inheriting from <code>BaseAgent</code> with specialized, non-LLM logic. (See Custom Agents)</li> </ul> <p>The following sections detail the core ADK primitives\u2014such as agent hierarchy, workflow agents, and interaction mechanisms\u2014that enable you to construct and manage these multi-agent systems effectively.</p>"},{"location":"agents/multi-agents/#2-adk-primitives-for-agent-composition","title":"2. ADK Primitives for Agent Composition","text":"<p>ADK provides core building blocks\u2014primitives\u2014that enable you to structure and manage interactions within your multi-agent system.</p>"},{"location":"agents/multi-agents/#21-agent-hierarchy-parent_agent-sub_agents","title":"2.1. Agent Hierarchy (<code>parent_agent</code>, <code>sub_agents</code>)","text":"<p>The foundation for structuring multi-agent systems is the parent-child relationship defined in <code>BaseAgent</code>.</p> <ul> <li>Establishing Hierarchy: You create a tree structure by passing a list of agent instances to the <code>sub_agents</code> argument when initializing a parent agent. ADK automatically sets the <code>parent_agent</code> attribute on each child agent during initialization (<code>google.adk.agents.base_agent.py</code> - <code>model_post_init</code>).</li> <li>Single Parent Rule: An agent instance can only be added as a sub-agent once. Attempting to assign a second parent will result in a <code>ValueError</code>.</li> <li>Importance: This hierarchy defines the scope for Workflow Agents and influences the potential targets for LLM-Driven Delegation. You can navigate the hierarchy using <code>agent.parent_agent</code> or find descendants using <code>agent.find_agent(name)</code>.</li> </ul> <pre><code># Conceptual Example: Defining Hierarchy\nfrom google.adk.agents import LlmAgent, BaseAgent\n\n# Define individual agents\ngreeter = LlmAgent(name=\"Greeter\", model=\"gemini-2.0-flash\")\ntask_doer = BaseAgent(name=\"TaskExecutor\") # Custom non-LLM agent\n\n# Create parent agent and assign children via sub_agents\ncoordinator = LlmAgent(\n    name=\"Coordinator\",\n    model=\"gemini-2.0-flash\",\n    description=\"I coordinate greetings and tasks.\",\n    sub_agents=[ # Assign sub_agents here\n        greeter,\n        task_doer\n    ]\n)\n\n# Framework automatically sets:\n# assert greeter.parent_agent == coordinator\n# assert task_doer.parent_agent == coordinator\n</code></pre>"},{"location":"agents/multi-agents/#22-workflow-agents-as-orchestrators","title":"2.2. Workflow Agents as Orchestrators","text":"<p>ADK includes specialized agents derived from <code>BaseAgent</code> that don't perform tasks themselves but orchestrate the execution flow of their <code>sub_agents</code>.</p> <ul> <li> <p><code>SequentialAgent</code>: Executes its <code>sub_agents</code> one after another in the order they are listed.</p> <ul> <li>Context: Passes the same <code>InvocationContext</code> sequentially, allowing agents to easily pass results via shared state.</li> </ul> <pre><code># Conceptual Example: Sequential Pipeline\nfrom google.adk.agents import SequentialAgent, LlmAgent\n\nstep1 = LlmAgent(name=\"Step1_Fetch\", output_key=\"data\") # Saves output to state['data']\nstep2 = LlmAgent(name=\"Step2_Process\", instruction=\"Process data from state key 'data'.\")\n\npipeline = SequentialAgent(name=\"MyPipeline\", sub_agents=[step1, step2])\n# When pipeline runs, Step2 can access the state['data'] set by Step1.\n</code></pre> </li> <li> <p><code>ParallelAgent</code>: Executes its <code>sub_agents</code> in parallel. Events from sub-agents may be interleaved.</p> <ul> <li>Context: Modifies the <code>InvocationContext.branch</code> for each child agent (e.g., <code>ParentBranch.ChildName</code>), providing a distinct contextual path which can be useful for isolating history in some memory implementations.</li> <li>State: Despite different branches, all parallel children access the same shared <code>session.state</code>, enabling them to read initial state and write results (use distinct keys to avoid race conditions).</li> </ul> <pre><code># Conceptual Example: Parallel Execution\nfrom google.adk.agents import ParallelAgent, LlmAgent\n\nfetch_weather = LlmAgent(name=\"WeatherFetcher\", output_key=\"weather\")\nfetch_news = LlmAgent(name=\"NewsFetcher\", output_key=\"news\")\n\ngatherer = ParallelAgent(name=\"InfoGatherer\", sub_agents=[fetch_weather, fetch_news])\n# When gatherer runs, WeatherFetcher and NewsFetcher run concurrently.\n# A subsequent agent could read state['weather'] and state['news'].\n</code></pre> </li> <li> <p><code>LoopAgent</code>: Executes its <code>sub_agents</code> sequentially in a loop.</p> <ul> <li>Termination: The loop stops if the optional <code>max_iterations</code> is reached, or if any sub-agent yields an <code>Event</code> with <code>actions.escalate=True</code>.</li> <li>Context &amp; State: Passes the same <code>InvocationContext</code> in each iteration, allowing state changes (e.g., counters, flags) to persist across loops.</li> </ul> <pre><code># Conceptual Example: Loop with Condition\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\nfrom google.adk.events import Event, EventActions\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom typing import AsyncGenerator\n\nclass CheckCondition(BaseAgent): # Custom agent to check state\n    async def _run_async_impl(self, ctx: InvocationContext) -&gt; AsyncGenerator[Event, None]:\n        status = ctx.session.state.get(\"status\", \"pending\")\n        is_done = (status == \"completed\")\n        yield Event(author=self.name, actions=EventActions(escalate=is_done)) # Escalate if done\n\nprocess_step = LlmAgent(name=\"ProcessingStep\") # Agent that might update state['status']\n\npoller = LoopAgent(\n    name=\"StatusPoller\",\n    max_iterations=10,\n    sub_agents=[process_step, CheckCondition(name=\"Checker\")]\n)\n# When poller runs, it executes process_step then Checker repeatedly\n# until Checker escalates (state['status'] == 'completed') or 10 iterations pass.\n</code></pre> </li> </ul>"},{"location":"agents/multi-agents/#23-interaction-communication-mechanisms","title":"2.3. Interaction &amp; Communication Mechanisms","text":"<p>Agents within a system often need to exchange data or trigger actions in one another. ADK facilitates this through:</p>"},{"location":"agents/multi-agents/#a-shared-session-state-sessionstate","title":"a) Shared Session State (<code>session.state</code>)","text":"<p>The most fundamental way for agents operating within the same invocation (and thus sharing the same <code>Session</code> object via the <code>InvocationContext</code>) to communicate passively.</p> <ul> <li>Mechanism: One agent (or its tool/callback) writes a value (<code>context.state['data_key'] = processed_data</code>), and a subsequent agent reads it (<code>data = context.state.get('data_key')</code>). State changes are tracked via <code>CallbackContext</code>.</li> <li>Convenience: The <code>output_key</code> property on <code>LlmAgent</code> automatically saves the agent's final response text (or structured output) to the specified state key.</li> <li>Nature: Asynchronous, passive communication. Ideal for pipelines orchestrated by <code>SequentialAgent</code> or passing data across <code>LoopAgent</code> iterations.</li> <li>See Also: State Management</li> </ul> <pre><code># Conceptual Example: Using output_key and reading state\nfrom google.adk.agents import LlmAgent, SequentialAgent\n\nagent_A = LlmAgent(name=\"AgentA\", instruction=\"Find the capital of France.\", output_key=\"capital_city\")\nagent_B = LlmAgent(name=\"AgentB\", instruction=\"Tell me about the city stored in state key 'capital_city'.\")\n\npipeline = SequentialAgent(name=\"CityInfo\", sub_agents=[agent_A, agent_B])\n# AgentA runs, saves \"Paris\" to state['capital_city'].\n# AgentB runs, its instruction processor reads state['capital_city'] to get \"Paris\".\n</code></pre>"},{"location":"agents/multi-agents/#b-llm-driven-delegation-agent-transfer","title":"b) LLM-Driven Delegation (Agent Transfer)","text":"<p>Leverages an <code>LlmAgent</code>'s understanding to dynamically route tasks to other suitable agents within the hierarchy.</p> <ul> <li>Mechanism: The agent's LLM generates a specific function call: <code>transfer_to_agent(agent_name='target_agent_name')</code>.</li> <li>Handling: The <code>AutoFlow</code>, used by default when sub-agents are present or transfer isn't disallowed, intercepts this call. It identifies the target agent using <code>root_agent.find_agent()</code> and updates the <code>InvocationContext</code> to switch execution focus.</li> <li>Requires: The calling <code>LlmAgent</code> needs clear <code>instructions</code> on when to transfer, and potential target agents need distinct <code>description</code>s for the LLM to make informed decisions. Transfer scope (parent, sub-agent, siblings) can be configured on the <code>LlmAgent</code>.</li> <li>Nature: Dynamic, flexible routing based on LLM interpretation.</li> </ul> <pre><code># Conceptual Setup: LLM Transfer\nfrom google.adk.agents import LlmAgent\n\nbooking_agent = LlmAgent(name=\"Booker\", description=\"Handles flight and hotel bookings.\")\ninfo_agent = LlmAgent(name=\"Info\", description=\"Provides general information and answers questions.\")\n\ncoordinator = LlmAgent(\n    name=\"Coordinator\",\n    instruction=\"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\",\n    description=\"Main coordinator.\",\n    # AutoFlow is typically used implicitly here\n    sub_agents=[booking_agent, info_agent]\n)\n# If coordinator receives \"Book a flight\", its LLM should generate:\n# FunctionCall(name='transfer_to_agent', args={'agent_name': 'Booker'})\n# ADK framework then routes execution to booking_agent.\n</code></pre>"},{"location":"agents/multi-agents/#c-explicit-invocation-agenttool","title":"c) Explicit Invocation (<code>AgentTool</code>)","text":"<p>Allows an <code>LlmAgent</code> to treat another <code>BaseAgent</code> instance as a callable function or Tool.</p> <ul> <li>Mechanism: Wrap the target agent instance in <code>AgentTool</code> and include it in the parent <code>LlmAgent</code>'s <code>tools</code> list. <code>AgentTool</code> generates a corresponding function declaration for the LLM.</li> <li>Handling: When the parent LLM generates a function call targeting the <code>AgentTool</code>, the framework executes <code>AgentTool.run_async</code>. This method runs the target agent, captures its final response, forwards any state/artifact changes back to the parent's context, and returns the response as the tool's result.</li> <li>Nature: Synchronous (within the parent's flow), explicit, controlled invocation like any other tool.</li> <li>(Note: <code>AgentTool</code> needs to be imported and used explicitly).</li> </ul> <pre><code># Conceptual Setup: Agent as a Tool\nfrom google.adk.agents import LlmAgent, BaseAgent\nfrom google.adk.tools import agent_tool\nfrom pydantic import BaseModel\n\n# Define a target agent (could be LlmAgent or custom BaseAgent)\nclass ImageGeneratorAgent(BaseAgent): # Example custom agent\n    name: str = \"ImageGen\"\n    description: str = \"Generates an image based on a prompt.\"\n    # ... internal logic ...\n    async def _run_async_impl(self, ctx): # Simplified run logic\n        prompt = ctx.session.state.get(\"image_prompt\", \"default prompt\")\n        # ... generate image bytes ...\n        image_bytes = b\"...\"\n        yield Event(author=self.name, content=types.Content(parts=[types.Part.from_bytes(image_bytes, \"image/png\")]))\n\nimage_agent = ImageGeneratorAgent()\nimage_tool = agent_tool.AgentTool(agent=image_agent) # Wrap the agent\n\n# Parent agent uses the AgentTool\nartist_agent = LlmAgent(\n    name=\"Artist\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"Create a prompt and use the ImageGen tool to generate the image.\",\n    tools=[image_tool] # Include the AgentTool\n)\n# Artist LLM generates a prompt, then calls:\n# FunctionCall(name='ImageGen', args={'image_prompt': 'a cat wearing a hat'})\n# Framework calls image_tool.run_async(...), which runs ImageGeneratorAgent.\n# The resulting image Part is returned to the Artist agent as the tool result.\n</code></pre> <p>These primitives provide the flexibility to design multi-agent interactions ranging from tightly coupled sequential workflows to dynamic, LLM-driven delegation networks.</p>"},{"location":"agents/multi-agents/#3-common-multi-agent-patterns-using-adk-primitives","title":"3. Common Multi-Agent Patterns using ADK Primitives","text":"<p>By combining ADK's composition primitives, you can implement various established patterns for multi-agent collaboration.</p>"},{"location":"agents/multi-agents/#coordinatordispatcher-pattern","title":"Coordinator/Dispatcher Pattern","text":"<ul> <li>Structure: A central <code>LlmAgent</code> (Coordinator) manages several specialized <code>sub_agents</code>.</li> <li>Goal: Route incoming requests to the appropriate specialist agent.</li> <li>ADK Primitives Used:<ul> <li>Hierarchy: Coordinator has specialists listed in <code>sub_agents</code>.</li> <li>Interaction: Primarily uses LLM-Driven Delegation (requires clear <code>description</code>s on sub-agents and appropriate <code>instruction</code> on Coordinator) or Explicit Invocation (<code>AgentTool</code>) (Coordinator includes <code>AgentTool</code>-wrapped specialists in its <code>tools</code>).</li> </ul> </li> </ul> <pre><code># Conceptual Code: Coordinator using LLM Transfer\nfrom google.adk.agents import LlmAgent\n\nbilling_agent = LlmAgent(name=\"Billing\", description=\"Handles billing inquiries.\")\nsupport_agent = LlmAgent(name=\"Support\", description=\"Handles technical support requests.\")\n\ncoordinator = LlmAgent(\n    name=\"HelpDeskCoordinator\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\",\n    description=\"Main help desk router.\",\n    # allow_transfer=True is often implicit with sub_agents in AutoFlow\n    sub_agents=[billing_agent, support_agent]\n)\n# User asks \"My payment failed\" -&gt; Coordinator's LLM should call transfer_to_agent(agent_name='Billing')\n# User asks \"I can't log in\" -&gt; Coordinator's LLM should call transfer_to_agent(agent_name='Support')\n</code></pre>"},{"location":"agents/multi-agents/#sequential-pipeline-pattern","title":"Sequential Pipeline Pattern","text":"<ul> <li>Structure: A <code>SequentialAgent</code> contains <code>sub_agents</code> executed in a fixed order.</li> <li>Goal: Implement a multi-step process where the output of one step feeds into the next.</li> <li>ADK Primitives Used:<ul> <li>Workflow: <code>SequentialAgent</code> defines the order.</li> <li>Communication: Primarily uses Shared Session State. Earlier agents write results (often via <code>output_key</code>), later agents read those results from <code>context.state</code>.</li> </ul> </li> </ul> <pre><code># Conceptual Code: Sequential Data Pipeline\nfrom google.adk.agents import SequentialAgent, LlmAgent\n\nvalidator = LlmAgent(name=\"ValidateInput\", instruction=\"Validate the input.\", output_key=\"validation_status\")\nprocessor = LlmAgent(name=\"ProcessData\", instruction=\"Process data if state key 'validation_status' is 'valid'.\", output_key=\"result\")\nreporter = LlmAgent(name=\"ReportResult\", instruction=\"Report the result from state key 'result'.\")\n\ndata_pipeline = SequentialAgent(\n    name=\"DataPipeline\",\n    sub_agents=[validator, processor, reporter]\n)\n# validator runs -&gt; saves to state['validation_status']\n# processor runs -&gt; reads state['validation_status'], saves to state['result']\n# reporter runs -&gt; reads state['result']\n</code></pre>"},{"location":"agents/multi-agents/#parallel-fan-outgather-pattern","title":"Parallel Fan-Out/Gather Pattern","text":"<ul> <li>Structure: A <code>ParallelAgent</code> runs multiple <code>sub_agents</code> concurrently, often followed by a later agent (in a <code>SequentialAgent</code>) that aggregates results.</li> <li>Goal: Execute independent tasks simultaneously to reduce latency, then combine their outputs.</li> <li>ADK Primitives Used:<ul> <li>Workflow: <code>ParallelAgent</code> for concurrent execution (Fan-Out). Often nested within a <code>SequentialAgent</code> to handle the subsequent aggregation step (Gather).</li> <li>Communication: Sub-agents write results to distinct keys in Shared Session State. The subsequent \"Gather\" agent reads multiple state keys.</li> </ul> </li> </ul> <pre><code># Conceptual Code: Parallel Information Gathering\nfrom google.adk.agents import SequentialAgent, ParallelAgent, LlmAgent\n\nfetch_api1 = LlmAgent(name=\"API1Fetcher\", instruction=\"Fetch data from API 1.\", output_key=\"api1_data\")\nfetch_api2 = LlmAgent(name=\"API2Fetcher\", instruction=\"Fetch data from API 2.\", output_key=\"api2_data\")\n\ngather_concurrently = ParallelAgent(\n    name=\"ConcurrentFetch\",\n    sub_agents=[fetch_api1, fetch_api2]\n)\n\nsynthesizer = LlmAgent(\n    name=\"Synthesizer\",\n    instruction=\"Combine results from state keys 'api1_data' and 'api2_data'.\"\n)\n\noverall_workflow = SequentialAgent(\n    name=\"FetchAndSynthesize\",\n    sub_agents=[gather_concurrently, synthesizer] # Run parallel fetch, then synthesize\n)\n# fetch_api1 and fetch_api2 run concurrently, saving to state.\n# synthesizer runs afterwards, reading state['api1_data'] and state['api2_data'].\n</code></pre>"},{"location":"agents/multi-agents/#hierarchical-task-decomposition","title":"Hierarchical Task Decomposition","text":"<ul> <li>Structure: A multi-level tree of agents where higher-level agents break down complex goals and delegate sub-tasks to lower-level agents.</li> <li>Goal: Solve complex problems by recursively breaking them down into simpler, executable steps.</li> <li>ADK Primitives Used:<ul> <li>Hierarchy: Multi-level <code>parent_agent</code>/<code>sub_agents</code> structure.</li> <li>Interaction: Primarily LLM-Driven Delegation or Explicit Invocation (<code>AgentTool</code>) used by parent agents to assign tasks to children. Results are returned up the hierarchy (via tool responses or state).</li> </ul> </li> </ul> <pre><code># Conceptual Code: Hierarchical Research Task\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools import agent_tool\n\n# Low-level tool-like agents\nweb_searcher = LlmAgent(name=\"WebSearch\", description=\"Performs web searches for facts.\")\nsummarizer = LlmAgent(name=\"Summarizer\", description=\"Summarizes text.\")\n\n# Mid-level agent combining tools\nresearch_assistant = LlmAgent(\n    name=\"ResearchAssistant\",\n    model=\"gemini-2.0-flash\",\n    description=\"Finds and summarizes information on a topic.\",\n    tools=[agent_tool.AgentTool(agent=web_searcher), agent_tool.AgentTool(agent=summarizer)]\n)\n\n# High-level agent delegating research\nreport_writer = LlmAgent(\n    name=\"ReportWriter\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"Write a report on topic X. Use the ResearchAssistant to gather information.\",\n    tools=[agent_tool.AgentTool(agent=research_assistant)]\n    # Alternatively, could use LLM Transfer if research_assistant is a sub_agent\n)\n# User interacts with ReportWriter.\n# ReportWriter calls ResearchAssistant tool.\n# ResearchAssistant calls WebSearch and Summarizer tools.\n# Results flow back up.\n</code></pre>"},{"location":"agents/multi-agents/#reviewcritique-pattern-generator-critic","title":"Review/Critique Pattern (Generator-Critic)","text":"<ul> <li>Structure: Typically involves two agents within a <code>SequentialAgent</code>: a Generator and a Critic/Reviewer.</li> <li>Goal: Improve the quality or validity of generated output by having a dedicated agent review it.</li> <li>ADK Primitives Used:<ul> <li>Workflow: <code>SequentialAgent</code> ensures generation happens before review.</li> <li>Communication: Shared Session State (Generator uses <code>output_key</code> to save output; Reviewer reads that state key). The Reviewer might save its feedback to another state key for subsequent steps.</li> </ul> </li> </ul> <pre><code># Conceptual Code: Generator-Critic\nfrom google.adk.agents import SequentialAgent, LlmAgent\n\ngenerator = LlmAgent(\n    name=\"DraftWriter\",\n    instruction=\"Write a short paragraph about subject X.\",\n    output_key=\"draft_text\"\n)\n\nreviewer = LlmAgent(\n    name=\"FactChecker\",\n    instruction=\"Review the text in state key 'draft_text' for factual accuracy. Output 'valid' or 'invalid' with reasons.\",\n    output_key=\"review_status\"\n)\n\n# Optional: Further steps based on review_status\n\nreview_pipeline = SequentialAgent(\n    name=\"WriteAndReview\",\n    sub_agents=[generator, reviewer]\n)\n# generator runs -&gt; saves draft to state['draft_text']\n# reviewer runs -&gt; reads state['draft_text'], saves status to state['review_status']\n</code></pre>"},{"location":"agents/multi-agents/#iterative-refinement-pattern","title":"Iterative Refinement Pattern","text":"<ul> <li>Structure: Uses a <code>LoopAgent</code> containing one or more agents that work on a task over multiple iterations.</li> <li>Goal: Progressively improve a result (e.g., code, text, plan) stored in the session state until a quality threshold is met or a maximum number of iterations is reached.</li> <li>ADK Primitives Used:<ul> <li>Workflow: <code>LoopAgent</code> manages the repetition.</li> <li>Communication: Shared Session State is essential for agents to read the previous iteration's output and save the refined version.</li> <li>Termination: The loop typically ends based on <code>max_iterations</code> or a dedicated checking agent setting <code>actions.escalate=True</code> when the result is satisfactory.</li> </ul> </li> </ul> <pre><code># Conceptual Code: Iterative Code Refinement\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\nfrom google.adk.events import Event, EventActions\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom typing import AsyncGenerator\n\n# Agent to generate/refine code based on state['current_code'] and state['requirements']\ncode_refiner = LlmAgent(\n    name=\"CodeRefiner\",\n    instruction=\"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Python code to meet requirements. Save to state['current_code'].\",\n    output_key=\"current_code\" # Overwrites previous code in state\n)\n\n# Agent to check if the code meets quality standards\nquality_checker = LlmAgent(\n    name=\"QualityChecker\",\n    instruction=\"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\",\n    output_key=\"quality_status\"\n)\n\n# Custom agent to check the status and escalate if 'pass'\nclass CheckStatusAndEscalate(BaseAgent):\n    async def _run_async_impl(self, ctx: InvocationContext) -&gt; AsyncGenerator[Event, None]:\n        status = ctx.session.state.get(\"quality_status\", \"fail\")\n        should_stop = (status == \"pass\")\n        yield Event(author=self.name, actions=EventActions(escalate=should_stop))\n\nrefinement_loop = LoopAgent(\n    name=\"CodeRefinementLoop\",\n    max_iterations=5,\n    sub_agents=[code_refiner, quality_checker, CheckStatusAndEscalate(name=\"StopChecker\")]\n)\n# Loop runs: Refiner -&gt; Checker -&gt; StopChecker\n# State['current_code'] is updated each iteration.\n# Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 iterations.\n</code></pre>"},{"location":"agents/multi-agents/#human-in-the-loop-pattern","title":"Human-in-the-Loop Pattern","text":"<ul> <li>Structure: Integrates human intervention points within an agent workflow.</li> <li>Goal: Allow for human oversight, approval, correction, or tasks that AI cannot perform.</li> <li>ADK Primitives Used (Conceptual):<ul> <li>Interaction: Can be implemented using a custom Tool that pauses execution and sends a request to an external system (e.g., a UI, ticketing system) waiting for human input. The tool then returns the human's response to the agent.</li> <li>Workflow: Could use LLM-Driven Delegation (<code>transfer_to_agent</code>) targeting a conceptual \"Human Agent\" that triggers the external workflow, or use the custom tool within an <code>LlmAgent</code>.</li> <li>State/Callbacks: State can hold task details for the human; callbacks can manage the interaction flow.</li> <li>Note: ADK doesn't have a built-in \"Human Agent\" type, so this requires custom integration.</li> </ul> </li> </ul> <pre><code># Conceptual Code: Using a Tool for Human Approval\nfrom google.adk.agents import LlmAgent, SequentialAgent\nfrom google.adk.tools import FunctionTool\n\n# --- Assume external_approval_tool exists ---\n# This tool would:\n# 1. Take details (e.g., request_id, amount, reason).\n# 2. Send these details to a human review system (e.g., via API).\n# 3. Poll or wait for the human response (approved/rejected).\n# 4. Return the human's decision.\n# async def external_approval_tool(amount: float, reason: str) -&gt; str: ...\napproval_tool = FunctionTool(func=external_approval_tool)\n\n# Agent that prepares the request\nprepare_request = LlmAgent(\n    name=\"PrepareApproval\",\n    instruction=\"Prepare the approval request details based on user input. Store amount and reason in state.\",\n    # ... likely sets state['approval_amount'] and state['approval_reason'] ...\n)\n\n# Agent that calls the human approval tool\nrequest_approval = LlmAgent(\n    name=\"RequestHumanApproval\",\n    instruction=\"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\",\n    tools=[approval_tool],\n    output_key=\"human_decision\"\n)\n\n# Agent that proceeds based on human decision\nprocess_decision = LlmAgent(\n    name=\"ProcessDecision\",\n    instruction=\"Check state key 'human_decision'. If 'approved', proceed. If 'rejected', inform user.\"\n)\n\napproval_workflow = SequentialAgent(\n    name=\"HumanApprovalWorkflow\",\n    sub_agents=[prepare_request, request_approval, process_decision]\n)\n</code></pre> <p>These patterns provide starting points for structuring your multi-agent systems. You can mix and match them as needed to create the most effective architecture for your specific application.</p>"},{"location":"agents/workflow-agents/","title":"Workflow Agents","text":"<p>This section introduces \"workflow agents\" - specialized agents that control the execution flow of its sub-agents.  </p> <p>Workflow agents are specialized components in ADK designed purely for orchestrating the execution flow of sub-agents. Their primary role is to manage how and when other agents run, defining the control flow of a process.</p> <p>Unlike LLM Agents, which use Large Language Models for dynamic reasoning and decision-making, Workflow Agents operate based on predefined logic. They determine the execution sequence according to their type (e.g., sequential, parallel, loop) without consulting an LLM for the orchestration itself. This results in deterministic and predictable execution patterns.</p> <p>ADK provides three core workflow agent types, each implementing a distinct execution pattern:</p> <ul> <li> <p> Sequential Agents</p> <p>Executes sub-agents one after another, in sequence.</p> <p> Learn more</p> </li> <li> <p> Loop Agents</p> <p>Repeatedly executes its sub-agents until a specific termination condition is met.</p> <p> Learn more</p> </li> <li> <p> Parallel Agents</p> <p>Executes multiple sub-agents in parallel.</p> <p> Learn more</p> </li> </ul>"},{"location":"agents/workflow-agents/#why-use-workflow-agents","title":"Why Use Workflow Agents?","text":"<p>Workflow agents are essential when you need explicit control over how a series of tasks or agents are executed. They provide:</p> <ul> <li>Predictability: The flow of execution is guaranteed based on the agent type and configuration.</li> <li>Reliability: Ensures tasks run in the required order or pattern consistently.</li> <li>Structure: Allows you to build complex processes by composing agents within clear control structures.</li> </ul> <p>While the workflow agent manages the control flow deterministically, the sub-agents it orchestrates can themselves be any type of agent, including intelligent <code>LlmAgent</code> instances. This allows you to combine structured process control with flexible, LLM-powered task execution.</p>"},{"location":"agents/workflow-agents/loop-agents/","title":"Loop agents","text":""},{"location":"agents/workflow-agents/loop-agents/#the-loopagent","title":"The <code>LoopAgent</code>","text":"<p>The <code>LoopAgent</code> is a workflow agent that executes its sub-agents in a loop (i.e. iteratively). It repeatedly runs a sequence of agents for a specified number of iterations or until a termination condition is met.</p> <p>Use the <code>LoopAgent</code> when your workflow involves repetition or iterative refinement, such as like revising code.</p>"},{"location":"agents/workflow-agents/loop-agents/#example","title":"Example","text":"<ul> <li>You want to build an agent that can generate images of food, but sometimes when you want to generate a specific number of items (e.g. 5 bananas), it generates a different number of those items in the image (e.g. an image of 7 bananas). You have two tools: <code>generate_image</code>, <code>count_food_items</code>. Because you want to keep generating images until it either correctly generates the specified number of items, or after a certain number of iterations, you should build your agent using a <code>LoopAgent</code>.</li> </ul> <p>As with other workflow agents, the <code>LoopAgent</code> is not powered by an LLM, and is thus deterministic in how it executes. That being said, workflow agents are only concerned only with their execution (i.e. in a loop), and not their internal logic; the tools or sub-agents of a workflow agent may or may not utilize LLMs.</p>"},{"location":"agents/workflow-agents/loop-agents/#how-it-works","title":"How it Works","text":"<p>When the <code>LoopAgent</code>'s <code>run_async()</code> method is called, it performs the following actions:</p> <ol> <li>Sub-Agent Execution:  It iterates through the <code>sub_agents</code> list in order. For each sub-agent, it calls the agent's <code>run_async()</code> method.</li> <li> <p>Termination Check:</p> <p>Crucially, the <code>LoopAgent</code> itself does not inherently decide when to stop looping. You must implement a termination mechanism to prevent infinite loops.  Common strategies include:</p> <ul> <li><code>max_iterations</code>: Set a maximum number of iterations in the <code>LoopAgent</code>. The loop will terminate after that many iterations.</li> <li>Escalation from sub-agent: Design one or more sub-agents to evaluate a condition (e.g., \"Is the document quality good enough?\", \"Has a consensus been reached?\").  If the condition is met, the sub-agent can signal termination (e.g., by raising a custom event, setting a flag in a shared context, or returning a specific value).</li> </ul> </li> </ol> <p></p>"},{"location":"agents/workflow-agents/loop-agents/#full-example-iterative-document-improvement","title":"Full Example: Iterative Document Improvement","text":"<p>Imagine a scenario where you want to iteratively improve a document:</p> <ul> <li>Writer Agent: An <code>LlmAgent</code> that generates or refines a draft on a topic.</li> <li> <p>Critic Agent: An <code>LlmAgent</code> that critiques the draft, identifying areas for improvement.</p> <pre><code>LoopAgent(sub_agents=[WriterAgent, CriticAgent], max_iterations=5)\n</code></pre> </li> </ul> <p>In this setup, the <code>LoopAgent</code> would manage the iterative process.  The <code>CriticAgent</code> could be designed to return a \"STOP\" signal when the document reaches a satisfactory quality level, preventing further iterations. Alternatively, the <code>max_iterations</code> parameter could be used to limit the process to a fixed number of cycles, or external logic could be implemented to make stop decisions. The loop would run at most five times, ensuring the iterative refinement doesn't continue indefinitely.</p> Full Code <pre><code>\n</code></pre>"},{"location":"agents/workflow-agents/parallel-agents/","title":"Parallel agents","text":""},{"location":"agents/workflow-agents/parallel-agents/#the-parallelagent","title":"The <code>ParallelAgent</code>","text":"<p>The <code>ParallelAgent</code> is a workflow agent that executes its sub-agents concurrently. This dramatically speeds up workflows where tasks can be performed independently.</p> <p>Use <code>ParallelAgent</code> when: For scenarios prioritizing speed and involving independent, resource-intensive tasks, a <code>ParallelAgent</code> facilitates efficient parallel execution. When sub-agents operate without dependencies, their tasks can be performed concurrently, significantly reducing overall processing time.</p> <p>As with other workflow agents, the <code>ParallelAgent</code> is not powered by an LLM, and is thus deterministic in how it executes. That being said, workflow agents are only concerned only with their execution (i.e. in parallel), and not their internal logic; the tools or sub-agents of a workflow agent may or may not utilize LLMs.</p>"},{"location":"agents/workflow-agents/parallel-agents/#example","title":"Example","text":"<p>This approach is particularly beneficial for operations like multi-source data retrieval or heavy computations, where parallelization yields substantial performance gains. Importantly, this strategy assumes no inherent need for shared state or direct information exchange between the concurrently executing agents.</p>"},{"location":"agents/workflow-agents/parallel-agents/#how-it-works","title":"How it works","text":"<p>When the <code>ParallelAgent</code>'s <code>run_async()</code> method is called:</p> <ol> <li>Concurrent Execution: It initiates the <code>run()</code> method of each sub-agent present in the <code>sub_agents</code> list concurrently.  This means all the agents start running at (approximately) the same time.</li> <li>Independent Branches:  Each sub-agent operates in its own execution branch.  There is no automatic sharing of conversation history or state between these branches during execution.</li> <li>Result Collection: The <code>ParallelAgent</code> manages the parallel execution and, typically, provides a way to access the results from each sub-agent after they have completed (e.g., through a list of results or events). The order of results may not be deterministic.</li> </ol>"},{"location":"agents/workflow-agents/parallel-agents/#independent-execution-and-state-management","title":"Independent Execution and State Management","text":"<p>It's crucial to understand that sub-agents within a <code>ParallelAgent</code> run independently.  If you need communication or data sharing between these agents, you must implement it explicitly.  Possible approaches include:</p> <ul> <li>Shared <code>InvocationContext</code>: You could pass a shared <code>InvocationContext</code> object to each sub-agent.  This object could act as a shared data store.  However, you'd need to manage concurrent access to this shared context carefully (e.g., using locks) to avoid race conditions.</li> <li>External State Management:  Use an external database, message queue, or other mechanism to manage shared state and facilitate communication between agents.</li> <li>Post-Processing: Collect results from each branch, and then implement logic to coordinate data afterwards.</li> </ul> <p></p>"},{"location":"agents/workflow-agents/parallel-agents/#full-example-parallel-web-research","title":"Full Example: Parallel Web Research","text":"<p>Imagine researching multiple topics simultaneously:</p> <ol> <li>Researcher Agent 1:  An <code>LlmAgent</code> that researches \"renewable energy sources.\"</li> <li>Researcher Agent 2:  An <code>LlmAgent</code> that researches \"electric vehicle technology.\"</li> <li> <p>Researcher Agent 3:  An <code>LlmAgent</code> that researches \"carbon capture methods.\"</p> <pre><code>ParallelAgent(sub_agents=[ResearcherAgent1, ResearcherAgent2, ResearcherAgent3])\n</code></pre> </li> </ol> <p>These research tasks are independent.  Using a <code>ParallelAgent</code> allows them to run concurrently, potentially reducing the total research time significantly compared to running them sequentially. The results from each agent would be collected separately after they finish.</p> Code <pre><code>\n</code></pre>"},{"location":"agents/workflow-agents/sequential-agents/","title":"Sequential agents","text":""},{"location":"agents/workflow-agents/sequential-agents/#the-sequentialagent","title":"The <code>SequentialAgent</code>","text":"<p>The <code>SequentialAgent</code> is a workflow agent that executes its sub-agents in the order they are specified in the list.</p> <p>Use the <code>SequentialAgent</code> when you want the execution to occur in a fixed, strict order.</p>"},{"location":"agents/workflow-agents/sequential-agents/#example","title":"Example","text":"<ul> <li>You want to build an agent that can summarize any webpage, using two tools: <code>get_page_contents</code> and <code>summarize_page</code>. Because the agent must always call <code>get_page_contents</code> before calling <code>summarize_page</code> (you can't summarize from nothing!), you should build your agent using a <code>SequentialAgent</code>.</li> </ul> <p>As with other workflow agents, the <code>SequentialAgent</code> is not powered by an LLM, and is thus deterministic in how it executes. That being said, workflow agents are only concerned only with their execution (i.e. in sequence), and not their internal logic; the tools or sub-agents of a workflow agent may or may not utilize LLMs.</p>"},{"location":"agents/workflow-agents/sequential-agents/#how-it-works","title":"How it works","text":"<p>When the <code>SequentialAgent</code>'s <code>run_async()</code> method is called, it performs the following actions:</p> <ol> <li>Iteration: It iterates through the <code>sub_agents</code> list in the order they were provided.</li> <li>Sub-Agent Execution: For each sub-agent in the list, it calls the sub-agent's <code>run_async()</code> method.</li> </ol> <p></p>"},{"location":"agents/workflow-agents/sequential-agents/#full-example-code-development-pipeline","title":"Full Example: Code Development Pipeline","text":"<p>Consider a simplified code development pipeline:</p> <ul> <li>Code Writer Agent:  An <code>LlmAgent</code> that generates initial code based on a specification.</li> <li>Code Reviewer Agent:  An <code>LlmAgent</code> that reviews the generated code for errors, style issues, and adherence to best practices.  It receives the output of the Code Writer Agent.</li> <li>Code Refactorer Agent: An <code>LlmAgent</code> that takes the reviewed code (and the reviewer's comments) and refactors it to improve quality and address issues.</li> </ul> <p>A <code>SequentialAgent</code> is perfect for this:</p> <pre><code>SequentialAgent(sub_agents=[CodeWriterAgent, CodeReviewerAgent, CodeRefactorerAgent])\n</code></pre> <p>This ensures the code is written, then reviewed, and finally refactored, in a strict, dependable order. The output from each sub-agent is passed to the next by storing them in state via <code>output_key</code>.</p> Code <pre><code>\n</code></pre>"},{"location":"artifacts/","title":"Artifacts","text":"<p>In ADK, Artifacts represent a crucial mechanism for managing named, versioned binary data associated either with a specific user interaction session or persistently with a user across multiple sessions. They allow your agents and tools to handle data beyond simple text strings, enabling richer interactions involving files, images, audio, and other binary formats.</p>"},{"location":"artifacts/#what-are-artifacts","title":"What are Artifacts?","text":"<ul> <li> <p>Definition: An Artifact is essentially a piece of binary data (like the content of a file) identified by a unique <code>filename</code> string within a specific scope (session or user). Each time you save an artifact with the same filename, a new version is created.  </p> </li> <li> <p>Representation: Artifacts are consistently represented using the standard <code>Part</code> object from the ADK TypeScript library. The core data is typically stored within the <code>Part</code> object, which itself contains:  </p> <ul> <li><code>data</code>: The raw binary content as a <code>Uint8Array</code>.  </li> <li><code>mimeType</code>: A string indicating the type of the data (e.g., <code>'image/png'</code>, <code>'application/pdf'</code>). This is essential for correctly interpreting the data later.</li> </ul> <pre><code>// Example of how an artifact might be represented as a Part\nimport { Part } from 'adk-typescript';\n\n// Assume 'imageBytes' contains the binary data of a PNG image\nconst imageBytes = new Uint8Array([0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A]); // Placeholder for actual image bytes\n\nconst imageArtifact: Part = {\n  inlineData: {\n    mimeType: \"image/png\",\n    data: imageBytes\n  }\n};\n\nconsole.log(`Artifact MIME Type: ${imageArtifact.inlineData?.mimeType}`);\nconsole.log(`Artifact Data (first 10 bytes): ${imageArtifact.inlineData?.data.slice(0, 10)}...`);\n</code></pre> </li> <li> <p>Persistence &amp; Management: Artifacts are not stored directly within the agent or session state. Their storage and retrieval are managed by a dedicated Artifact Service (an implementation of <code>BaseArtifactService</code>, defined in the ADK TypeScript library). ADK provides implementations like <code>InMemoryArtifactService</code> (for testing/temporary storage) and cloud storage implementations for persistent storage. The chosen service handles versioning automatically when you save data.</p> </li> </ul>"},{"location":"artifacts/#why-use-artifacts","title":"Why Use Artifacts?","text":"<p>While session <code>state</code> is suitable for storing small pieces of configuration or conversational context (like strings, numbers, booleans, or small objects/arrays), Artifacts are designed for scenarios involving binary or large data:</p> <ol> <li>Handling Non-Textual Data: Easily store and retrieve images, audio clips, video snippets, PDFs, spreadsheets, or any other file format relevant to your agent's function.  </li> <li>Persisting Large Data: Session state is generally not optimized for storing large amounts of data. Artifacts provide a dedicated mechanism for persisting larger blobs without cluttering the session state.  </li> <li>User File Management: Provide capabilities for users to upload files (which can be saved as artifacts) and retrieve or download files generated by the agent (loaded from artifacts).  </li> <li>Sharing Outputs: Enable tools or agents to generate binary outputs (like a PDF report or a generated image) that can be saved via <code>saveArtifact</code> and later accessed by other parts of the application or even in subsequent sessions (if using user namespacing).  </li> <li>Caching Binary Data: Store the results of computationally expensive operations that produce binary data (e.g., rendering a complex chart image) as artifacts to avoid regenerating them on subsequent requests.</li> </ol> <p>In essence, whenever your agent needs to work with file-like binary data that needs to be persisted, versioned, or shared, Artifacts managed by an <code>ArtifactService</code> are the appropriate mechanism within ADK.</p>"},{"location":"artifacts/#common-use-cases","title":"Common Use Cases","text":"<p>Artifacts provide a flexible way to handle binary data within your ADK applications.</p> <p>Here are some typical scenarios where they prove valuable:</p> <ul> <li> <p>Generated Reports/Files:</p> <ul> <li>A tool or agent generates a report (e.g., a PDF analysis, a CSV data export, an image chart).  </li> <li>The tool uses <code>toolContext.saveArtifact(\"monthly_report_oct_2024.pdf\", reportPart)</code> to store the generated file.  </li> <li>The user can later ask the agent to retrieve this report, which might involve another tool using <code>toolContext.loadArtifact(\"monthly_report_oct_2024.pdf\")</code> or listing available reports using <code>toolContext.listArtifacts()</code>.</li> </ul> </li> <li> <p>Handling User Uploads: </p> <ul> <li>A user uploads a file (e.g., an image for analysis, a document for summarization) through a front-end interface.  </li> <li>The application backend receives the file, creates a <code>Part</code> from its bytes and MIME type, and uses the <code>runner.sessionService</code> (or similar mechanism outside a direct agent run) or a dedicated tool/callback within a run via <code>context.saveArtifact</code> to store it, potentially using the <code>user:</code> namespace if it should persist across sessions (e.g., <code>user:uploaded_image.jpg</code>).  </li> <li>An agent can then be prompted to process this uploaded file, using <code>context.loadArtifact(\"user:uploaded_image.jpg\")</code> to retrieve it.</li> </ul> </li> <li> <p>Storing Intermediate Binary Results: </p> <ul> <li>An agent performs a complex multi-step process where one step generates intermediate binary data (e.g., audio synthesis, simulation results).  </li> <li>This data is saved using <code>context.saveArtifact</code> with a temporary or descriptive name (e.g., <code>\"temp_audio_step1.wav\"</code>).  </li> <li>A subsequent agent or tool in the flow (perhaps in a <code>SequentialAgent</code> or triggered later) can load this intermediate artifact using <code>context.loadArtifact</code> to continue the process.</li> </ul> </li> <li> <p>Persistent User Data: </p> <ul> <li>Storing user-specific configuration or data that isn't a simple key-value state.  </li> <li>An agent saves user preferences or a profile picture using <code>context.saveArtifact(\"user:profile_settings.json\", settingsPart)</code> or <code>context.saveArtifact(\"user:avatar.png\", avatarPart)</code>.  </li> <li>These artifacts can be loaded in any future session for that user to personalize their experience.</li> </ul> </li> <li> <p>Caching Generated Binary Content: </p> <ul> <li>An agent frequently generates the same binary output based on certain inputs (e.g., a company logo image, a standard audio greeting).  </li> <li>Before generating, a <code>beforeToolCallback</code> or <code>beforeAgentCallback</code> checks if the artifact exists using <code>context.loadArtifact</code>.  </li> <li>If it exists, the cached artifact is used, skipping the generation step.  </li> <li>If not, the content is generated, and <code>context.saveArtifact</code> is called in an <code>afterToolCallback</code> or <code>afterAgentCallback</code> to cache it for next time.</li> </ul> </li> </ul>"},{"location":"artifacts/#core-concepts","title":"Core Concepts","text":"<p>Understanding artifacts involves grasping a few key components: the service that manages them, the data structure used to hold them, and how they are identified and versioned.</p>"},{"location":"artifacts/#artifact-service-baseartifactservice","title":"Artifact Service (<code>BaseArtifactService</code>)","text":"<ul> <li> <p>Role: The central component responsible for the actual storage and retrieval logic for artifacts. It defines how and where artifacts are persisted.  </p> </li> <li> <p>Interface: Defined by the interface <code>BaseArtifactService</code> in the ADK TypeScript library. Any concrete implementation must provide methods for:  </p> <ul> <li><code>saveArtifact(...) -&gt; number</code>: Stores the artifact data and returns its assigned version number.  </li> <li><code>loadArtifact(...) -&gt; Part | undefined</code>: Retrieves a specific version (or the latest) of an artifact.  </li> <li><code>listArtifactKeys(...) -&gt; string[]</code>: Lists the unique filenames of artifacts within a given scope.  </li> <li><code>deleteArtifact(...) -&gt; Promise&lt;void&gt;</code>: Removes an artifact (and potentially all its versions, depending on implementation).  </li> <li><code>listVersions(...) -&gt; number[]</code>: Lists all available version numbers for a specific artifact filename.</li> </ul> </li> <li> <p>Configuration: You provide an instance of an artifact service (e.g., <code>InMemoryArtifactService</code>) when initializing the <code>Runner</code>. The <code>Runner</code> then makes this service available to agents and tools via the <code>InvocationContext</code>.</p> </li> </ul> <pre><code>import { \n  Runner, \n  InMemoryArtifactService, \n  Agent, \n  InMemorySessionService \n} from 'adk-typescript';\n\n// Example: Configuring the Runner with an Artifact Service\nconst myAgent = new Agent({\n  name: \"artifact_user_agent\", \n  model: \"gemini-2.0-flash\"\n});\nconst artifactService = new InMemoryArtifactService(); // Choose an implementation\nconst sessionService = new InMemorySessionService();\n\nconst runner = new Runner({\n  agent: myAgent,\n  appName: \"my_artifact_app\",\n  sessionService: sessionService,\n  artifactService: artifactService // Provide the service instance here\n});\n// Now, contexts within runs managed by this runner can use artifact methods\n</code></pre>"},{"location":"artifacts/#artifact-data-part","title":"Artifact Data (<code>Part</code>)","text":"<ul> <li> <p>Standard Representation: Artifact content is universally represented using the <code>Part</code> object, the same structure used for parts of LLM messages.  </p> </li> <li> <p>Key Attribute (<code>inlineData</code>): For artifacts, the most relevant attribute is <code>inlineData</code>, which contains:  </p> <ul> <li><code>data</code> (<code>Uint8Array</code>): The raw binary content of the artifact.  </li> <li><code>mimeType</code> (<code>string</code>): A standard MIME type string (e.g., <code>'application/pdf'</code>, <code>'image/png'</code>, <code>'audio/mpeg'</code>) describing the nature of the binary data. This is crucial for correct interpretation when loading the artifact.</li> </ul> </li> <li> <p>Creation: You typically create a <code>Part</code> for an artifact by constructing it with the appropriate <code>inlineData</code> property.</p> </li> </ul> <pre><code>import { Part } from 'adk-typescript';\n\n// Example: Creating an artifact Part from raw bytes\nconst pdfBytes = new Uint8Array([0x25, 0x50, 0x44, 0x46]); // Your raw PDF data (example start bytes)\nconst pdfMimeType = \"application/pdf\";\n\n// Creating the Part object\nconst pdfArtifact: Part = {\n  inlineData: {\n    data: pdfBytes,\n    mimeType: pdfMimeType\n  }\n};\n\nconsole.log(`Created artifact with MIME type: ${pdfArtifact.inlineData?.mimeType}`);\n</code></pre>"},{"location":"artifacts/#filename-string","title":"Filename (<code>string</code>)","text":"<ul> <li>Identifier: A simple string used to name and retrieve an artifact within its specific namespace (see below).  </li> <li>Uniqueness: Filenames must be unique within their scope (either the session or the user namespace).  </li> <li>Best Practice: Use descriptive names, potentially including file extensions (e.g., <code>\"monthly_report.pdf\"</code>, <code>\"user_avatar.jpg\"</code>), although the extension itself doesn't dictate behavior \u2013 the <code>mimeType</code> does.</li> </ul>"},{"location":"artifacts/#versioning-number","title":"Versioning (<code>number</code>)","text":"<ul> <li>Automatic Versioning: The artifact service automatically handles versioning. When you call <code>saveArtifact</code>, the service determines the next available version number (typically starting from 0 and incrementing) for that specific filename and scope.  </li> <li>Returned by <code>saveArtifact</code>: The <code>saveArtifact</code> method returns the integer version number that was assigned to the newly saved artifact.  </li> <li>Retrieval: </li> <li><code>loadArtifact(..., version=undefined)</code> (default): Retrieves the latest available version of the artifact.  </li> <li><code>loadArtifact(..., version=N)</code>: Retrieves the specific version <code>N</code>.  </li> <li>Listing Versions: The <code>listVersions</code> method (on the service, not context) can be used to find all existing version numbers for an artifact.</li> </ul>"},{"location":"artifacts/#namespacing-session-vs-user","title":"Namespacing (Session vs. User)","text":"<ul> <li> <p>Concept: Artifacts can be scoped either to a specific session or more broadly to a user across all their sessions within the application. This scoping is determined by the <code>filename</code> format and handled internally by the <code>ArtifactService</code>.  </p> </li> <li> <p>Default (Session Scope): If you use a plain filename like <code>\"report.pdf\"</code>, the artifact is associated with the specific <code>appName</code>, <code>userId</code>, and <code>sessionId</code>. It's only accessible within that exact session context.  </p> </li> <li> <p>Internal Path (Example): <code>appName/userId/sessionId/report.pdf/&lt;version&gt;</code> (as managed by the artifact service implementation)</p> </li> <li> <p>User Scope (<code>\"user:\"</code> prefix): If you prefix the filename with <code>\"user:\"</code>, like <code>\"user:profile.png\"</code>, the artifact is associated only with the <code>appName</code> and <code>userId</code>. It can be accessed or updated from any session belonging to that user within the app.  </p> </li> <li> <p>Internal Path (Example): <code>appName/userId/user/user:profile.png/&lt;version&gt;</code> (The <code>user:</code> prefix is often kept in the final path segment for clarity, as seen in the service implementations).  </p> </li> <li>Use Case: Ideal for data that belongs to the user themselves, independent of a specific conversation, such as profile pictures, user preferences files, or long-term reports.</li> </ul> <pre><code>// Example illustrating namespace difference (conceptual)\n\n// Session-specific artifact filename\nconst sessionReportFilename = \"summary.txt\";\n\n// User-specific artifact filename\nconst userConfigFilename = \"user:settings.json\";\n\n// When saving 'summary.txt', it's tied to the current session ID.\n// When saving 'user:settings.json', it's tied only to the user ID.\n</code></pre> <p>These core concepts work together to provide a flexible system for managing binary data within the ADK framework.</p>"},{"location":"artifacts/#interacting-with-artifacts-via-context-objects","title":"Interacting with Artifacts (via Context Objects)","text":"<p>The primary way you interact with artifacts within your agent's logic (specifically within callbacks or tools) is through methods provided by the <code>CallbackContext</code> and <code>ToolContext</code> objects. These methods abstract away the underlying storage details managed by the <code>ArtifactService</code>.</p>"},{"location":"artifacts/#prerequisite-configuring-the-artifactservice","title":"Prerequisite: Configuring the <code>ArtifactService</code>","text":"<p>Before you can use any artifact methods via the context objects, you must provide an instance of a <code>BaseArtifactService</code> implementation (like <code>InMemoryArtifactService</code>) when initializing your <code>Runner</code>.</p> <pre><code>import { \n  Runner, \n  InMemoryArtifactService, \n  Agent, \n  InMemorySessionService \n} from 'adk-typescript';\n\n// Your agent definition\nconst agent = new Agent({\n  name: \"my_agent\", \n  model: \"gemini-2.0-flash\"\n});\n\n// Instantiate the desired artifact service\nconst artifactService = new InMemoryArtifactService();\n\n// Provide it to the Runner\nconst runner = new Runner({\n  agent: agent,\n  appName: \"artifact_app\",\n  sessionService: new InMemorySessionService(),\n  artifactService: artifactService // Service must be provided here\n});\n</code></pre> <p>If no <code>artifactService</code> is configured in the <code>InvocationContext</code> (which happens if it's not passed to the <code>Runner</code>), calling <code>saveArtifact</code>, <code>loadArtifact</code>, or <code>listArtifacts</code> on the context objects will raise an error.</p>"},{"location":"artifacts/#accessing-methods","title":"Accessing Methods","text":"<p>The artifact interaction methods are available directly on instances of <code>CallbackContext</code> (passed to agent and model callbacks) and <code>ToolContext</code> (passed to tool callbacks). Remember that <code>ToolContext</code> inherits from <code>CallbackContext</code>.</p>"},{"location":"artifacts/#saving-artifacts","title":"Saving Artifacts","text":"<ul> <li>Method:</li> </ul> <pre><code>context.saveArtifact(filename: string, artifact: Part): number\n</code></pre> <ul> <li> <p>Available Contexts: <code>CallbackContext</code>, <code>ToolContext</code>.  </p> </li> <li> <p>Action: </p> <ol> <li>Takes a <code>filename</code> string (which may include the <code>\"user:\"</code> prefix for user-scoping) and a <code>Part</code> object containing the artifact data (usually in <code>artifact.inlineData</code>).  </li> <li>Passes this information to the underlying <code>artifactService.saveArtifact</code>.  </li> <li>The service stores the data, assigns the next available version number for that filename and scope.  </li> <li>Crucially, the context automatically records this action by adding an entry to the current event's artifact delta tracking. This delta maps the <code>filename</code> to the newly assigned <code>version</code>.</li> </ol> </li> <li> <p>Returns: The integer <code>version</code> number assigned to the saved artifact.  </p> </li> <li> <p>Code Example (within a hypothetical tool or callback):</p> </li> </ul> <pre><code>import { Part, CallbackContext } from 'adk-typescript'; // Or ToolContext\n\nasync function saveGeneratedReport(context: CallbackContext, reportBytes: Uint8Array): Promise&lt;void&gt; {\n  /**\n   * Saves generated PDF report bytes as an artifact.\n   */\n  const reportArtifact: Part = {\n    inlineData: {\n      data: reportBytes,\n      mimeType: \"application/pdf\"\n    }\n  };\n  const filename = \"generated_report.pdf\";\n\n  try {\n    const version = context.saveArtifact(filename, reportArtifact);\n    console.log(`Successfully saved artifact '${filename}' as version ${version}.`);\n    // The event generated after this callback will contain artifact delta information\n  } catch (e) {\n    if (e instanceof Error) {\n      console.log(`Error saving artifact: ${e.message}. Is ArtifactService configured?`);\n    } else {\n      // Handle potential storage errors\n      console.log(`An unexpected error occurred during artifact save: ${e}`);\n    }\n  }\n}\n\n// --- Example Usage Concept ---\n// const reportData = new Uint8Array([...]); // Assume this holds the PDF bytes\n// await saveGeneratedReport(callbackContext, reportData);\n</code></pre>"},{"location":"artifacts/#loading-artifacts","title":"Loading Artifacts","text":"<ul> <li>Method:</li> </ul> <pre><code>context.loadArtifact(filename: string, version?: number): Part | undefined\n</code></pre> <ul> <li> <p>Available Contexts: <code>CallbackContext</code>, <code>ToolContext</code>.  </p> </li> <li> <p>Action: </p> <ol> <li>Takes a <code>filename</code> string (potentially including <code>\"user:\"</code>).  </li> <li>Optionally takes a number <code>version</code>. If <code>version</code> is <code>undefined</code> (the default), it requests the latest version from the service. If a specific number is provided, it requests that exact version.  </li> <li>Calls the underlying <code>artifactService.loadArtifact</code>.  </li> <li>The service attempts to retrieve the specified artifact.</li> </ol> </li> <li> <p>Returns: A <code>Part</code> object containing the artifact data if found, or <code>undefined</code> if the artifact (or the specified version) does not exist.  </p> </li> <li> <p>Code Example (within a hypothetical tool or callback):</p> </li> </ul> <pre><code>import { Part, CallbackContext } from 'adk-typescript'; // Or ToolContext\n\nasync function processLatestReport(context: CallbackContext): Promise&lt;void&gt; {\n  /**\n   * Loads the latest report artifact and processes its data.\n   */\n  const filename = \"generated_report.pdf\";\n  try {\n    // Load the latest version\n    const reportArtifact = context.loadArtifact(filename);\n\n    if (reportArtifact &amp;&amp; reportArtifact.inlineData) {\n      console.log(`Successfully loaded latest artifact '${filename}'.`);\n      console.log(`MIME Type: ${reportArtifact.inlineData.mimeType}`);\n      // Process the reportArtifact.inlineData.data (Uint8Array)\n      const pdfBytes = reportArtifact.inlineData.data;\n      console.log(`Report size: ${pdfBytes.length} bytes.`);\n      // ... further processing ...\n    } else {\n      console.log(`Artifact '${filename}' not found.`);\n    }\n\n    // Example: Load a specific version (if version 0 exists)\n    // const specificVersionArtifact = context.loadArtifact(filename, 0);\n    // if (specificVersionArtifact) {\n    //   console.log(`Loaded version 0 of '${filename}'.`);\n    // }\n\n  } catch (e) {\n    if (e instanceof Error) {\n      console.log(`Error loading artifact: ${e.message}. Is ArtifactService configured?`);\n    } else {\n      // Handle potential storage errors\n      console.log(`An unexpected error occurred during artifact load: ${e}`);\n    }\n  }\n}\n\n// --- Example Usage Concept ---\n// await processLatestReport(callbackContext);\n</code></pre>"},{"location":"artifacts/#listing-artifact-filenames-tool-context-only","title":"Listing Artifact Filenames (Tool Context Only)","text":"<ul> <li>Method:</li> </ul> <pre><code>toolContext.listArtifacts(): string[]\n</code></pre> <ul> <li> <p>Available Context: <code>ToolContext</code> only. This method is not available on the base <code>CallbackContext</code>.  </p> </li> <li> <p>Action: Calls the underlying <code>artifactService.listArtifactKeys</code> to get a list of all unique artifact filenames accessible within the current scope (including both session-specific files and user-scoped files prefixed with <code>\"user:\"</code>).  </p> </li> <li> <p>Returns: A sorted <code>string[]</code> of filenames.  </p> </li> <li> <p>Code Example (within a tool function):</p> </li> </ul> <pre><code>import { ToolContext } from 'adk-typescript';\n\nfunction listUserFiles(toolContext: ToolContext): string {\n  /**\n   * Tool to list available artifacts for the user.\n   */\n  try {\n    const availableFiles = toolContext.listArtifacts();\n    if (!availableFiles.length) {\n      return \"You have no saved artifacts.\";\n    } else {\n      // Format the list for the user/LLM\n      const fileListStr = availableFiles.map(fname =&gt; `- ${fname}`).join('\\n');\n      return `Here are your available artifacts:\\n${fileListStr}`;\n    }\n  } catch (e) {\n    if (e instanceof Error) {\n      console.log(`Error listing artifacts: ${e.message}. Is ArtifactService configured?`);\n      return \"Error: Could not list artifacts.\";\n    } else {\n      console.log(`An unexpected error occurred during artifact list: ${e}`);\n      return \"Error: An unexpected error occurred while listing artifacts.\";\n    }\n  }\n}\n\n// This function would typically be wrapped in a FunctionTool\n// import { FunctionTool } from 'adk-typescript';\n// const listFilesTool = new FunctionTool({ func: listUserFiles });\n</code></pre> <p>These context methods provide a convenient and consistent way to manage binary data persistence within ADK, regardless of the chosen backend storage implementation (<code>InMemoryArtifactService</code> or other cloud storage services).</p>"},{"location":"artifacts/#available-implementations","title":"Available Implementations","text":"<p>ADK provides concrete implementations of the <code>BaseArtifactService</code> interface, offering different storage backends suitable for various development stages and deployment needs. These implementations handle the details of storing, versioning, and retrieving artifact data based on the <code>appName</code>, <code>userId</code>, <code>sessionId</code>, and <code>filename</code> (including the <code>user:</code> namespace prefix).</p>"},{"location":"artifacts/#inmemoryartifactservice","title":"InMemoryArtifactService","text":"<ul> <li>Source: Imported from <code>adk-typescript</code>.  </li> <li>Storage Mechanism: Uses a JavaScript Map held in the application's memory to store artifacts. The Map keys represent the artifact path (incorporating app, user, session/user-scope, and filename), and the values are arrays of <code>Part</code>, where each element in the array corresponds to a version (index 0 is version 0, index 1 is version 1, etc.).  </li> <li>Key Features: <ul> <li>Simplicity: Requires no external setup or dependencies beyond the core ADK library.  </li> <li>Speed: Operations are typically very fast as they involve in-memory Map lookups and array manipulations.  </li> <li>Ephemeral: All stored artifacts are lost when the Node.js process running the application terminates. Data does not persist between application restarts.  </li> </ul> </li> <li>Use Cases: <ul> <li>Ideal for local development and testing where persistence is not required.  </li> <li>Suitable for short-lived demonstrations or scenarios where artifact data is purely temporary within a single run of the application.  </li> </ul> </li> <li>Instantiation:</li> </ul> <pre><code>import { InMemoryArtifactService, Runner } from 'adk-typescript';\n\n// Simply instantiate the class\nconst inMemoryService = new InMemoryArtifactService();\n\n// Then pass it to the Runner\n// const runner = new Runner({\n//   ...\n//   artifactService: inMemoryService\n// });\n</code></pre> <p>Choosing the appropriate <code>ArtifactService</code> implementation depends on your application's requirements for data persistence, scalability, and operational environment.</p>"},{"location":"artifacts/#best-practices","title":"Best Practices","text":"<p>To use artifacts effectively and maintainably:</p> <ul> <li>Choose the Right Service: Use <code>InMemoryArtifactService</code> for rapid prototyping, testing, and scenarios where persistence isn't needed. Use cloud storage implementations (or implement your own <code>BaseArtifactService</code> for other backends) for production environments requiring data persistence and scalability.  </li> <li>Meaningful Filenames: Use clear, descriptive filenames. Including relevant extensions (<code>.pdf</code>, <code>.png</code>, <code>.wav</code>) helps humans understand the content, even though the <code>mimeType</code> dictates programmatic handling. Establish conventions for temporary vs. persistent artifact names.  </li> <li>Specify Correct MIME Types: Always provide an accurate <code>mimeType</code> when creating the <code>Part</code> for <code>saveArtifact</code>. This is critical for applications or tools that later <code>loadArtifact</code> to interpret the binary data correctly. Use standard IANA MIME types where possible.  </li> <li>Understand Versioning: Remember that <code>loadArtifact()</code> without a specific <code>version</code> argument retrieves the latest version. If your logic depends on a specific historical version of an artifact, be sure to provide the integer version number when loading.  </li> <li>Use Namespacing (<code>user:</code>) Deliberately: Only use the <code>\"user:\"</code> prefix for filenames when the data truly belongs to the user and should be accessible across all their sessions. For data specific to a single conversation or session, use regular filenames without the prefix.  </li> <li>Error Handling: <ul> <li>Always check if an <code>artifactService</code> is actually configured before calling context methods (<code>saveArtifact</code>, <code>loadArtifact</code>, <code>listArtifacts</code>) \u2013 they will raise an error if the service is not configured. Use proper try/catch blocks.  </li> <li>Check the return value of <code>loadArtifact</code>, as it will be <code>undefined</code> if the artifact or version doesn't exist. Don't assume it always returns a <code>Part</code>.  </li> <li>Be prepared to handle exceptions from the underlying storage service, especially with cloud storage services (permission issues, bucket not existing, network errors).  </li> </ul> </li> <li>Size Considerations: Artifacts are suitable for typical file sizes, but be mindful of potential costs and performance impacts with extremely large files, especially with cloud storage. <code>InMemoryArtifactService</code> can consume significant memory if storing many large artifacts. Evaluate if very large data might be better handled through direct cloud storage links or other specialized storage solutions rather than passing entire binary arrays in-memory.  </li> <li>Cleanup Strategy: For persistent storage like cloud storage services, artifacts remain until explicitly deleted. If artifacts represent temporary data or have a limited lifespan, implement a strategy for cleanup. This might involve:  <ul> <li>Using storage lifecycle policies on the bucket or container.  </li> <li>Building specific tools or administrative functions that utilize the <code>artifactService.deleteArtifact</code> method (note: delete is not exposed via context objects for safety).  </li> <li>Carefully managing filenames to allow pattern-based deletion if needed.</li> </ul> </li> </ul>"},{"location":"callbacks/","title":"Callbacks: Observe, Customize, and Control Agent Behavior","text":""},{"location":"callbacks/#introduction-what-are-callbacks-and-why-use-them","title":"Introduction: What are Callbacks and Why Use Them?","text":"<p>Callbacks are a cornerstone feature of ADK, providing a powerful mechanism to hook into an agent's execution process. They allow you to observe, customize, and even control the agent's behavior at specific, predefined points without modifying the core ADK framework code.</p> <p>What are they? In essence, callbacks are standard TypeScript functions that you define. You then associate these functions with an agent when you create it. The ADK framework automatically calls your functions at key stages, letting you observe or intervene. Think of it like checkpoints during the agent's process:</p> <ul> <li>Before the agent starts its main work on a request, and after it finishes: When you ask an agent to do something (e.g., answer a question), it runs its internal logic to figure out the response.</li> <li>The <code>beforeAgentCallback</code> executes right before this main work begins for that specific request.</li> <li>The <code>afterAgentCallback</code> executes right after the agent has finished all its steps for that request and has prepared the final result, but just before the result is returned.</li> <li>This \"main work\" encompasses the agent's entire process for handling that single request. This might involve deciding to call an LLM, actually calling the LLM, deciding to use a tool, using the tool, processing the results, and finally putting together the answer. These callbacks essentially wrap the whole sequence from receiving the input to producing the final output for that one interaction.</li> <li>Before sending a request to, or after receiving a response from, the Large Language Model (LLM): These callbacks (<code>beforeModelCallback</code>, <code>afterModelCallback</code>) allow you to inspect or modify the data going to and coming from the LLM specifically.</li> <li>Before executing a tool (like a function or another agent) or after it finishes: Similarly, <code>beforeToolCallback</code> and <code>afterToolCallback</code> callbacks give you control points specifically around the execution of tools invoked by the agent.</li> </ul> <p></p> <p>Why use them? Callbacks unlock significant flexibility and enable advanced agent capabilities:</p> <ul> <li>Observe &amp; Debug: Log detailed information at critical steps for monitoring and troubleshooting.  </li> <li>Customize &amp; Control: Modify data flowing through the agent (like LLM requests or tool results) or even bypass certain steps entirely based on your logic.  </li> <li>Implement Guardrails: Enforce safety rules, validate inputs/outputs, or prevent disallowed operations.  </li> <li>Manage State: Read or dynamically update the agent's session state during execution.  </li> <li>Integrate &amp; Enhance: Trigger external actions (API calls, notifications) or add features like caching.</li> </ul> <p>How are they added? You register callbacks by passing your defined TypeScript functions as arguments to the agent's constructor when you create an instance of <code>LlmAgent</code>.</p> <pre><code>import { LlmAgent, CallbackContext } from 'adk-typescript/agents';\nimport { LlmResponse, LlmRequest, LlmRegistry } from 'adk-typescript/models';\n\n// --- Define your callback function ---\nfunction myBeforeModelLogic(\n    callbackContext: CallbackContext, \n    llmRequest: LlmRequest\n): LlmResponse | undefined {\n    console.log(`Callback running before model call for agent: ${callbackContext.agentName}`);\n    // ... your custom logic here ...\n    return undefined; // Allow the model call to proceed\n}\n\n// --- Register it during Agent creation ---\nconst myAgent = new LlmAgent({\n    name: \"MyCallbackAgent\",\n    model: \"gemini-2.0-flash\", // Or your desired model\n    instruction: \"Be helpful.\",\n    // Other agent parameters...\n    beforeModelCallback: myBeforeModelLogic // Pass the function here\n});\n</code></pre>"},{"location":"callbacks/#the-callback-mechanism-interception-and-control","title":"The Callback Mechanism: Interception and Control","text":"<p>When the ADK framework encounters a point where a callback can run (e.g., just before calling the LLM), it checks if you provided a corresponding callback function for that agent. If you did, the framework executes your function.</p> <p>Context is Key: Your callback function isn't called in isolation. The framework provides special context objects (<code>CallbackContext</code> or <code>ToolContext</code>) as arguments. These objects contain vital information about the current state of the agent's execution, including the invocation details, session state, and potentially references to services like artifacts or memory. You use these context objects to understand the situation and interact with the framework. (See the dedicated \"Context Objects\" section for full details).</p> <p>Controlling the Flow (The Core Mechanism): The most powerful aspect of callbacks lies in how their return value influences the agent's subsequent actions. This is how you intercept and control the execution flow:</p> <ol> <li> <p><code>return undefined</code> (Allow Default Behavior): </p> <ul> <li>This is the standard way to signal that your callback has finished its work (e.g., logging, inspection, minor modifications to mutable input arguments like <code>llmRequest</code>) and that the ADK agent should proceed with its normal operation.  </li> <li>For <code>before*</code> callbacks (<code>beforeAgentCallback</code>, <code>beforeModelCallback</code>, <code>beforeToolCallback</code>), returning <code>undefined</code> means the next step in the sequence (running the agent logic, calling the LLM, executing the tool) will occur.  </li> <li>For <code>after*</code> callbacks (<code>afterAgentCallback</code>, <code>afterModelCallback</code>, <code>afterToolCallback</code>), returning <code>undefined</code> means the result just produced by the preceding step (the agent's output, the LLM's response, the tool's result) will be used as is.</li> </ul> </li> <li> <p><code>return &lt;Specific Object&gt;</code> (Override Default Behavior): </p> <ul> <li>Returning a specific type of object (instead of <code>undefined</code>) is how you override the ADK agent's default behavior. The framework will use the object you return and skip the step that would normally follow or replace the result that was just generated.  </li> <li><code>beforeAgentCallback</code> \u2192 <code>Content</code>: Skips the agent's main execution logic. The returned <code>Content</code> object is immediately treated as the agent's final output for this turn. Useful for handling simple requests directly or enforcing access control.  </li> <li><code>beforeModelCallback</code> \u2192 <code>LlmResponse</code>: Skips the call to the external Large Language Model. The returned <code>LlmResponse</code> object is processed as if it were the actual response from the LLM. Ideal for implementing input guardrails, prompt validation, or serving cached responses.  </li> <li><code>beforeToolCallback</code> \u2192 <code>Record&lt;string, any&gt;</code>: Skips the execution of the actual tool function (or sub-agent). The returned object is used as the result of the tool call, which is then typically passed back to the LLM. Perfect for validating tool arguments, applying policy restrictions, or returning mocked/cached tool results.  </li> <li><code>afterAgentCallback</code> \u2192 <code>Content</code>: Replaces the <code>Content</code> that the agent's run logic just produced.  </li> <li><code>afterModelCallback</code> \u2192 <code>LlmResponse</code>: Replaces the <code>LlmResponse</code> received from the LLM. Useful for sanitizing outputs, adding standard disclaimers, or modifying the LLM's response structure.  </li> <li><code>afterToolCallback</code> \u2192 <code>Record&lt;string, any&gt;</code>: Replaces the result returned by the tool. Allows for post-processing or standardization of tool outputs before they are sent back to the LLM.</li> </ul> </li> </ol> <p>Conceptual Code Example (Guardrail):</p> <p>This example demonstrates the common pattern for a guardrail using <code>beforeModelCallback</code>.</p> <pre><code>import { LlmAgent, CallbackContext } from 'adk-typescript/agents';\nimport { LlmResponse, LlmRequest, Content, LlmRegistry } from 'adk-typescript/models';\nimport { runners } from 'adk-typescript';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\n\nconst GEMINI_2_FLASH = \"gemini-2.0-flash\";\n\n// --- Define the Callback Function ---\nfunction simpleBeforeModelModifier(\n    callbackContext: CallbackContext, \n    llmRequest: LlmRequest\n): LlmResponse | undefined {\n    // Inspect/modify the LLM request or skip the call\n    const agentName = callbackContext.agentName;\n    console.log(`[Callback] Before model call for agent: ${agentName}`);\n\n    // Inspect the last user message in the request contents\n    let lastUserMessage = \"\";\n    if (llmRequest.contents &amp;&amp; llmRequest.contents.length &gt; 0) {\n        const lastContent = llmRequest.contents[llmRequest.contents.length - 1];\n        if (lastContent.role === 'user' &amp;&amp; lastContent.parts &amp;&amp; lastContent.parts.length &gt; 0) {\n            lastUserMessage = lastContent.parts[0].text || \"\";\n        }\n    }\n    console.log(`[Callback] Inspecting last user message: '${lastUserMessage}'`);\n\n    // --- Modification Example ---\n    // Add a prefix to the system instruction\n    if (llmRequest.config.systemInstruction) {\n        const originalInstruction = llmRequest.config.systemInstruction as string;\n        const prefix = \"[Modified by Callback] \";\n        const modifiedText = prefix + originalInstruction;\n        llmRequest.config.systemInstruction = modifiedText;\n        console.log(`[Callback] Modified system instruction to: '${modifiedText}'`);\n    }\n\n    // --- Skip Example ---\n    // Check if the last user message contains \"BLOCK\"\n    if (lastUserMessage.toUpperCase().includes(\"BLOCK\")) {\n        console.log(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\");\n        // Return an LlmResponse to skip the actual LLM call\n        return new LlmResponse({\n            content: {\n                role: \"model\",\n                parts: [{ text: \"LLM call was blocked by beforeModelCallback.\" }]\n            }\n        });\n    } else {\n        console.log(\"[Callback] Proceeding with LLM call.\");\n        // Return undefined to allow the (modified) request to go to the LLM\n        return undefined;\n    }\n}\n\n// Create LlmAgent and Assign Callback\nconst myLlmAgent = new LlmAgent({\n    name: \"ModelCallbackAgent\",\n    model: GEMINI_2_FLASH,\n    instruction: \"You are a helpful assistant.\", // Base instruction\n    description: \"An LLM agent demonstrating beforeModelCallback\",\n    beforeModelCallback: simpleBeforeModelModifier // Pass the function here\n});\n\nconst APP_NAME = \"guardrail_app\";\nconst USER_ID = \"user_1\";\nconst SESSION_ID = \"session_001\";\n\n// Session and Runner\nconst sessionService = new InMemorySessionService();\nsessionService.createSession({\n    appName: APP_NAME, \n    userId: USER_ID, \n    sessionId: SESSION_ID\n});\nconst runner = new runners.Runner({\n    agent: myLlmAgent, \n    appName: APP_NAME, \n    sessionService: sessionService\n});\n\n// Agent Interaction\nasync function callAgent(query: string) {\n    const content: Content = {\n        role: 'user', \n        parts: [{ text: query }]\n    };\n\n    for await (const event of runner.run({\n        userId: USER_ID,\n        sessionId: SESSION_ID,\n        newMessage: content\n    })) {\n        if (event.isFinalResponse() &amp;&amp; event.content?.parts?.[0]?.text) {\n            const finalResponse = event.content.parts[0].text;\n            console.log(\"Agent Response: \", finalResponse);\n        } else if (event.errorCode) {\n            console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n        }\n    }\n}\n\n// Usage: \ncallAgent(\"callback example\");\n</code></pre> <p>By understanding this mechanism of returning <code>undefined</code> versus returning specific objects, you can precisely control the agent's execution path, making callbacks an essential tool for building sophisticated and reliable agents with ADK.</p>"},{"location":"callbacks/design-patterns-and-best-practices/","title":"Design Patterns and Best Practices for Callbacks","text":"<p>Callbacks offer powerful hooks into the agent lifecycle. Here are common design patterns illustrating how to leverage them effectively in ADK, followed by best practices for implementation.</p>"},{"location":"callbacks/design-patterns-and-best-practices/#design-patterns","title":"Design Patterns","text":"<p>These patterns demonstrate typical ways to enhance or control agent behavior using callbacks:</p>"},{"location":"callbacks/design-patterns-and-best-practices/#1-guardrails-policy-enforcement","title":"1. Guardrails &amp; Policy Enforcement","text":"<ul> <li>Pattern: Intercept requests before they reach the LLM or tools to enforce rules.</li> <li>How: Use <code>before_model_callback</code> to inspect the <code>LlmRequest</code> prompt or <code>before_tool_callback</code> to inspect tool arguments (<code>args</code>). If a policy violation is detected (e.g., forbidden topics, profanity), return a predefined response (<code>LlmResponse</code> or <code>dict</code>) to block the operation and optionally update <code>context.state</code> to log the violation.</li> <li>Example: A <code>before_model_callback</code> checks <code>llm_request.contents</code> for sensitive keywords and returns a standard \"Cannot process this request\" <code>LlmResponse</code> if found, preventing the LLM call.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#2-dynamic-state-management","title":"2. Dynamic State Management","text":"<ul> <li>Pattern: Read from and write to session state within callbacks to make agent behavior context-aware and pass data between steps.</li> <li>How: Access <code>callback_context.state</code> or <code>tool_context.state</code>. Modifications (<code>state['key'] = value</code>) are automatically tracked in the subsequent <code>Event.actions.state_delta</code> for persistence by the <code>SessionService</code>.</li> <li>Example: An <code>after_tool_callback</code> saves a <code>transaction_id</code> from the tool's result to <code>tool_context.state['last_transaction_id']</code>. A later <code>before_agent_callback</code> might read <code>state['user_tier']</code> to customize the agent's greeting.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#3-logging-and-monitoring","title":"3. Logging and Monitoring","text":"<ul> <li>Pattern: Add detailed logging at specific lifecycle points for observability and debugging.</li> <li>How: Implement callbacks (e.g., <code>before_agent_callback</code>, <code>after_tool_callback</code>, <code>after_model_callback</code>) to print or send structured logs containing information like agent name, tool name, invocation ID, and relevant data from the context or arguments.</li> <li>Example: Log messages like <code>INFO: [Invocation: e-123] Before Tool: search_api - Args: {'query': 'ADK'}</code>.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#4-caching","title":"4. Caching","text":"<ul> <li>Pattern: Avoid redundant LLM calls or tool executions by caching results.</li> <li>How: In <code>before_model_callback</code> or <code>before_tool_callback</code>, generate a cache key based on the request/arguments. Check <code>context.state</code> (or an external cache) for this key. If found, return the cached <code>LlmResponse</code> or result <code>dict</code> directly, skipping the actual operation. If not found, allow the operation to proceed and use the corresponding <code>after_</code> callback (<code>after_model_callback</code>, <code>after_tool_callback</code>) to store the new result in the cache using the key.</li> <li>Example: <code>before_tool_callback</code> for <code>get_stock_price(symbol)</code> checks <code>state[f\"cache:stock:{symbol}\"]</code>. If present, returns the cached price; otherwise, allows the API call and <code>after_tool_callback</code> saves the result to the state key.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#5-requestresponse-modification","title":"5. Request/Response Modification","text":"<ul> <li>Pattern: Alter data just before it's sent to the LLM/tool or just after it's received.</li> <li>How:<ul> <li><code>before_model_callback</code>: Modify <code>llm_request</code> (e.g., add system instructions based on <code>state</code>).</li> <li><code>after_model_callback</code>: Modify the returned <code>LlmResponse</code> (e.g., format text, filter content).</li> <li><code>before_tool_callback</code>: Modify the tool <code>args</code> dictionary.</li> <li><code>after_tool_callback</code>: Modify the <code>tool_response</code> dictionary.</li> </ul> </li> <li>Example: <code>before_model_callback</code> appends \"User language preference: Spanish\" to <code>llm_request.config.system_instruction</code> if <code>context.state['lang'] == 'es'</code>.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#6-conditional-skipping-of-steps","title":"6. Conditional Skipping of Steps","text":"<ul> <li>Pattern: Prevent standard operations (agent run, LLM call, tool execution) based on certain conditions.</li> <li>How: Return a value from a <code>before_</code> callback (<code>Content</code> from <code>before_agent_callback</code>, <code>LlmResponse</code> from <code>before_model_callback</code>, <code>dict</code> from <code>before_tool_callback</code>). The framework interprets this returned value as the result for that step, skipping the normal execution.</li> <li>Example: <code>before_tool_callback</code> checks <code>tool_context.state['api_quota_exceeded']</code>. If <code>True</code>, it returns <code>{'error': 'API quota exceeded'}</code>, preventing the actual tool function from running.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#7-tool-specific-actions-authentication-summarization-control","title":"7. Tool-Specific Actions (Authentication &amp; Summarization Control)","text":"<ul> <li>Pattern: Handle actions specific to the tool lifecycle, primarily authentication and controlling LLM summarization of tool results.</li> <li>How: Use <code>ToolContext</code> within tool callbacks (<code>before_tool_callback</code>, <code>after_tool_callback</code>).<ul> <li>Authentication: Call <code>tool_context.request_credential(auth_config)</code> in <code>before_tool_callback</code> if credentials are required but not found (e.g., via <code>tool_context.get_auth_response</code> or state check). This initiates the auth flow.</li> <li>Summarization: Set <code>tool_context.actions.skip_summarization = True</code> if the raw dictionary output of the tool should be passed back to the LLM or potentially displayed directly, bypassing the default LLM summarization step.</li> </ul> </li> <li>Example: A <code>before_tool_callback</code> for a secure API checks for an auth token in state; if missing, it calls <code>request_credential</code>. An <code>after_tool_callback</code> for a tool returning structured JSON might set <code>skip_summarization = True</code>.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#8-artifact-handling","title":"8. Artifact Handling","text":"<ul> <li>Pattern: Save or load session-related files or large data blobs during the agent lifecycle.</li> <li>How: Use <code>callback_context.save_artifact</code> / <code>tool_context.save_artifact</code> to store data (e.g., generated reports, logs, intermediate data). Use <code>load_artifact</code> to retrieve previously stored artifacts. Changes are tracked via <code>Event.actions.artifact_delta</code>.</li> <li>Example: An <code>after_tool_callback</code> for a \"generate_report\" tool saves the output file using <code>tool_context.save_artifact(\"report.pdf\", report_part)</code>. A <code>before_agent_callback</code> might load a configuration artifact using <code>callback_context.load_artifact(\"agent_config.json\")</code>.</li> </ul>"},{"location":"callbacks/design-patterns-and-best-practices/#best-practices-for-callbacks","title":"Best Practices for Callbacks","text":"<ul> <li>Keep Focused: Design each callback for a single, well-defined purpose (e.g., just logging, just validation). Avoid monolithic callbacks.</li> <li>Mind Performance: Callbacks execute synchronously within the agent's processing loop. Avoid long-running or blocking operations (network calls, heavy computation). Offload if necessary, but be aware this adds complexity.</li> <li>Handle Errors Gracefully: Use <code>try...except</code> blocks within your callback functions. Log errors appropriately and decide if the agent invocation should halt or attempt recovery. Don't let callback errors crash the entire process.</li> <li>Manage State Carefully:<ul> <li>Be deliberate about reading from and writing to <code>context.state</code>. Changes are immediately visible within the current invocation and persisted at the end of the event processing.</li> <li>Use specific state keys rather than modifying broad structures to avoid unintended side effects.</li> <li>Consider using state prefixes (<code>State.APP_PREFIX</code>, <code>State.USER_PREFIX</code>, <code>State.TEMP_PREFIX</code>) for clarity, especially with persistent <code>SessionService</code> implementations.</li> </ul> </li> <li>Consider Idempotency: If a callback performs actions with external side effects (e.g., incrementing an external counter), design it to be idempotent (safe to run multiple times with the same input) if possible, to handle potential retries in the framework or your application.</li> <li>Test Thoroughly: Unit test your callback functions using mock context objects. Perform integration tests to ensure callbacks function correctly within the full agent flow.</li> <li>Ensure Clarity: Use descriptive names for your callback functions. Add clear docstrings explaining their purpose, when they run, and any side effects (especially state modifications).</li> <li>Use Correct Context Type: Always use the specific context type provided (<code>CallbackContext</code> for agent/model, <code>ToolContext</code> for tools) to ensure access to the appropriate methods and properties.</li> </ul> <p>By applying these patterns and best practices, you can effectively use callbacks to create more robust, observable, and customized agent behaviors in ADK.</p>"},{"location":"callbacks/types-of-callbacks/","title":"Types of Callbacks","text":"<p>The framework provides different types of callbacks that trigger at various stages of an agent's execution. Understanding when each callback fires and what context it receives is key to using them effectively.</p>"},{"location":"callbacks/types-of-callbacks/#agent-lifecycle-callbacks","title":"Agent Lifecycle Callbacks","text":"<p>These callbacks are available on any agent that inherits from <code>BaseAgent</code> (including <code>LlmAgent</code>, <code>SequentialAgent</code>, <code>ParallelAgent</code>, <code>LoopAgent</code>, etc).</p>"},{"location":"callbacks/types-of-callbacks/#before-agent-callback","title":"Before Agent Callback","text":"<p>When: Called immediately before the agent's <code>_run_async_impl</code> (or <code>_run_live_impl</code>) method is executed. It runs after the agent's <code>InvocationContext</code> is created but before its core logic begins.</p> <p>Purpose: Ideal for setting up resources or state needed only for this specific agent's run, performing validation checks on the session state (callback_context.state) before execution starts, logging the entry point of the agent's activity, or potentially modifying the invocation context before the core logic uses it.</p> Code <pre><code>import { \n  LlmAgent, \n  CallbackContext\n} from 'adk-typescript/agents';\nimport {\n  Content,\n  LlmRegistry\n} from 'adk-typescript/models';\nimport { runners } from 'adk-typescript';\n\n// Define the model\nconst GEMINI_2_FLASH = \"gemini-2.0-flash\";\n\n\n// --- 1. Define the Callback Function ---\nfunction checkIfAgentShouldRun(callbackContext: CallbackContext): Content | null {\n  /**\n   * Logs entry and checks 'skip_llm_agent' in session state.\n   * If True, returns Content to skip the agent's execution.\n   * If False or not present, returns null to allow execution.\n   */\n  const agentName = callbackContext.agentName;\n  const invocationId = callbackContext.invocationId;\n  const currentState = callbackContext.state;\n\n  console.log(`\\n[Callback] Entering agent: ${agentName} (Inv: ${invocationId})`);\n  console.log(`[Callback] Current State: ${JSON.stringify(currentState)}`);\n\n  // Check the condition in session state\n  if (currentState.skip_llm_agent === true) {\n    console.log(`[Callback] State condition 'skip_llm_agent=true' met: Skipping agent ${agentName}.`);\n    // Return Content to skip the agent's run\n    return {\n      parts: [{ text: `Agent ${agentName} skipped by before_agent_callback due to state.` }],\n      role: \"model\" // Assign model role to the overriding response\n    };\n  } else {\n    console.log(`[Callback] State condition not met: Proceeding with agent ${agentName}.`);\n    // Return null to allow the LlmAgent's normal execution\n    return null;\n  }\n}\n\n// --- 2. Setup Agent with Callback ---\n// Create model instance (using LlmRegistry)\nconst model = LlmRegistry.newLlm(GEMINI_2_FLASH);\n\nconst llmAgentWithBeforeCallback = new LlmAgent({\n  name: \"MyControlledAgent\",\n  model: model,\n  instruction: \"You are a concise assistant.\",\n  description: \"An LLM agent demonstrating stateful before_agent_callback\",\n  beforeAgentCallback: checkIfAgentShouldRun // Assign the callback\n});\n\n// --- 3. Setup Runner and Sessions using InMemoryRunner ---\nasync function main(): Promise&lt;void&gt; {\n  const appName = \"before_agent_demo\";\n  const userId = \"test_user\";\n  const sessionIdRun = \"session_will_run\";\n  const sessionIdSkip = \"session_will_skip\";\n\n  // Use InMemoryRunner - it includes InMemorySessionService\n  const runner = new runners.InMemoryRunner(llmAgentWithBeforeCallback, appName);\n\n  // Get the bundled session service\n  const sessionService = runner.sessionService;\n\n  // Create session 1: Agent will run (default empty state)\n  sessionService.createSession({\n    appName: appName,\n    userId: userId,\n    sessionId: sessionIdRun\n    // No initial state means 'skip_llm_agent' will be false in the callback check\n  });\n\n  // Create session 2: Agent will be skipped (state has skip_llm_agent=true)\n  sessionService.createSession({\n    appName: appName,\n    userId: userId,\n    sessionId: sessionIdSkip,\n    state: { skip_llm_agent: true } // Set the state flag here\n  });\n\n  try {\n    // --- Scenario 1: Run where callback allows agent execution ---\n    console.log(\"\\n\" + \"=\".repeat(20) + \n                ` SCENARIO 1: Running Agent on Session '${sessionIdRun}' (Should Proceed) ` + \n                \"=\".repeat(20));\n\n    const events1 = runner.run({\n      userId: userId,\n      sessionId: sessionIdRun,\n      newMessage: {\n        role: \"user\", \n        parts: [{ text: \"Hello, please respond.\" }]\n      }\n    });\n\n    for await (const event of events1) {\n      // Print final output (either from LLM or callback override)\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts) {\n        console.log(`Final Output: [${event.author}] ${event.content.parts[0].text?.trim()}`);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n\n    // --- Scenario 2: Run where callback intercepts and skips agent ---\n    console.log(\"\\n\" + \"=\".repeat(20) + \n                ` SCENARIO 2: Running Agent on Session '${sessionIdSkip}' (Should Skip) ` + \n                \"=\".repeat(20));\n\n    const events2 = runner.run({\n      userId: userId,\n      sessionId: sessionIdSkip,\n      newMessage: {\n        role: \"user\", \n        parts: [{ text: \"This message won't reach the LLM.\" }]\n      }\n    });\n\n    for await (const event of events2) {\n      // Print final output (either from LLM or callback override)\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts) {\n        console.log(`Final Output: [${event.author}] ${event.content.parts[0].text?.trim()}`);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n  } catch (error) {\n    console.error(`Error in main function: ${error}`);\n  }\n}\n\n// --- 4. Execute ---\n// In TypeScript/JS we can call async functions at the top level\nmain().catch(error =&gt; {\n  console.error(`Unhandled error in main: ${error}`);\n});\n\n// Export the agent and main function for external use\nexport const agent = llmAgentWithBeforeCallback;\nexport { main as runBeforeAgentCallbackDemo }; \n</code></pre> <p>Note on the <code>before_agent_callback</code> Example:</p> <ul> <li>What it Shows: This example demonstrates the <code>before_agent_callback</code>. This callback runs right before the agent's main processing logic starts for a given request.</li> <li>How it Works: The callback function (<code>checkIfAgentShouldRun</code>) looks at a flag (<code>skip_llm_agent</code>) in the session's state.<ul> <li>If the flag is <code>true</code>, the callback returns a <code>Content</code> object. This tells the ADK framework to skip the agent's main execution entirely and use the callback's returned content as the final response.</li> <li>If the flag is <code>false</code> (or not set), the callback returns <code>null</code>. This tells the ADK framework to proceed with the agent's normal execution (calling the LLM in this case).</li> </ul> </li> <li>Expected Outcome: You'll see two scenarios:<ol> <li>In the session with the <code>skip_llm_agent: true</code> state, the agent's LLM call is bypassed, and the output comes directly from the callback (\"Agent... skipped...\").</li> <li>In the session without that state flag, the callback allows the agent to run, and you see the actual response from the LLM (e.g., \"Hello!\").</li> </ol> </li> <li>Understanding Callbacks: This highlights how <code>before_</code> callbacks act as gatekeepers, allowing you to intercept execution before a major step and potentially prevent it based on checks (like state, input validation, permissions).</li> </ul>"},{"location":"callbacks/types-of-callbacks/#after-agent-callback","title":"After Agent Callback","text":"<p>When: Called immediately after the agent's <code>_run_async_impl</code> (or <code>_run_live_impl</code>) method successfully completes. It does not run if the agent was skipped due to <code>before_agent_callback</code> returning content or if <code>end_invocation</code> was set during the agent's run.</p> <p>Purpose: Useful for cleanup tasks, post-execution validation, logging the completion of an agent's activity, modifying final state, or augmenting/replacing the agent's final output.</p> Code <pre><code>import {\n  LlmAgent,\n  CallbackContext,\n} from 'adk-typescript/agents';\nimport {\n  Content,\n  LlmRegistry,\n} from 'adk-typescript/models';\nimport { runners } from 'adk-typescript';\n\n// Define the model - Use the specific model name requested\nconst GEMINI_2_FLASH = \"gemini-2.0-flash\";\n\n// --- 1. Define the Callback Function ---\nfunction modifyOutputAfterAgent(callbackContext: CallbackContext): Content | null {\n  /**\n   * Logs exit from an agent and checks 'add_concluding_note' in session state.\n   * If True, returns new Content to *replace* the agent's original output.\n   * If False or not present, returns null, allowing the agent's original output to be used.\n   */\n  const agentName = callbackContext.agentName;\n  const invocationId = callbackContext.invocationId;\n  const currentState = callbackContext.state;\n\n  console.log(`\\n[Callback] Exiting agent: ${agentName} (Inv: ${invocationId})`);\n  console.log(`[Callback] Current State: ${JSON.stringify(currentState)}`);\n\n  // Example: Check state to decide whether to modify the final output\n  if (currentState.add_concluding_note === true) {\n    console.log(`[Callback] State condition 'add_concluding_note=true' met: Replacing agent ${agentName}'s output.`);\n\n    // Return Content to *replace* the agent's own output\n    return {\n      parts: [{ text: `Concluding note added by after_agent_callback, replacing original output.` }],\n      role: \"model\" // Assign model role to the overriding response\n    };\n  } else {\n    console.log(`[Callback] State condition not met: Using agent ${agentName}'s original output.`);\n    // Return null - the agent's output produced just before this callback will be used.\n    return null;\n  }\n}\n\n// --- 2. Setup Agent with Callback ---\n// Create model instance (using LlmRegistry)\nconst model = LlmRegistry.newLlm(GEMINI_2_FLASH);\n\nconst llmAgentWithAfterCallback = new LlmAgent({\n  name: \"MySimpleAgentWithAfter\",\n  model: model,\n  instruction: \"You are a simple agent. Just say 'Processing complete!'\",\n  description: \"An LLM agent demonstrating after_agent_callback for output modification\",\n  afterAgentCallback: modifyOutputAfterAgent // Assign the callback here\n});\n\n// --- 3. Setup Runner and Sessions using InMemoryRunner ---\nasync function main(): Promise&lt;void&gt; {\n  const appName = \"after_agent_demo\";\n  const userId = \"test_user_after\";\n  const sessionIdNormal = \"session_run_normally\";\n  const sessionIdModify = \"session_modify_output\";\n\n  // Use InMemoryRunner - it includes InMemorySessionService\n  const runner = new runners.InMemoryRunner(llmAgentWithAfterCallback, appName);\n\n  // Get the bundled session service\n  const sessionService = runner.sessionService;\n\n  // Create session 1: Agent output will be used as is (default empty state)\n  sessionService.createSession({\n    appName: appName,\n    userId: userId,\n    sessionId: sessionIdNormal\n    // No initial state means 'add_concluding_note' will be false in the callback check\n  });\n\n  // Create session 2: Agent output will be replaced by the callback\n  sessionService.createSession({\n    appName: appName,\n    userId: userId,\n    sessionId: sessionIdModify,\n    state: { add_concluding_note: true } // Set the state flag here\n  });\n\n\n  try {\n    // --- Scenario 1: Run where callback allows agent's original output ---\n    console.log(\"\\n\" + \"=\".repeat(20) + \n                ` SCENARIO 1: Running Agent on Session '${sessionIdNormal}' (Should Use Original Output) ` + \n                \"=\".repeat(20));\n\n    const events1 = runner.run({\n      userId: userId,\n      sessionId: sessionIdNormal,\n      newMessage: {\n        role: \"user\", \n        parts: [{ text: \"Process this please.\" }]\n      }\n    });\n\n    for await (const event of events1) {\n      // Print final output (either from LLM or callback override)\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts) {\n        console.log(`Final Output: [${event.author}] ${event.content.parts[0].text?.trim()}`);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n\n    // --- Scenario 2: Run where callback replaces the agent's output ---\n    console.log(\"\\n\" + \"=\".repeat(20) + \n                ` SCENARIO 2: Running Agent on Session '${sessionIdModify}' (Should Replace Output) ` + \n                \"=\".repeat(20));\n\n    const events2 = runner.run({\n      userId: userId,\n      sessionId: sessionIdModify,\n      newMessage: {\n        role: \"user\", \n        parts: [{ text: \"Process this and add note.\" }]\n      }\n    });\n\n    for await (const event of events2) {\n      // Print final output (either from LLM or callback override)\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts) {\n        console.log(`Final Output: [${event.author}] ${event.content.parts[0].text?.trim()}`);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n  } catch (error) {\n    console.error(`Error in main function: ${error}`);\n  }\n}\n\n// --- 4. Execute ---\n// In TypeScript/JS we can call async functions at the top level\nmain().catch(error =&gt; {\n  console.error(`Unhandled error in main: ${error}`);\n});\n\n// Export the agent and main function for external use\nexport const agent = llmAgentWithAfterCallback;\nexport { main as runAfterAgentCallbackDemo }; \n</code></pre> <p>Note on the <code>afterAgentCallback</code> Example:</p> <ul> <li>What it Shows: This example demonstrates the <code>afterAgentCallback</code>. This callback runs right after the agent's main processing logic has finished and produced its result, but before that result is finalized and returned.</li> <li>How it Works: The callback function (<code>modifyOutputAfterAgent</code>) checks a flag (<code>add_concluding_note</code>) in the session's state.<ul> <li>If the flag is <code>true</code>, the callback returns a new <code>Content</code> object. This tells the ADK framework to replace the agent's original output with the content returned by the callback.</li> <li>If the flag is <code>false</code> (or not set), the callback returns <code>null</code>. This tells the ADK framework to use the original output generated by the agent.</li> </ul> </li> <li>Expected Outcome: You'll see two scenarios:<ol> <li>In the session without the <code>add_concluding_note: true</code> state, the callback allows the agent's original output (\"Processing complete!\") to be used.</li> <li>In the session with that state flag, the callback intercepts the agent's original output and replaces it with its own message (\"Concluding note added...\").</li> </ol> </li> <li>Understanding Callbacks: This highlights how <code>after_</code> callbacks allow post-processing or modification. You can inspect the result of a step (the agent's run) and decide whether to let it pass through, change it, or completely replace it based on your logic.</li> </ul>"},{"location":"callbacks/types-of-callbacks/#llm-interaction-callbacks","title":"LLM Interaction Callbacks","text":"<p>These callbacks are specific to <code>LlmAgent</code> and provide hooks around the interaction with the Large Language Model.</p>"},{"location":"callbacks/types-of-callbacks/#before-model-callback","title":"Before Model Callback","text":"<p>When: Called just before the <code>generate_content_async</code> (or equivalent) request is sent to the LLM within an <code>LlmAgent</code>'s flow.</p> <p>Purpose: Allows inspection and modification of the request going to the LLM. Use cases include adding dynamic instructions, injecting few-shot examples based on state, modifying model config, implementing guardrails (like profanity filters), or implementing request-level caching.</p> <p>Return Value Effect: If the callback returns <code>None</code>, the LLM continues its normal workflow. If the callback returns an <code>LlmResponse</code> object, then the call to the LLM is skipped. The returned <code>LlmResponse</code> is used directly as if it came from the model. This is powerful for implementing guardrails or caching.</p> Code <pre><code>import {\n  LlmAgent,\n  CallbackContext,\n} from 'adk-typescript/agents';\nimport {\n  LlmRequest,\n  LlmResponse,\n  Content,\n  LlmRegistry,\n} from 'adk-typescript/models';\nimport { runners } from 'adk-typescript';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\n\n// Define the model\nconst GEMINI_2_FLASH = \"gemini-2.0-flash\";\n\n// --- Define the Callback Function ---\nfunction simpleBeforeModelModifier(\n  callbackContext: CallbackContext, \n  llmRequest: LlmRequest\n): LlmResponse | undefined {\n  /**\n   * Inspects/modifies the LLM request or skips the call.\n   */\n  const agentName = callbackContext.agentName;\n  console.log(`[Callback] Before model call for agent: ${agentName}`);\n\n  // Inspect the last user message in the request contents\n  let lastUserMessage = \"\";\n  if (llmRequest.contents &amp;&amp; llmRequest.contents.length &gt; 0) {\n    const lastContent = llmRequest.contents[llmRequest.contents.length - 1];\n    if (lastContent.role === 'user' &amp;&amp; lastContent.parts &amp;&amp; lastContent.parts.length &gt; 0) {\n      lastUserMessage = lastContent.parts[0].text || \"\";\n    }\n  }\n  console.log(`[Callback] Inspecting last user message: '${lastUserMessage}'`);\n\n  // --- Modification Example ---\n  // Add a prefix to the system instruction\n  if (llmRequest.config.systemInstruction) {\n    const originalInstruction = llmRequest.config.systemInstruction as string;\n    const prefix = \"[Modified by Callback] \";\n\n    const modifiedText = prefix + originalInstruction;\n    llmRequest.config.systemInstruction = modifiedText;\n    console.log(`[Callback] Modified system instruction to: '${modifiedText}'`);\n  }\n\n  // --- Skip Example ---\n  // Check if the last user message contains \"BLOCK\"\n  if (lastUserMessage.toUpperCase().includes(\"BLOCK\")) {\n    console.log(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\");\n    // Return an LlmResponse to skip the actual LLM call\n    return new LlmResponse({\n      content: {\n        role: \"model\",\n        parts: [{ text: \"LLM call was blocked by before_model_callback.\" }]\n      }\n    });\n  } else {\n    console.log(\"[Callback] Proceeding with LLM call.\");\n    // Return undefined to allow the (modified) request to go to the LLM\n    return undefined;\n  }\n}\n\n// Create model instance (using LlmRegistry)\nconst model = LlmRegistry.newLlm(GEMINI_2_FLASH);\n\n// Create LlmAgent and Assign Callback\nconst myLlmAgent = new LlmAgent({\n  name: \"ModelCallbackAgent\",\n  model: model,\n  instruction: \"You are a helpful assistant.\", // Base instruction\n  description: \"An LLM agent demonstrating before_model_callback\",\n  beforeModelCallback: simpleBeforeModelModifier // Assign the function here\n});\n\n// Setup constants for the session\nconst APP_NAME = \"guardrail_app\";\nconst USER_ID = \"user_1\";\nconst SESSION_ID = \"session_001\";\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nsessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: myLlmAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nasync function callAgent(query: string): Promise&lt;void&gt; {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  try {\n    const events = runner.run({\n      userId: USER_ID, \n      sessionId: SESSION_ID, \n      newMessage: content\n    });\n\n    for await (const event of events) {\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n        const finalResponse = event.content.parts[0].text;\n        console.log(\"Agent Response: \", finalResponse);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n  } catch (error) {\n    console.error(\"Error running agent:\", error);\n  }\n}\n\n// Execute with a sample query\ncallAgent(\"Tell me about the weather today.\");\n\n// Try with a blocking keyword\nsetTimeout(() =&gt; {\n  console.log(\"\\nTrying with blocking keyword:\");\n  callAgent(\"BLOCK this request please\");\n}, 2000);\n\n// Export for external use\nexport const agent = myLlmAgent;\nexport async function runBeforeModelCallbackDemo(query: string): Promise&lt;void&gt; {\n  await callAgent(query);\n} \n</code></pre>"},{"location":"callbacks/types-of-callbacks/#after-model-callback","title":"After Model Callback","text":"<p>When: Called just after a response (<code>LlmResponse</code>) is received from the LLM, before it's processed further by the invoking agent.</p> <p>Purpose: Allows inspection or modification of the raw LLM response. Use cases include</p> <ul> <li>logging model outputs,</li> <li>reformatting responses,</li> <li>censoring sensitive information generated by the model,</li> <li>parsing structured data from the LLM response and storing it in <code>callback_context.state</code></li> <li>or handling specific error codes.</li> </ul> Code <pre><code>import {\n  LlmAgent,\n  CallbackContext,\n} from 'adk-typescript/agents';\nimport {\n  LlmResponse,\n  Content,\n  LlmRegistry,\n} from 'adk-typescript/models';\nimport { runners } from 'adk-typescript';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\n\n\n// Define the model\nconst GEMINI_2_FLASH = \"gemini-2.0-flash\";\n\n// --- Define the Callback Function ---\nfunction simpleAfterModelModifier(\n  callbackContext: CallbackContext, \n  llmResponse: LlmResponse\n): LlmResponse | undefined {\n  /**\n   * Inspects/modifies the LLM response after it's received.\n   */\n  const agentName = callbackContext.agentName;\n  console.log(`[Callback] After model call for agent: ${agentName}`);\n\n  // --- Inspection ---\n  let originalText = \"\";\n  if (llmResponse.content &amp;&amp; llmResponse.content.parts &amp;&amp; llmResponse.content.parts.length &gt; 0) {\n    // Check if it's a text response\n    const firstPart = llmResponse.content.parts[0];\n    if (firstPart.text) {\n      originalText = firstPart.text;\n      console.log(`[Callback] Inspected original response text: '${originalText.substring(0, 100)}...'`); // Log snippet\n    } else if (firstPart.functionCall) {\n      console.log(`[Callback] Inspected response: Contains function call '${firstPart.functionCall.name}'. No text modification.`);\n      return undefined; // Don't modify tool calls in this example\n    } else {\n      console.log(\"[Callback] Inspected response: No text content found.\");\n      return undefined;\n    }\n  } else if (llmResponse.errorMessage) {\n    console.log(`[Callback] Inspected response: Contains error '${llmResponse.errorMessage}'. No modification.`);\n    return undefined;\n  } else {\n    console.log(\"[Callback] Inspected response: Empty LlmResponse.\");\n    return undefined; // Nothing to modify\n  }\n\n  // --- Modification Example ---\n  // Replace \"joke\" with \"funny story\" (case-insensitive)\n  const searchTerm = \"joke\";\n  const replaceTerm = \"funny story\";\n\n  if (originalText.toLowerCase().includes(searchTerm)) {\n    console.log(`[Callback] Found '${searchTerm}'. Modifying response.`);\n\n    // Perform the replacements with case sensitivity in mind\n    let modifiedText = originalText.replace(\n      new RegExp(searchTerm, 'g'), \n      replaceTerm\n    );\n    modifiedText = modifiedText.replace(\n      new RegExp(searchTerm.charAt(0).toUpperCase() + searchTerm.slice(1), 'g'), \n      replaceTerm.charAt(0).toUpperCase() + replaceTerm.slice(1)\n    );\n\n    // Create a new LlmResponse with the modified content\n    // Clone the structure to avoid modifying original if other callbacks exist\n    const newResponse = new LlmResponse({\n      content: {\n        role: \"model\",\n        parts: [{ text: modifiedText }]\n      },\n      // Copy other relevant fields if necessary\n      groundingMetadata: llmResponse.groundingMetadata\n    });\n\n    console.log(`[Callback] Returning modified response.`);\n    return newResponse; // Return the modified response\n  } else {\n    console.log(`[Callback] '${searchTerm}' not found. Passing original response through.`);\n    // Return undefined to use the original llm_response\n    return undefined;\n  }\n}\n\n// Create model instance (using LlmRegistry)\nconst model = LlmRegistry.newLlm(GEMINI_2_FLASH);\n\n// Create LlmAgent and Assign Callback\nconst myLlmAgent = new LlmAgent({\n  name: \"AfterModelCallbackAgent\",\n  model: model,\n  instruction: \"You are a helpful assistant.\",\n  description: \"An LLM agent demonstrating after_model_callback\",\n  afterModelCallback: simpleAfterModelModifier // Assign the function here\n});\n\n// Setup constants for the session\nconst APP_NAME = \"guardrail_app\";\nconst USER_ID = \"user_1\";\nconst SESSION_ID = \"session_001\";\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nsessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: myLlmAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nasync function callAgent(query: string): Promise&lt;void&gt; {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  try {\n    const events = runner.run({\n      userId: USER_ID, \n      sessionId: SESSION_ID, \n      newMessage: content\n    });\n\n    for await (const event of events) {\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n        const finalResponse = event.content.parts[0].text;\n        console.log(\"Agent Response: \", finalResponse);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n  } catch (error) {\n    console.error(\"Error running agent:\", error);\n  }\n}\n\n// Regular query (may not contain the word 'joke')\ncallAgent(\"Tell me about the weather today.\");\n\n// Query specifically asking for a joke to trigger the replacement\nsetTimeout(() =&gt; {\n  console.log(\"\\nTrying with a query that should trigger word replacement:\");\n  callAgent(\"Tell me a joke about programming.\");\n}, 2000);\n\n// Export for external use\nexport const agent = myLlmAgent;\nexport async function runAfterModelCallbackDemo(query: string): Promise&lt;void&gt; {\n  await callAgent(query);\n} \n</code></pre>"},{"location":"callbacks/types-of-callbacks/#tool-execution-callbacks","title":"Tool Execution Callbacks","text":"<p>These callbacks are also specific to <code>LlmAgent</code> and trigger around the execution of tools (including <code>FunctionTool</code>, <code>AgentTool</code>, etc.) that the LLM might request.</p>"},{"location":"callbacks/types-of-callbacks/#before-tool-callback","title":"Before Tool Callback","text":"<p>When: Called just before a specific tool's <code>run_async</code> method is invoked, after the LLM has generated a function call for it.</p> <p>Purpose: Allows inspection and modification of tool arguments, performing authorization checks before execution, logging tool usage attempts, or implementing tool-level caching.</p> <p>Return Value Effect:</p> <ol> <li>If the callback returns <code>None</code>, the tool's <code>run_async</code> method is executed with the (potentially modified) <code>args</code>.  </li> <li>If a dictionary is returned, the tool's <code>run_async</code> method is skipped. The returned dictionary is used directly as the result of the tool call. This is useful for caching or overriding tool behavior.  </li> </ol> Code <pre><code>import {\n  LlmAgent,\n} from 'adk-typescript/agents';\nimport {\n  Content,\n  LlmRegistry,\n} from 'adk-typescript/models';\nimport {\n  FunctionTool,\n  ToolContext,\n  BaseTool,\n} from 'adk-typescript/tools';\nimport { runners } from 'adk-typescript';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\n\n// Define the model\nconst GEMINI_2_FLASH = \"gemini-2.0-flash\";\n\n\n// Create a function that will be converted to a tool\nfunction getCapitalCity(params: Record&lt;string, any&gt;): string {\n  /**\n   * Retrieves the capital city of a given country.\n   */\n  const country = params.country as string;\n  console.log(`--- Tool 'get_capital_city' executing with country: ${country} ---`);\n  const countryCapitals: Record&lt;string, string&gt; = {\n    \"united states\": \"Washington, D.C.\",\n    \"canada\": \"Ottawa\",\n    \"france\": \"Paris\",\n    \"germany\": \"Berlin\",\n  };\n  return countryCapitals[country.toLowerCase()] || `Capital not found for ${country}`;\n}\n\n// Create the function tool\nconst capitalTool = new FunctionTool(getCapitalCity);\n\n// Define the before tool callback\nfunction simpleBeforeToolModifier(\n  tool: BaseTool, \n  args: Record&lt;string, any&gt;, \n  toolContext: ToolContext\n): Record&lt;string, any&gt; | undefined {\n  /**\n   * Inspects/modifies tool args or skips the tool call.\n   */\n  const agentName = toolContext.agentName;\n  const toolName = tool.name;\n  console.log(`[Callback] Before tool call for tool '${toolName}' in agent '${agentName}'`);\n  console.log(`[Callback] Original args: ${JSON.stringify(args)}`);\n\n  if (toolName === 'get_capital_city' &amp;&amp; args.country?.toLowerCase() === 'canada') {\n    console.log(\"[Callback] Detected 'Canada'. Modifying args to 'France'.\");\n    args.country = 'France';\n    console.log(`[Callback] Modified args: ${JSON.stringify(args)}`);\n    return undefined;\n  }\n\n  // If the tool is 'get_capital_city' and country is 'BLOCK'\n  if (toolName === 'get_capital_city' &amp;&amp; args.country?.toUpperCase() === 'BLOCK') {\n    console.log(\"[Callback] Detected 'BLOCK'. Skipping tool execution.\");\n    return { result: \"Tool execution was blocked by before_tool_callback.\" };\n  }\n\n  console.log(\"[Callback] Proceeding with original or previously modified args.\");\n  return undefined;\n}\n\n// Create model instance (using LlmRegistry)\nconst model = LlmRegistry.newLlm(GEMINI_2_FLASH);\n\n// Create the LLM agent with tool and callback\nconst myLlmAgent = new LlmAgent({\n  name: \"ToolCallbackAgent\",\n  model: model,\n  instruction: \"You are an agent that can find capital cities. Use the get_capital_city tool.\",\n  description: \"An LLM agent demonstrating before_tool_callback\",\n  tools: [capitalTool],\n  beforeToolCallback: simpleBeforeToolModifier\n});\n\n// Setup constants for the session\nconst APP_NAME = \"guardrail_app\";\nconst USER_ID = \"user_1\";\nconst SESSION_ID = \"session_001\";\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nsessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: myLlmAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nasync function callAgent(query: string): Promise&lt;void&gt; {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  try {\n    const events = runner.run({\n      userId: USER_ID, \n      sessionId: SESSION_ID, \n      newMessage: content\n    });\n\n    for await (const event of events) {\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n        const finalResponse = event.content.parts[0].text;\n        console.log(\"Agent Response: \", finalResponse);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n  } catch (error) {\n    console.error(\"Error running agent:\", error);\n  }\n}\n\n// Execute with a sample query\ncallAgent(\"What is the capital of Canada?\");\n\n// Export for external use\nexport const agent = myLlmAgent;\nexport async function runBeforeToolCallbackDemo(query: string): Promise&lt;void&gt; {\n  await callAgent(query);\n} \n</code></pre>"},{"location":"callbacks/types-of-callbacks/#after-tool-callback","title":"After Tool Callback","text":"<p>When: Called just after the tool's <code>run_async</code> method completes successfully.</p> <p>Purpose: Allows inspection and modification of the tool's result before it's sent back to the LLM (potentially after summarization). Useful for logging tool results, post-processing or formatting results, or saving specific parts of the result to the session state.</p> <p>Return Value Effect:</p> <ol> <li>If the callback returns <code>None</code>, the original <code>tool_response</code> is used.  </li> <li>If a new dictionary is returned, it replaces the original <code>tool_response</code>. This allows modifying or filtering the result seen by the LLM.</li> </ol> Code <pre><code>import {\n  LlmAgent,\n} from 'adk-typescript/agents';\nimport {\n  Content,\n  LlmRegistry,\n} from 'adk-typescript/models';\nimport {\n  FunctionTool,\n  ToolContext,\n  BaseTool,\n} from 'adk-typescript/tools';\nimport { runners } from 'adk-typescript';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\n\n// Define the model\nconst GEMINI_2_FLASH = \"gemini-2.0-flash\";\n\n\n// --- Define a Simple Tool Function ---\nfunction getCapitalCity(params: Record&lt;string, any&gt;): Record&lt;string, string&gt; {\n  /**\n   * Retrieves the capital city of a given country.\n   */\n  const country = params.country as string;\n  console.log(`--- Tool 'get_capital_city' executing with country: ${country} ---`);\n  const countryCapitals: Record&lt;string, string&gt; = {\n    \"united states\": \"Washington, D.C.\",\n    \"canada\": \"Ottawa\",\n    \"france\": \"Paris\",\n    \"germany\": \"Berlin\",\n  };\n  return { result: countryCapitals[country.toLowerCase()] || `Capital not found for ${country}` };\n}\n\n// --- Wrap the function into a Tool ---\nconst capitalTool = new FunctionTool(getCapitalCity);\n\n// --- Define the Callback Function ---\nfunction simpleAfterToolModifier(\n  tool: BaseTool, \n  args: Record&lt;string, any&gt;,\n  toolContext: ToolContext,\n  toolResponse: Record&lt;string, any&gt;\n): Record&lt;string, any&gt; | undefined {\n  /**\n   * Inspects/modifies the tool result after execution.\n   */\n  const agentName = toolContext.agentName;\n  const toolName = tool.name;\n  console.log(`[Callback] After tool call for tool '${toolName}' in agent '${agentName}'`);\n  console.log(`[Callback] Args used: ${JSON.stringify(args)}`);\n  console.log(`[Callback] Original tool_response: ${JSON.stringify(toolResponse)}`);\n\n  // Default structure for function tool results is {\"result\": &lt;return_value&gt;}\n  const originalResultValue = toolResponse.result || \"\";\n\n  // --- Modification Example ---\n  // If the tool was 'get_capital_city' and result is 'Washington, D.C.'\n  if (toolName === 'get_capital_city' &amp;&amp; originalResultValue === \"Washington, D.C.\") {\n    console.log(\"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\");\n\n    // IMPORTANT: Create a new object or clone the existing one\n    const modifiedResponse = { ...toolResponse };\n    modifiedResponse.result = `${originalResultValue} (Note: This is the capital of the USA).`;\n    modifiedResponse.note_added_by_callback = true; // Add extra info if needed\n\n    console.log(`[Callback] Modified tool_response: ${JSON.stringify(modifiedResponse)}`);\n    return modifiedResponse; // Return the modified dictionary\n  }\n\n  console.log(\"[Callback] Passing original tool response through.\");\n  // Return undefined to use the original tool_response\n  return undefined;\n}\n\n// Create model instance (using LlmRegistry)\nconst model = LlmRegistry.newLlm(GEMINI_2_FLASH);\n\n// Create LlmAgent and Assign Callback\nconst myLlmAgent = new LlmAgent({\n  name: \"AfterToolCallbackAgent\",\n  model: model,\n  instruction: \"You are an agent that finds capital cities using the get_capital_city tool. Report the result clearly.\",\n  description: \"An LLM agent demonstrating after_tool_callback\",\n  tools: [capitalTool], // Add the tool\n  afterToolCallback: simpleAfterToolModifier // Assign the callback\n});\n\n// Setup constants for the session\nconst APP_NAME = \"guardrail_app\";\nconst USER_ID = \"user_1\";\nconst SESSION_ID = \"session_001\";\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nsessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: myLlmAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nasync function callAgent(query: string): Promise&lt;void&gt; {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  try {\n    const events = runner.run({\n      userId: USER_ID, \n      sessionId: SESSION_ID, \n      newMessage: content\n    });\n\n    for await (const event of events) {\n      if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n        const finalResponse = event.content.parts[0].text;\n        console.log(\"Agent Response: \", finalResponse);\n      } else if (event.errorCode) {\n        console.log(`Error Event: [${event.errorCode}] ${event.errorMessage}`);\n      }\n    }\n  } catch (error) {\n    console.error(\"Error running agent:\", error);\n  }\n}\n\n// Execute with a sample query\ncallAgent(\"What is the capital of United States?\");\nsetTimeout(() =&gt; {\n  console.log(\"\\nTrying with a different country:\");\n  callAgent(\"What is the capital of France?\");\n}, 2000);\n\n// Export for external use\nexport const agent = myLlmAgent;\nexport async function runAfterToolCallbackDemo(query: string): Promise&lt;void&gt; {\n  await callAgent(query);\n} \n</code></pre>"},{"location":"context/","title":"Context","text":""},{"location":"context/#what-are-context","title":"What are Context","text":"<p>In the Agent Development Kit (ADK), \"context\" refers to the crucial bundle of information available to your agent and its tools during specific operations. Think of it as the necessary background knowledge and resources needed to handle a current task or conversation turn effectively.</p> <p>Agents often need more than just the latest user message to perform well. Context is essential because it enables:</p> <ol> <li>Maintaining State: Remembering details across multiple steps in a conversation (e.g., user preferences, previous calculations, items in a shopping cart). This is primarily managed through session state.</li> <li>Passing Data: Sharing information discovered or generated in one step (like an LLM call or a tool execution) with subsequent steps. Session state is key here too.</li> <li>Accessing Services: Interacting with framework capabilities like:<ul> <li>Artifact Storage: Saving or loading files or data blobs (like PDFs, images, configuration files) associated with the session.</li> <li>Memory: Searching for relevant information from past interactions or external knowledge sources connected to the user.</li> <li>Authentication: Requesting and retrieving credentials needed by tools to access external APIs securely.</li> </ul> </li> <li>Identity and Tracking: Knowing which agent is currently running (<code>agent.name</code>) and uniquely identifying the current request-response cycle (<code>invocationId</code>) for logging and debugging.</li> <li>Tool-Specific Actions: Enabling specialized operations within tools, such as requesting authentication or searching memory, which require access to the current interaction's details.</li> </ol> <p>The central piece holding all this information together for a single, complete user-request-to-final-response cycle (an invocation) is the <code>InvocationContext</code>. However, you typically won't create or manage this object directly. The ADK framework creates it when an invocation starts (e.g., via <code>runner.runAsync()</code>) and passes the relevant contextual information implicitly to your agent code, callbacks, and tools.</p> <pre><code>// Conceptual Pseudocode: How the framework provides context (Internal Logic)\n\n// const runner = new Runner({\n//   agent: myRootAgent, \n//   sessionService: sessionService, \n//   artifactService: artifactService\n// });\n// const userMessage = { ... }; // Content object\n// const session = await sessionService.getSession(...); // Or create new\n\n// --- Inside runner.runAsync(...) ---\n// 1. Framework creates the main context for this specific run\n// const invocationContext = new InvocationContext({\n//   invocationId: \"unique-id-for-this-run\",\n//   session: session,\n//   userContent: userMessage,\n//   agent: myRootAgent, // The starting agent\n//   sessionService: sessionService,\n//   artifactService: artifactService,\n//   memoryService: memoryService,\n//   // ... other necessary fields ...\n// });\n\n// 2. Framework calls the agent's run method, passing the context implicitly\n// await myRootAgent.runAsync(invocationContext);\n// --- End Internal Logic ---\n\n// As a developer, you work with the context objects provided in method arguments.\n</code></pre>"},{"location":"context/#the-different-types-of-context","title":"The Different types of Context","text":"<p>While <code>InvocationContext</code> acts as the comprehensive internal container, ADK provides specialized context objects tailored to specific situations. This ensures you have the right tools and permissions for the task at hand without needing to handle the full complexity of the internal context everywhere. Here are the different \"flavors\" you'll encounter:</p> <ol> <li> <p><code>InvocationContext</code></p> <ul> <li>Where Used: Received as the <code>ctx</code> argument directly within an agent's core implementation methods (<code>runAsyncImpl</code>, <code>runLiveImpl</code>).</li> <li>Purpose: Provides access to the entire state of the current invocation. This is the most comprehensive context object.</li> <li>Key Contents: Direct access to <code>session</code> (including <code>state</code> and <code>events</code>), the current <code>agent</code> instance, <code>invocationId</code>, initial <code>userContent</code>, references to configured services (<code>artifactService</code>, <code>memoryService</code>, <code>sessionService</code>), and fields related to live/streaming modes.</li> <li>Use Case: Primarily used when the agent's core logic needs direct access to the overall session or services, though often state and artifact interactions are delegated to callbacks/tools which use their own contexts. Also used to control the invocation itself (e.g., setting <code>ctx.endInvocation = true</code>).</li> </ul> <pre><code>// Example: Agent implementation receiving InvocationContext\nimport { BaseAgent, InvocationContext } from '../agents';\nimport { Event } from '../events/Event';\n\nclass MyAgent extends BaseAgent {\n  async *runAsyncImpl(ctx: InvocationContext): AsyncGenerator&lt;Event&gt; {\n    // Direct access example\n    const agentName = ctx.agent.name;\n    const sessionId = ctx.session.id;\n    console.log(`Agent ${agentName} running in session ${sessionId} for invocation ${ctx.invocationId}`);\n    // ... agent logic using ctx ...\n    yield new Event({ /* ... */ });\n  }\n}\n</code></pre> </li> <li> <p><code>ReadonlyContext</code></p> <ul> <li>Where Used: Provided in scenarios where only read access to basic information is needed and mutation is disallowed (e.g., instruction provider functions). It's also the base class for other contexts.</li> <li>Purpose: Offers a safe, read-only view of fundamental contextual details.</li> <li>Key Contents: <code>invocationId</code>, <code>agentName</code>, and a read-only view of the current <code>state</code>.</li> </ul> <pre><code>// Example: Instruction provider receiving ReadonlyContext\nimport { ReadonlyContext } from '../agents';\n\nfunction myInstructionProvider(context: ReadonlyContext): string {\n  // Read-only access example\n  const userTier = context.state.get(\"userTier\", \"standard\"); // Can read state\n  // context.state['newKey'] = 'value'; // This would typically cause an error or be ineffective\n  return `Process the request for a ${userTier} user.`;\n}\n</code></pre> </li> <li> <p><code>CallbackContext</code></p> <ul> <li>Where Used: Passed as <code>callbackContext</code> to agent lifecycle callbacks (<code>beforeAgentCallback</code>, <code>afterAgentCallback</code>) and model interaction callbacks (<code>beforeModelCallback</code>, <code>afterModelCallback</code>).</li> <li>Purpose: Facilitates inspecting and modifying state, interacting with artifacts, and accessing invocation details specifically within callbacks.</li> <li>Key Capabilities (Adds to <code>ReadonlyContext</code>):<ul> <li>Mutable <code>state</code> Property: Allows reading and writing to session state. Changes made here (<code>callbackContext.state['key'] = value</code>) are tracked and associated with the event generated by the framework after the callback.</li> <li>Artifact Methods: <code>loadArtifact(filename)</code> and <code>saveArtifact(filename, part)</code> methods for interacting with the configured <code>artifactService</code>.</li> <li>Direct <code>userContent</code> access.</li> </ul> </li> </ul> <pre><code>// Example: Callback receiving CallbackContext\nimport { CallbackContext } from '../agents';\nimport { LlmRequest } from '../models';\nimport { Content } from '../models/types';\n\nfunction myBeforeModelCb(callbackContext: CallbackContext, request: LlmRequest): Content | null {\n  // Read/Write state example\n  const callCount = callbackContext.state.get(\"modelCalls\", 0);\n  callbackContext.state[\"modelCalls\"] = callCount + 1; // Modify state\n\n  // Optionally load an artifact\n  // const configPart = callbackContext.loadArtifact(\"model_config.json\");\n  console.log(`Preparing model call #${callCount + 1} for invocation ${callbackContext.invocationId}`);\n  return null; // Allow model call to proceed\n}\n</code></pre> </li> <li> <p><code>ToolContext</code></p> <ul> <li>Where Used: Passed as <code>toolContext</code> to the functions backing <code>FunctionTool</code>s and to tool execution callbacks (<code>beforeToolCallback</code>, <code>afterToolCallback</code>).</li> <li>Purpose: Provides a simplified context for tool execution, with access to the session and additional context properties.</li> <li>Key Capabilities:<ul> <li>Extends <code>CallbackContext</code>: Inherits all capabilities of <code>CallbackContext</code>, including <code>loadArtifact</code> and <code>saveArtifact</code> methods.</li> <li>Artifact Methods: Adds <code>listArtifacts()</code> method to enumerate available artifacts.</li> <li>Memory Search: Provides <code>searchMemory(query: string)</code> to access memory services.</li> <li>Authentication: Methods for handling credentials via <code>requestCredential(authConfig)</code> and <code>getAuthResponse(authConfig)</code>.</li> <li>Helper Methods: <code>has(key)</code>, <code>get(key, defaultValue)</code>, and <code>set(key, value)</code> for managing context properties.</li> <li>Function Call ID: Maintains a reference to the current <code>functionCallId</code> to link tool executions with their calling events.</li> </ul> </li> </ul> <pre><code>// Example: Tool function receiving ToolContext\nimport { ToolContext } from '../tools';\n\n// Assume this function is wrapped by a FunctionTool\nfunction searchExternalApi(query: string, toolContext: ToolContext): Record&lt;string, any&gt; {\n  // Access to parent CallbackContext methods like loadArtifact\n  const configArtifact = toolContext.loadArtifact(\"api_config.json\");\n\n  // ToolContext-specific memory search capabilities\n  const memoryResults = toolContext.searchMemory(query);\n\n  // Auth handling\n  const apiKey = toolContext.get('apiKey');\n  if (!apiKey) {\n    // Request authentication if needed\n    toolContext.requestCredential({/* auth config */});\n    return { status: \"Auth Required\" };\n  }\n\n  // Set a value in the context if needed\n  toolContext.set('lastQuery', query);\n\n  return { \n    result: `Data for ${query} fetched.`,\n    memoryResults\n  };\n}\n</code></pre> </li> </ol> <p>Understanding these different context objects and when to use them is key to effectively managing state, accessing services, and controlling the flow of your ADK application. The next section will detail common tasks you can perform using these contexts.</p>"},{"location":"context/#common-tasks-using-context","title":"Common Tasks Using Context","text":"<p>Now that you understand the different context objects, let's focus on how to use them for common tasks when building your agents and tools.</p>"},{"location":"context/#accessing-information","title":"Accessing Information","text":"<p>You'll frequently need to read information stored within the context.</p> <ul> <li> <p>Reading Session State: Access data saved in previous steps or user/app-level settings.</p> <pre><code>// Example: In a Tool function\nimport { ToolContext } from '../tools';\n\nfunction myTool(toolContext: ToolContext): Record&lt;string, any&gt; {\n  const userPref = toolContext.session.state.get(\"userDisplayPreference\", \"default_mode\");\n  const apiEndpoint = toolContext.session.state.get(\"app:apiEndpoint\"); // Read app-level state\n\n  if (userPref === \"dark_mode\") {\n    // ... apply dark mode logic ...\n  }\n  console.log(`Using API endpoint: ${apiEndpoint}`);\n  // ... rest of tool logic ...\n  return { /* result */ };\n}\n\n// Example: In a Callback function\nimport { CallbackContext } from '../agents';\n\nfunction myCallback(callbackContext: CallbackContext): void {\n  const lastToolResult = callbackContext.state.get(\"temp:lastApiResult\"); // Read temporary state\n  if (lastToolResult) {\n    console.log(`Found temporary result from last tool: ${lastToolResult}`);\n  }\n  // ... callback logic ...\n}\n</code></pre> </li> <li> <p>Getting Current Identifiers: Useful for logging or custom logic based on the current operation.</p> <pre><code>// Example: In any context (ToolContext shown)\nimport { ToolContext } from '../tools';\n\nfunction logToolUsage(toolContext: ToolContext): Record&lt;string, any&gt; {\n  const agentName = toolContext.get('agentName', 'unknown');\n  const invId = toolContext.session.id;\n  const funcCallId = toolContext.get('functionCallId', 'N/A');\n\n  console.log(`Log: Session=${invId}, Agent=${agentName}, FunctionCallID=${funcCallId} - Tool Executed.`);\n  return { /* result */ };\n}\n</code></pre> </li> <li> <p>Accessing the Initial User Input: Refer back to the message that started the current invocation.</p> <pre><code>// Example: In a Callback\nimport { CallbackContext } from '../agents';\n\nfunction checkInitialIntent(callbackContext: CallbackContext): void {\n  let initialText = \"N/A\";\n  if (callbackContext.userContent &amp;&amp; callbackContext.userContent.parts) {\n    initialText = callbackContext.userContent.parts[0].text || \"Non-text input\";\n  }\n\n  console.log(`This invocation started with user input: '${initialText}'`);\n}\n\n// Example: In an Agent's runAsyncImpl\n// async *runAsyncImpl(ctx: InvocationContext): AsyncGenerator&lt;Event&gt; {\n//   if (ctx.userContent &amp;&amp; ctx.userContent.parts) {\n//     const initialText = ctx.userContent.parts[0].text;\n//     console.log(`Agent logic remembering initial query: ${initialText}`);\n//   }\n//   // ...\n// }\n</code></pre> </li> </ul>"},{"location":"context/#managing-session-state","title":"Managing Session State","text":"<p>State is crucial for memory and data flow. When you modify state using <code>CallbackContext</code> or accessing state via <code>ToolContext</code>, the changes are tracked and persisted by the framework.</p> <ul> <li>How it Works: Writing to <code>callbackContext.state['myKey'] = myValue</code> or <code>toolContext.session.state['myKey'] = myValue</code> adds this change to the state which will be persisted by the framework.</li> <li> <p>Passing Data Between Tools:</p> <pre><code>// Example: Tool 1 - Fetches user ID\nimport { ToolContext } from '../tools';\nimport { v4 as uuidv4 } from 'uuid';\n\nfunction getUserProfile(toolContext: ToolContext): Record&lt;string, any&gt; {\n  const userId = uuidv4(); // Simulate fetching ID\n  // Save the ID to state for the next tool\n  toolContext.session.state[\"temp:currentUserId\"] = userId;\n  return { profileStatus: \"ID generated\" };\n}\n\n// Example: Tool 2 - Uses user ID from state\nfunction getUserOrders(toolContext: ToolContext): Record&lt;string, any&gt; {\n  const userId = toolContext.session.state.get(\"temp:currentUserId\");\n  if (!userId) {\n    return { error: \"User ID not found in state\" };\n  }\n\n  console.log(`Fetching orders for user ID: ${userId}`);\n  // ... logic to fetch orders using userId ...\n  return { orders: [\"order123\", \"order456\"] };\n}\n</code></pre> </li> <li> <p>Updating User Preferences:</p> <pre><code>// Example: Tool or Callback identifies a preference\nimport { ToolContext } from '../tools'; // Or CallbackContext\n\nfunction setUserPreference(toolContext: ToolContext, preference: string, value: string): Record&lt;string, any&gt; {\n  // Use 'user:' prefix for user-level state (if using a persistent SessionService)\n  const stateKey = `user:${preference}`;\n  toolContext.session.state[stateKey] = value;\n  console.log(`Set user preference '${preference}' to '${value}'`);\n  return { status: \"Preference updated\" };\n}\n</code></pre> </li> <li> <p>State Prefixes: While basic state is session-specific, prefixes like <code>app:</code> and <code>user:</code> can be used with persistent <code>SessionService</code> implementations to indicate broader scope (app-wide or user-wide across sessions). <code>temp:</code> can denote data only relevant within the current invocation.</p> </li> </ul>"},{"location":"context/#working-with-artifacts","title":"Working with Artifacts","text":"<p>Use artifacts to handle files or large data blobs associated with the session. Common use case: processing uploaded documents.</p> <ul> <li> <p>Document Summarizer Example Flow:</p> <ol> <li> <p>Ingest Reference (e.g., in a Setup Tool or Callback): Save the path or URI of the document, not the entire content, as an artifact.</p> <pre><code>// Example: In a callback or initial tool\nimport { CallbackContext } from '../agents'; // Or ToolContext\nimport { Part } from '../models/types';\n\nasync function saveDocumentReference(context: CallbackContext, filePath: string): Promise&lt;void&gt; {\n  // Assume filePath is something like \"gs://my-bucket/docs/report.pdf\" or \"/local/path/to/report.pdf\"\n  try {\n    // Create a Part containing the path/URI text\n    const artifactPart: Part = { text: filePath };\n    const version = await context.saveArtifact(\"document_to_summarize.txt\", artifactPart);\n    console.log(`Saved document reference '${filePath}' as artifact version ${version}`);\n    // Store the filename in state if needed by other tools\n    context.state[\"temp:docArtifactName\"] = \"document_to_summarize.txt\";\n  } catch (e) {\n    console.log(`Error saving artifact: ${e}`); // E.g., Artifact service not configured\n  }\n}\n\n// Example usage:\n// await saveDocumentReference(callbackContext, \"gs://my-bucket/docs/report.pdf\");\n</code></pre> </li> <li> <p>Summarizer Tool: Load the artifact to get the path/URI, read the actual document content using appropriate libraries, summarize, and return the result.</p> <pre><code>// Example: In the Summarizer tool function\nimport { ToolContext } from '../tools';\nimport { Part } from '../models/types';\n\nasync function summarizeDocumentTool(toolContext: ToolContext): Promise&lt;Record&lt;string, any&gt;&gt; {\n  const artifactName = toolContext.session.state.get(\"temp:docArtifactName\");\n  if (!artifactName) {\n    return { error: \"Document artifact name not found in state.\" };\n  }\n\n  try {\n    // ToolContext extends CallbackContext, so it has loadArtifact method\n    const artifactPart = await toolContext.loadArtifact(artifactName);\n    if (!artifactPart || !artifactPart.text) {\n      return { error: `No artifact data available: ${artifactName}` };\n    }\n\n    const filePath = artifactPart.text;\n    console.log(`Using document reference: ${filePath}`);\n\n    // Read the file and process it...\n    // (file reading code would go here)\n\n    return { summary: `Summary of content from ${filePath}` };\n  } catch (e) {\n    if (e instanceof Error) {\n      return { error: `Error processing document: ${e.message}` };\n    }\n    return { error: \"Unknown error occurred\" };\n  }\n}\n</code></pre> </li> </ol> </li> <li> <p>Listing Artifacts: If you need to work with artifacts, do so via the appropriate context.</p> <pre><code>// Example: Using CallbackContext to work with artifacts\nimport { CallbackContext } from '../agents';\n\nasync function handleArtifacts(callbackContext: CallbackContext): Promise&lt;void&gt; {\n  try {\n    // CallbackContext has loadArtifact and saveArtifact methods\n    // Load an existing artifact\n    const artifact = await callbackContext.loadArtifact(\"document.txt\");\n    console.log(\"Loaded artifact content:\", artifact?.text);\n\n    // Save a new artifact\n    const newArtifact: Part = { text: \"This is new artifact content\" };\n    const version = await callbackContext.saveArtifact(\"new-document.txt\", newArtifact);\n    console.log(`Saved new artifact with version ${version}`);\n  } catch (e) {\n    console.error(\"Error handling artifacts:\", e);\n  }\n}\n</code></pre> </li> </ul>"},{"location":"context/#authentication-handling","title":"Authentication Handling","text":"<p>Managing authentication for tools that need to access external services.</p> <pre><code>// Example: Tool requiring auth\nimport { ToolContext } from '../tools';\n\n// Define a key to store credentials\nconst AUTH_STATE_KEY = \"user:myApiCredential\";\n\nfunction callSecureApi(toolContext: ToolContext, requestData: string): Record&lt;string, any&gt; {\n  // 1. Check if credential already exists in state\n  const credential = toolContext.session.state.get(AUTH_STATE_KEY);\n\n  if (!credential) {\n    // 2. Handle missing credential\n    console.log(\"Credential not found\");\n\n    // Request auth implementation depends on your framework's specifics\n    // This is a simplified example\n    toolContext.set('needsAuth', true);\n    return { status: \"Authentication required. Please provide credentials.\" };\n  }\n\n  // 3. Use credential to make API call\n  console.log(`Using credential to call API with data: ${requestData}`);\n  // ... Make the actual API call using credential ...\n  const apiResult = `API result for ${requestData}`;\n\n  return { result: apiResult };\n}\n</code></pre>"},{"location":"context/#leveraging-memory","title":"Leveraging Memory","text":"<p>Access relevant information from the past or external sources.</p> <pre><code>// Example: Tool using memory search\nimport { ToolContext } from '../tools';\n\nfunction findRelatedInfo(toolContext: ToolContext, topic: string): Record&lt;string, any&gt; {\n  try {\n    // ToolContext has a dedicated searchMemory method\n    const searchResults = toolContext.searchMemory(`Information about ${topic}`);\n\n    if (searchResults) {\n      // Process the search results\n      // searchResults is of type SearchMemoryResponse, which includes a list of results\n      return { \n        found: true,\n        memoryResults: searchResults \n      };\n    } else {\n      return { message: \"No relevant memories found.\" };\n    }\n  } catch (e) {\n    if (e instanceof Error) {\n      return { error: `Memory service error: ${e.message}` }; // e.g., Service not configured\n    }\n    return { error: \"Unexpected error searching memory\" };\n  }\n}\n</code></pre>"},{"location":"context/#advanced-direct-invocationcontext-usage","title":"Advanced: Direct <code>InvocationContext</code> Usage","text":"<p>While most interactions happen via specialized contexts, sometimes the agent's core logic (<code>runAsyncImpl</code>/<code>runLiveImpl</code>) needs direct access.</p> <pre><code>// Example: Inside agent's runAsyncImpl\nimport { InvocationContext, BaseAgent } from '../agents';\nimport { Event } from '../events/Event';\n\nclass MyControllingAgent extends BaseAgent {\n  async *runAsyncImpl(ctx: InvocationContext): AsyncGenerator&lt;Event&gt; {\n    // Example: Check if a specific service is available\n    if (!ctx.memoryService) {\n      console.log(\"Memory service is not available for this invocation.\");\n      // Potentially change agent behavior\n    }\n\n    // Example: Early termination based on some condition\n    if (ctx.session.state.get(\"criticalErrorFlag\")) {\n      console.log(\"Critical error detected, ending invocation.\");\n      ctx.endInvocation = true; // Signal framework to stop processing\n      yield new Event({\n        author: this.name,\n        invocationId: ctx.invocationId,\n        content: { parts: [{ text: \"Stopping due to critical error.\" }] }\n      });\n      return; // Stop this agent's execution\n    }\n\n    // ... Normal agent processing ...\n    yield new Event({ /* event details */ });\n  }\n}\n</code></pre> <p>Setting <code>ctx.endInvocation = true</code> is a way to gracefully stop the entire request-response cycle from within the agent or its callbacks/tools.</p>"},{"location":"context/#key-takeaways-best-practices","title":"Key Takeaways &amp; Best Practices","text":"<ul> <li>Use the Right Context: Always use the most specific context object provided (<code>ToolContext</code> in tools/tool-callbacks, <code>CallbackContext</code> in agent/model-callbacks, <code>ReadonlyContext</code> where applicable). Use the full <code>InvocationContext</code> (<code>ctx</code>) directly in <code>runAsyncImpl</code> / <code>runLiveImpl</code> only when necessary.</li> <li>State for Data Flow: Session state is the primary way to share data, remember preferences, and manage conversational memory within an invocation. Use prefixes (<code>app:</code>, <code>user:</code>, <code>temp:</code>) thoughtfully when using persistent storage.</li> <li>Artifacts for Files: Use <code>saveArtifact</code> and <code>loadArtifact</code> for managing file references (like paths or URIs) or larger data blobs. Store references, load content on demand.</li> <li>Tracked Changes: Modifications to state or artifacts are automatically managed by the framework.</li> <li>Start Simple: Focus on <code>state</code> and basic artifact usage first. Explore authentication, memory, and advanced <code>InvocationContext</code> fields (like those for live streaming) as your needs become more complex. When building more sophisticated agents, gradually incorporate additional context capabilities as your understanding of the framework deepens.</li> </ul> <p>By understanding and effectively using these context objects, you can build more sophisticated, stateful, and capable agents with the TypeScript ADK.</p>"},{"location":"deploy/","title":"Deploying Your Agent","text":"<p>Once you've built and tested your agent using ADK TypeScript, the next step is to deploy it so it can be accessed, queried, and used in production or integrated with other applications. Deployment moves your agent from your local development machine to a scalable and reliable environment.</p> <p></p>"},{"location":"deploy/#deployment-options","title":"Deployment Options","text":"<p>Your ADK TypeScript agent can be deployed to a range of different environments based on your needs for production readiness or custom flexibility:</p>"},{"location":"deploy/#agent-engine-in-vertex-ai","title":"Agent Engine in Vertex AI","text":"<p>Agent Engine is a fully managed auto-scaling service on Google Cloud specifically designed for deploying, managing, and scaling AI agents built with frameworks such as ADK TypeScript. It provides a serverless deployment experience with automatic scaling, high availability, and simple management.</p> <p>Learn more about deploying your agent to Vertex AI Agent Engine.</p>"},{"location":"deploy/#cloud-run","title":"Cloud Run","text":"<p>Cloud Run is a managed auto-scaling compute platform on Google Cloud that enables you to run your agent as a container-based application. It's a great option for when you need more control over your deployment while still benefiting from managed infrastructure.</p> <p>Learn more about deploying your agent to Cloud Run.</p>"},{"location":"deploy/#google-kubernetes-engine-gke","title":"Google Kubernetes Engine (GKE)","text":"<p>GKE is Google Cloud's managed Kubernetes service that gives you the highest degree of control and customization for your agent deployment. This is ideal for complex production scenarios with specific networking, scaling, or integration requirements.</p> <p>Learn more about deploying your agent to GKE.</p>"},{"location":"deploy/agent-engine/","title":"Deploy to Vertex AI Agent Engine","text":"<p>Agent Engine is a fully managed Google Cloud service enabling developers to deploy, manage, and scale AI agents in production. Agent Engine handles the infrastructure to scale agents in production so you can focus on creating intelligent and impactful applications.</p> <pre><code>import { AgentEngine } from '@google-cloud/vertexai';\n\n// Create and deploy your agent to Agent Engine\nconst remoteApp = await AgentEngine.create({\n  agent: rootAgent,\n  dependencies: [\n    \"@google-cloud/vertexai\",\n    \"adk-typescript\"\n  ]\n});\n</code></pre>"},{"location":"deploy/agent-engine/#install-vertex-ai-sdk","title":"Install Vertex AI SDK","text":"<p>Agent Engine is part of the Vertex AI SDK for Node.js. For more information, you can review the Agent Engine quickstart documentation.</p>"},{"location":"deploy/agent-engine/#install-the-vertex-ai-sdk","title":"Install the Vertex AI SDK","text":"<pre><code>npm install @google-cloud/vertexai\n# You'll also need the ADK TypeScript package\nnpm install adk-typescript\n</code></pre> <p>Info</p> <p>Make sure you have Node.js version 18.0.0 or higher installed.</p>"},{"location":"deploy/agent-engine/#initialization","title":"Initialization","text":"<pre><code>import { VertexAI } from '@google-cloud/vertexai';\n\nconst PROJECT_ID = \"your-project-id\";\nconst LOCATION = \"us-central1\";\n\n// Initialize Vertex AI\nconst vertexAI = new VertexAI({\n  project: PROJECT_ID,\n  location: LOCATION,\n});\n</code></pre> <p>For <code>LOCATION</code>, you can check out the list of supported regions in Agent Engine.</p>"},{"location":"deploy/agent-engine/#create-your-agent","title":"Create your agent","text":"<p>You can create a simple agent with TypeScript that has two tools (for getting weather and retrieving time in a specified city):</p> <pre><code>import { Agent, FunctionTool } from 'adk-typescript';\n\n// Define tool functions\nfunction getWeather(params: { city: string }): object {\n  const { city } = params;\n  // This is a mock implementation\n  return {\n    status: \"success\",\n    report: `The weather in ${city} is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).`\n  };\n}\n\nfunction getTime(params: { city: string }): object {\n  const { city } = params;\n  // This is a mock implementation\n  return {\n    status: \"success\",\n    time: `The current time in ${city} is 3:45 PM.`\n  };\n}\n\n// Create tools\nconst weatherTool = new FunctionTool({\n  name: \"get_weather\",\n  description: \"Get the current weather for a specific city\",\n  func: getWeather\n});\n\nconst timeTool = new FunctionTool({\n  name: \"get_time\",\n  description: \"Get the current time for a specific city\",\n  func: getTime\n});\n\n// Create the agent\nconst rootAgent = new Agent({\n  name: \"multi_tool_agent\",\n  model: \"gemini-2.0-flash\",\n  description: \"An agent that can get weather and time information for cities\",\n  tools: [weatherTool, timeTool],\n  instruction: \"You can help users get weather and time information for different cities.\"\n});\n</code></pre>"},{"location":"deploy/agent-engine/#prepare-your-agent-for-agent-engine","title":"Prepare your agent for Agent Engine","text":"<p>Use the Agent Engine SDK to wrap your agent to make it deployable to Agent Engine:</p> <pre><code>import { AgentEngineApp } from '@google-cloud/vertexai';\n\nconst app = new AgentEngineApp({\n  agent: rootAgent,\n  enableTracing: true,\n});\n</code></pre>"},{"location":"deploy/agent-engine/#try-your-agent-locally","title":"Try your agent locally","text":"<p>You can try it locally before deploying to Agent Engine.</p>"},{"location":"deploy/agent-engine/#create-session-local","title":"Create session (local)","text":"<pre><code>const session = await app.createSession({ userId: \"u_123\" });\nconsole.log(session);\n</code></pre> <p>Expected output for <code>createSession</code> (local):</p> <pre><code>{\n  id: 'c6a33dae-26ef-410c-9135-b434a528291f',\n  appName: 'default-app-name',\n  userId: 'u_123',\n  state: {},\n  events: [],\n  lastUpdateTime: 1743440392.8689594\n}\n</code></pre>"},{"location":"deploy/agent-engine/#list-sessions-local","title":"List sessions (local)","text":"<pre><code>const sessions = await app.listSessions({ userId: \"u_123\" });\nconsole.log(sessions);\n</code></pre> <p>Expected output for <code>listSessions</code> (local):</p> <pre><code>{\n  sessionIds: ['c6a33dae-26ef-410c-9135-b434a528291f']\n}\n</code></pre>"},{"location":"deploy/agent-engine/#get-a-specific-session-local","title":"Get a specific session (local)","text":"<pre><code>const retrievedSession = await app.getSession({\n  userId: \"u_123\",\n  sessionId: session.id\n});\nconsole.log(retrievedSession);\n</code></pre> <p>Expected output for <code>getSession</code> (local):</p> <pre><code>{\n  id: 'c6a33dae-26ef-410c-9135-b434a528291f',\n  appName: 'default-app-name',\n  userId: 'u_123',\n  state: {},\n  events: [],\n  lastUpdateTime: 1743681991.95696\n}\n</code></pre>"},{"location":"deploy/agent-engine/#send-queries-to-your-agent-local","title":"Send queries to your agent (local)","text":"<pre><code>// Using async iterator with for-await-of\nconst events = app.streamQuery({\n  userId: \"u_123\",\n  sessionId: session.id,\n  message: \"whats the weather in new york\"\n});\n\nfor await (const event of events) {\n  console.log(event);\n}\n</code></pre> <p>Expected output for <code>streamQuery</code> (local):</p> <pre><code>{parts: [{functionCall: {id: 'af-a33fedb0-29e6-4d0c-9eb3-00c402969395', args: {city: 'new york'}, name: 'get_weather'}}], role: 'model'}\n{parts: [{functionResponse: {id: 'af-a33fedb0-29e6-4d0c-9eb3-00c402969395', name: 'get_weather', response: {status: 'success', report: 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}}}], role: 'user'}\n{parts: [{text: 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}], role: 'model'}\n</code></pre>"},{"location":"deploy/agent-engine/#deploy-your-agent-to-agent-engine","title":"Deploy your agent to Agent Engine","text":"<pre><code>import { AgentEngine } from '@google-cloud/vertexai';\n\nconst remoteApp = await AgentEngine.create({\n  agent: rootAgent,\n  dependencies: [\n    \"@google-cloud/vertexai\",\n    \"adk-typescript\"\n  ]\n});\n</code></pre> <p>This step may take several minutes to finish.</p>"},{"location":"deploy/agent-engine/#grant-the-deployed-agent-permissions","title":"Grant the deployed agent permissions","text":"<p>Before proceeding to query your agent on Agent Engine, your deployed agent must first be granted additional permissions before it can use managed sessions. Managed sessions are a built-in component of Agent Engine that enables agents to keep track of the state of a conversation. Without granting the deploy agent the permissions below, you may see errors when querying your deployed agent.</p> <p>You can follow the instructions in Set up your service agent permissions to grant the following permissions via the IAM admin page:</p> <ul> <li>Vertex AI User (<code>roles/aiplatform.user</code>) to your <code>service-PROJECT_NUMBER@gcp-sa-aiplatform-re.iam.gserviceaccount.com</code> service account</li> </ul>"},{"location":"deploy/agent-engine/#try-your-agent-on-agent-engine","title":"Try your agent on Agent Engine","text":""},{"location":"deploy/agent-engine/#create-session-remote","title":"Create session (remote)","text":"<pre><code>const remoteSession = await remoteApp.createSession({ userId: \"u_456\" });\nconsole.log(remoteSession);\n</code></pre> <p>Expected output for <code>createSession</code> (remote):</p> <pre><code>{\n  events: [],\n  userId: 'u_456',\n  state: {},\n  id: '7543472750996750336',\n  appName: '7917477678498709504',\n  lastUpdateTime: 1743683353.030133\n}\n</code></pre> <p><code>id</code> is the session ID, and <code>appName</code> is the resource ID of the deployed agent on Agent Engine.</p>"},{"location":"deploy/agent-engine/#list-sessions-remote","title":"List sessions (remote)","text":"<pre><code>const remoteSessions = await remoteApp.listSessions({ userId: \"u_456\" });\nconsole.log(remoteSessions);\n</code></pre>"},{"location":"deploy/agent-engine/#get-a-specific-session-remote","title":"Get a specific session (remote)","text":"<pre><code>const retrievedRemoteSession = await remoteApp.getSession({\n  userId: \"u_456\", \n  sessionId: remoteSession.id\n});\nconsole.log(retrievedRemoteSession);\n</code></pre> <p>Note</p> <p>While using your agent locally, session ID is stored in <code>session.id</code> property, when using your agent remotely on Agent Engine, it's accessed the same way with <code>remoteSession.id</code>.</p>"},{"location":"deploy/agent-engine/#send-queries-to-your-agent-remote","title":"Send queries to your agent (remote)","text":"<pre><code>// Using async iterator with for-await-of\nconst remoteEvents = remoteApp.streamQuery({\n  userId: \"u_456\",\n  sessionId: remoteSession.id,\n  message: \"whats the weather in new york\"\n});\n\nfor await (const event of remoteEvents) {\n  console.log(event);\n}\n</code></pre> <p>Expected output for <code>streamQuery</code> (remote):</p> <pre><code>{parts: [{functionCall: {id: 'af-f1906423-a531-4ecf-a1ef-723b05e85321', args: {city: 'new york'}, name: 'get_weather'}}], role: 'model'}\n{parts: [{functionResponse: {id: 'af-f1906423-a531-4ecf-a1ef-723b05e85321', name: 'get_weather', response: {status: 'success', report: 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}}}], role: 'user'}\n{parts: [{text: 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}], role: 'model'}\n</code></pre>"},{"location":"deploy/agent-engine/#clean-up","title":"Clean up","text":"<p>After you've finished, it's a good practice to clean up your cloud resources. You can delete the deployed Agent Engine instance to avoid any unexpected charges on your Google Cloud account.</p> <pre><code>await remoteApp.delete({ force: true });\n</code></pre> <p>The <code>force: true</code> option will also delete any child resources that were generated from the deployed agent, such as sessions.</p>"},{"location":"deploy/cloud-run/","title":"Deploy to Cloud Run","text":"<p>Cloud Run is a fully managed platform that enables you to run your code directly on top of Google's scalable infrastructure.</p> <p>To deploy your agent, you can use either the <code>adk deploy cloud_run</code> command (recommended), or with <code>gcloud run deploy</code> command through Cloud Run.</p>"},{"location":"deploy/cloud-run/#agent-sample","title":"Agent sample","text":"<p>For each of the commands, we will reference a <code>capital_agent</code> sample defined in the Agent documentation page. We will assume it's in a <code>capital_agent</code> directory.</p> <p>To proceed, confirm that your agent code is configured as follows:</p> <ol> <li>Agent code is in a file called <code>index.ts</code> within your agent directory.</li> <li>Your agent variable is named <code>rootAgent</code>.</li> <li>The agent is properly exported from the module.</li> </ol>"},{"location":"deploy/cloud-run/#environment-variables","title":"Environment variables","text":"<p>Set your environment variables as described in the Setup and Installation guide.</p> <pre><code>export GOOGLE_CLOUD_PROJECT=your-project-id\nexport GOOGLE_CLOUD_LOCATION=us-central1 # Or your preferred location\n</code></pre> <p>(Replace <code>your-project-id</code> with your actual GCP project ID)</p>"},{"location":"deploy/cloud-run/#deployment-commands","title":"Deployment commands","text":"adk CLIgcloud CLI"},{"location":"deploy/cloud-run/#adk-cli","title":"adk CLI","text":"<p>The <code>adk deploy cloud_run</code> command deploys your agent code to Google Cloud Run.</p> <p>Ensure you have authenticated with Google Cloud (<code>gcloud auth login</code> and <code>gcloud config set project &lt;your-project-id&gt;</code>).</p>"},{"location":"deploy/cloud-run/#setup-environment-variables","title":"Setup environment variables","text":"<p>Optional but recommended: Setting environment variables can make the deployment commands cleaner.</p> <pre><code># Set your Google Cloud Project ID\nexport GOOGLE_CLOUD_PROJECT=\"your-gcp-project-id\"\n\n# Set your desired Google Cloud Location\nexport GOOGLE_CLOUD_LOCATION=\"us-central1\" # Example location\n\n# Set the path to your agent code directory\nexport AGENT_PATH=\"./capital_agent\" # Assuming capital_agent is in the current directory\n\n# Set a name for your Cloud Run service (optional)\nexport SERVICE_NAME=\"capital-agent-service\"\n\n# Set an application name (optional)\nexport APP_NAME=\"capital-agent-app\"\n</code></pre>"},{"location":"deploy/cloud-run/#command-usage","title":"Command usage","text":""},{"location":"deploy/cloud-run/#minimal-command","title":"Minimal command","text":"<pre><code>npx adk deploy cloud_run \\\n--project=$GOOGLE_CLOUD_PROJECT \\\n--region=$GOOGLE_CLOUD_LOCATION \\\n$AGENT_PATH\n</code></pre>"},{"location":"deploy/cloud-run/#full-command-with-optional-flags","title":"Full command with optional flags","text":"<pre><code>npx adk deploy cloud_run \\\n--project=$GOOGLE_CLOUD_PROJECT \\\n--region=$GOOGLE_CLOUD_LOCATION \\\n--service_name=$SERVICE_NAME \\\n--app_name=$APP_NAME \\\n--with_ui \\\n$AGENT_PATH\n</code></pre>"},{"location":"deploy/cloud-run/#arguments","title":"Arguments","text":"<ul> <li><code>AGENT_PATH</code>: (Required) Positional argument specifying the path to the directory containing your agent's source code (e.g., <code>$AGENT_PATH</code> in the examples, or <code>capital_agent/</code>). This directory must contain your main agent file (e.g., <code>index.ts</code>).</li> </ul>"},{"location":"deploy/cloud-run/#options","title":"Options","text":"<ul> <li><code>--project TEXT</code>: (Required) Your Google Cloud project ID (e.g., <code>$GOOGLE_CLOUD_PROJECT</code>).</li> <li><code>--region TEXT</code>: (Required) The Google Cloud location for deployment (e.g., <code>$GOOGLE_CLOUD_LOCATION</code>, <code>us-central1</code>).</li> <li><code>--service_name TEXT</code>: (Optional) The name for the Cloud Run service (e.g., <code>$SERVICE_NAME</code>). Defaults to <code>adk-default-service-name</code>.</li> <li><code>--app_name TEXT</code>: (Optional) The application name for the ADK API server (e.g., <code>$APP_NAME</code>). Defaults to the name of the directory specified by <code>AGENT_PATH</code> (e.g., <code>capital_agent</code> if <code>AGENT_PATH</code> is <code>./capital_agent</code>).</li> <li><code>--agent_engine_id TEXT</code>: (Optional) If you are using a managed session service via Vertex AI Agent Engine, provide its resource ID here.</li> <li><code>--port INTEGER</code>: (Optional) The port number the ADK API server will listen on within the container. Defaults to 8000.</li> <li><code>--with_ui</code>: (Optional) If included, deploys the ADK dev UI alongside the agent API server. By default, only the API server is deployed.</li> <li><code>--temp_folder TEXT</code>: (Optional) Specifies a directory for storing intermediate files generated during the deployment process. Defaults to a timestamped folder in the system's temporary directory. (Note: This option is generally not needed unless troubleshooting issues).</li> <li><code>--help</code>: Show the help message and exit.</li> </ul>"},{"location":"deploy/cloud-run/#authenticated-access","title":"Authenticated access","text":"<p>During the deployment process, you might be prompted: <code>Allow unauthenticated invocations to [your-service-name] (y/N)?</code>.</p> <ul> <li>Enter <code>y</code> to allow public access to your agent's API endpoint without authentication.</li> <li>Enter <code>N</code> (or press Enter for the default) to require authentication (e.g., using an identity token as shown in the \"Testing your agent\" section).</li> </ul> <p>Upon successful execution, the command will deploy your agent to Cloud Run and provide the URL of the deployed service.</p>"},{"location":"deploy/cloud-run/#gcloud-cli","title":"gcloud CLI","text":"<p>Alternatively, you can deploy using the standard <code>gcloud run deploy</code> command with a <code>Dockerfile</code>. This method requires more manual setup compared to the <code>adk</code> command but offers flexibility, particularly if you want to embed your agent within a custom Express application.</p> <p>Ensure you have authenticated with Google Cloud (<code>gcloud auth login</code> and <code>gcloud config set project &lt;your-project-id&gt;</code>).</p>"},{"location":"deploy/cloud-run/#project-structure","title":"Project Structure","text":"<p>Organize your project files as follows:</p> <pre><code>your-project-directory/\n\u251c\u2500\u2500 capital_agent/\n\u2502   \u2514\u2500\u2500 index.ts       # Your agent code (TypeScript implementation)\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 server.ts      # Express server entry point\n\u251c\u2500\u2500 package.json       # Node.js dependencies\n\u251c\u2500\u2500 tsconfig.json      # TypeScript configuration\n\u2514\u2500\u2500 Dockerfile         # Container build instructions\n</code></pre> <p>Create the following files (<code>src/server.ts</code>, <code>package.json</code>, <code>tsconfig.json</code>, <code>Dockerfile</code>) in the root of <code>your-project-directory/</code>.</p>"},{"location":"deploy/cloud-run/#code-files","title":"Code files","text":"<ol> <li> <p>This file sets up the Express server to serve your ADK agent API:</p> src/server.ts<pre><code>import express from 'express';\nimport path from 'path';\nimport { createApiServer } from 'adk-typescript/dist/cli/apiServer';\n\n// Get the directory where server.ts is located\nconst AGENT_DIR = path.resolve(__dirname, '..');\n\n// Example allowed origins for CORS\nconst ALLOWED_ORIGINS = ['http://localhost', 'http://localhost:8080', '*'];\n\n// Set to true if you intend to serve a web interface, false otherwise\nconst SERVE_WEB_INTERFACE = true;\n\n// Create the API server \nconst { app, server } = createApiServer({\n  agentDir: AGENT_DIR,\n  sessionDbUrl: '', // Let it use default in-memory session store\n  allowOrigins: ALLOWED_ORIGINS,\n  web: SERVE_WEB_INTERFACE,\n  port: parseInt(process.env.PORT || '8080', 10)\n});\n\n// You can add more Express routes or configurations below if needed\n// Example:\n// app.get('/hello', (req, res) =&gt; {\n//   res.json({ message: 'Hello World' });\n// });\n\n// Graceful shutdown handling\nprocess.on('SIGINT', () =&gt; {\n  console.log('Shutting down API server...');\n  server.close(() =&gt; {\n    console.log('API server stopped.');\n    process.exit(0);\n  });\n});\n\nconsole.log(`Server running on port ${process.env.PORT || 8080}`);\n</code></pre> </li> <li> <p>Configure Node.js dependencies:</p> package.json<pre><code>{\n  \"name\": \"adk-typescript-agent\",\n  \"version\": \"1.0.0\",\n  \"description\": \"ADK TypeScript Agent for Cloud Run deployment\",\n  \"main\": \"dist/server.js\",\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"start\": \"node dist/server.js\",\n    \"dev\": \"ts-node src/server.ts\"\n  },\n  \"dependencies\": {\n    \"adk-typescript\": \"^0.1.0\",\n    \"express\": \"^4.18.2\",\n    \"@google-cloud/vertexai\": \"^0.2.1\"\n  },\n  \"devDependencies\": {\n    \"@types/express\": \"^4.17.17\",\n    \"@types/node\": \"^20.4.2\",\n    \"ts-node\": \"^10.9.1\",\n    \"typescript\": \"^5.1.6\"\n  },\n  \"engines\": {\n    \"node\": \"&gt;=18.0.0\"\n  }\n}\n</code></pre> </li> <li> <p>Configure TypeScript:</p> tsconfig.json<pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"NodeNext\",\n    \"moduleResolution\": \"NodeNext\",\n    \"esModuleInterop\": true,\n    \"strict\": true,\n    \"outDir\": \"dist\",\n    \"rootDir\": \".\",\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true\n  },\n  \"include\": [\"src/**/*\", \"capital_agent/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n</code></pre> </li> <li> <p>Define the container image:</p> Dockerfile<pre><code>FROM node:18-slim\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm ci --only=production\n\n# Copy compiled TypeScript\nCOPY dist/ ./dist/\nCOPY capital_agent/ ./capital_agent/\n\n# Create a non-root user and use it\nRUN mkdir -p /home/nodeuser/.npm &amp;&amp; \\\n    chown -R node:node /home/nodeuser/.npm &amp;&amp; \\\n    chown -R node:node /app\n\nUSER node\n\n# Start the application\nCMD [ \"node\", \"dist/server.js\" ]\n</code></pre> </li> </ol>"},{"location":"deploy/cloud-run/#build-steps","title":"Build steps","text":"<p>Before building the container image, compile your TypeScript code:</p> <pre><code>npm install\nnpm run build\n</code></pre>"},{"location":"deploy/cloud-run/#deploy-using-gcloud","title":"Deploy using <code>gcloud</code>","text":"<p>Navigate to <code>your-project-directory</code> in your terminal.</p> <pre><code>gcloud run deploy capital-agent-service \\\n--source . \\\n--region $GOOGLE_CLOUD_LOCATION \\\n--project $GOOGLE_CLOUD_PROJECT \\\n--allow-unauthenticated \\\n--set-env-vars=\"GOOGLE_CLOUD_PROJECT=$GOOGLE_CLOUD_PROJECT,GOOGLE_CLOUD_LOCATION=$GOOGLE_CLOUD_LOCATION\"\n# Add any other necessary environment variables your agent might need\n</code></pre> <ul> <li><code>capital-agent-service</code>: The name you want to give your Cloud Run service.</li> <li><code>--source .</code>: Tells gcloud to build the container image from the Dockerfile in the current directory.</li> <li><code>--region</code>: Specifies the deployment region.</li> <li><code>--project</code>: Specifies the GCP project.</li> <li><code>--allow-unauthenticated</code>: Allows public access to the service. Remove this flag for private services.</li> <li><code>--set-env-vars</code>: Passes necessary environment variables to the running container. Ensure you include all variables required by ADK and your agent.</li> </ul> <p><code>gcloud</code> will build the Docker image, push it to Google Artifact Registry, and deploy it to Cloud Run. Upon completion, it will output the URL of your deployed service.</p> <p>For a full list of deployment options, see the <code>gcloud run deploy</code> reference documentation.</p>"},{"location":"deploy/cloud-run/#testing-your-agent","title":"Testing your agent","text":"<p>Once your agent is deployed to Cloud Run, you can interact with it via the deployed UI (if enabled) or directly with its API endpoints using tools like <code>curl</code>. You'll need the service URL provided after deployment.</p> UI TestingAPI Testing (curl)"},{"location":"deploy/cloud-run/#ui-testing","title":"UI Testing","text":"<p>If you deployed your agent with the UI enabled:</p> <ul> <li>adk CLI: You included the <code>--with_ui</code> flag during deployment.</li> <li>gcloud CLI: You set <code>SERVE_WEB_INTERFACE = true</code> in your <code>server.ts</code>.</li> </ul> <p>You can test your agent by simply navigating to the Cloud Run service URL provided after deployment in your web browser.</p> <pre><code># Example URL format\n# https://your-service-name-abc123xyz.a.run.app\n</code></pre> <p>The ADK dev UI allows you to interact with your agent, manage sessions, and view execution details directly in the browser.</p> <p>To verify your agent is working as intended, you can:</p> <ol> <li>Select your agent from the dropdown menu.</li> <li>Type a message and verify that you receive an expected response from your agent.</li> </ol> <p>If you experience any unexpected behavior, check the Cloud Run console logs.</p>"},{"location":"deploy/cloud-run/#api-testing-curl","title":"API Testing (curl)","text":"<p>You can interact with the agent's API endpoints using tools like <code>curl</code>. This is useful for programmatic interaction or if you deployed without the UI.</p> <p>You'll need the service URL provided after deployment and potentially an identity token for authentication if your service isn't set to allow unauthenticated access.</p>"},{"location":"deploy/cloud-run/#set-the-application-url","title":"Set the application URL","text":"<p>Replace the example URL with the actual URL of your deployed Cloud Run service.</p> <pre><code>export APP_URL=\"YOUR_CLOUD_RUN_SERVICE_URL\"\n# Example: export APP_URL=\"https://adk-default-service-name-abc123xyz.a.run.app\"\n</code></pre>"},{"location":"deploy/cloud-run/#get-an-identity-token-if-needed","title":"Get an identity token (if needed)","text":"<p>If your service requires authentication (i.e., you didn't use <code>--allow-unauthenticated</code> with <code>gcloud</code> or answered 'N' to the prompt with <code>adk</code>), obtain an identity token.</p> <pre><code>export TOKEN=$(gcloud auth print-identity-token)\n</code></pre> <p>If your service allows unauthenticated access, you can omit the <code>-H \"Authorization: Bearer $TOKEN\"</code> header from the <code>curl</code> commands below.</p>"},{"location":"deploy/cloud-run/#list-available-apps","title":"List available apps","text":"<p>Verify the deployed application name.</p> <pre><code>curl -X GET -H \"Authorization: Bearer $TOKEN\" $APP_URL/list-apps\n</code></pre> <p>(Adjust the <code>app_name</code> in the following commands based on this output if needed. The default is often the agent directory name, e.g., <code>capital_agent</code>).</p>"},{"location":"deploy/cloud-run/#create-or-update-a-session","title":"Create or Update a Session","text":"<p>Initialize or update the state for a specific user and session. Replace <code>capital_agent</code> with your actual app name if different. The values <code>user_123</code> and <code>session_abc</code> are example identifiers; you can replace them with your desired user and session IDs.</p> <pre><code>curl -X POST -H \"Authorization: Bearer $TOKEN\" \\\n    $APP_URL/apps/capital_agent/users/user_123/sessions/session_abc \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"state\": {\"preferredLanguage\": \"English\", \"visitCount\": 5}}'\n</code></pre>"},{"location":"deploy/cloud-run/#run-the-agent","title":"Run the Agent","text":"<p>Send a prompt to your agent. Replace <code>capital_agent</code> with your app name and adjust the user/session IDs and prompt as needed.</p> <pre><code>curl -X POST -H \"Authorization: Bearer $TOKEN\" \\\n    $APP_URL/run_sse \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\n    \"app_name\": \"capital_agent\",\n    \"user_id\": \"user_123\",\n    \"session_id\": \"session_abc\",\n    \"new_message\": {\n        \"role\": \"user\",\n        \"parts\": [{\n        \"text\": \"What is the capital of Canada?\"\n        }]\n    },\n    \"streaming\": false\n    }'\n</code></pre> <ul> <li>Set <code>\"streaming\": true</code> if you want to receive Server-Sent Events (SSE).</li> <li>The response will contain the agent's execution events, including the final answer.</li> </ul>"},{"location":"deploy/gke/","title":"Deploy to GKE","text":"<p>GKE is Google Cloud's managed Kubernetes service. It allows you to deploy and manage containerized applications using Kubernetes.</p> <p>To deploy your agent you will need to have a Kubernetes cluster running on GKE. You can create a cluster using the Google Cloud Console or the <code>gcloud</code> command line tool.</p>"},{"location":"deploy/gke/#agent-sample","title":"Agent sample","text":"<p>For each of the commands, we will reference a <code>capital_agent</code> sample defined in the Agent documentation page. We will assume it's in a <code>capital_agent</code> directory.</p> <p>To proceed, confirm that your agent code is configured as follows:</p> <ol> <li>Agent code is in a file called <code>index.ts</code> within your agent directory.</li> <li>Your agent variable is named <code>rootAgent</code>.</li> <li>The agent is properly exported from the module.</li> </ol>"},{"location":"deploy/gke/#environment-variables","title":"Environment variables","text":"<p>Set your environment variables as described in the Setup and Installation guide. You also need to install the <code>kubectl</code> command line tool. You can find instructions to do so in the Google Kubernetes Engine Documentation.</p> <pre><code>export GOOGLE_CLOUD_PROJECT=your-project-id # Your GCP project ID\nexport GOOGLE_CLOUD_LOCATION=us-central1 # Or your preferred location\nexport GOOGLE_CLOUD_PROJECT_NUMBER=$(gcloud projects describe --format json $GOOGLE_CLOUD_PROJECT | jq -r \".projectNumber\")\n</code></pre> <p>If you don't have <code>jq</code> installed, you can use the following command to get the project number:</p> <pre><code>gcloud projects describe $GOOGLE_CLOUD_PROJECT\n</code></pre> <p>And copy the project number from the output.</p> <pre><code>export GOOGLE_CLOUD_PROJECT_NUMBER=YOUR_PROJECT_NUMBER\n</code></pre>"},{"location":"deploy/gke/#deployment-commands","title":"Deployment commands","text":""},{"location":"deploy/gke/#gcloud-cli","title":"gcloud CLI","text":"<p>You can deploy your agent to GKE using the <code>gcloud</code> and <code>kubectl</code> cli and Kubernetes manifest files.</p> <p>Ensure you have authenticated with Google Cloud (<code>gcloud auth login</code> and <code>gcloud config set project &lt;your-project-id&gt;</code>).</p>"},{"location":"deploy/gke/#create-a-gke-cluster","title":"Create a GKE cluster","text":"<p>You can create a GKE cluster using the <code>gcloud</code> command line tool. This example creates an Autopilot cluster named <code>adk-cluster</code> in the <code>us-central1</code> region.</p> <p>If creating a GKE Standard cluster, make sure Workload Identity is enabled. Workload Identity is enabled by default in an AutoPilot cluster.</p> <pre><code>gcloud container clusters create-auto adk-cluster \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --project=$GOOGLE_CLOUD_PROJECT\n</code></pre> <p>After creating the cluster, you need to connect to it using <code>kubectl</code>. This command configures <code>kubectl</code> to use the credentials for your new cluster.</p> <pre><code>gcloud container clusters get-credentials adk-cluster \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --project=$GOOGLE_CLOUD_PROJECT\n</code></pre>"},{"location":"deploy/gke/#artifact-registry","title":"Artifact Registry","text":"<p>You need to create a Google Artifact Registry repository to store your container images. You can do this using the <code>gcloud</code> command line tool.</p> <pre><code>gcloud artifacts repositories create adk-repo \\\n    --repository-format=docker \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --description=\"ADK repository\"\n</code></pre>"},{"location":"deploy/gke/#project-structure","title":"Project Structure","text":"<p>Organize your project files as follows:</p> <pre><code>your-project-directory/\n\u251c\u2500\u2500 capital_agent/\n\u2502   \u2514\u2500\u2500 index.ts       # Your agent code (TypeScript implementation)\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 server.ts      # Express server entry point\n\u251c\u2500\u2500 package.json       # Node.js dependencies\n\u251c\u2500\u2500 tsconfig.json      # TypeScript configuration\n\u2514\u2500\u2500 Dockerfile         # Container build instructions\n</code></pre> <p>Create the following files (<code>src/server.ts</code>, <code>package.json</code>, <code>tsconfig.json</code>, <code>Dockerfile</code>) in the root of <code>your-project-directory/</code>.</p>"},{"location":"deploy/gke/#code-files","title":"Code files","text":"<ol> <li> <p>This file sets up the Express server to serve your ADK agent API:</p> src/server.ts<pre><code>import express from 'express';\nimport path from 'path';\nimport { createApiServer } from 'adk-typescript/dist/cli/apiServer';\n\n// Get the directory where server.ts is located\nconst AGENT_DIR = path.resolve(__dirname, '..');\n\n// Example allowed origins for CORS\nconst ALLOWED_ORIGINS = ['http://localhost', 'http://localhost:8080', '*'];\n\n// Set to true if you intend to serve a web interface, false otherwise\nconst SERVE_WEB_INTERFACE = true;\n\n// Create the API server \nconst { app, server } = createApiServer({\n  agentDir: AGENT_DIR,\n  sessionDbUrl: '', // Let it use default in-memory session store\n  allowOrigins: ALLOWED_ORIGINS,\n  web: SERVE_WEB_INTERFACE,\n  port: parseInt(process.env.PORT || '8080', 10)\n});\n\n// You can add more Express routes or configurations below if needed\n// Example:\n// app.get('/hello', (req, res) =&gt; {\n//   res.json({ message: 'Hello World' });\n// });\n\n// Graceful shutdown handling\nprocess.on('SIGINT', () =&gt; {\n  console.log('Shutting down API server...');\n  server.close(() =&gt; {\n    console.log('API server stopped.');\n    process.exit(0);\n  });\n});\n\nconsole.log(`Server running on port ${process.env.PORT || 8080}`);\n</code></pre> </li> <li> <p>Configure Node.js dependencies:</p> package.json<pre><code>{\n  \"name\": \"adk-typescript-agent\",\n  \"version\": \"1.0.0\",\n  \"description\": \"ADK TypeScript Agent for GKE deployment\",\n  \"main\": \"dist/server.js\",\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"start\": \"node dist/server.js\",\n    \"dev\": \"ts-node src/server.ts\"\n  },\n  \"dependencies\": {\n    \"adk-typescript\": \"^0.1.0\",\n    \"express\": \"^4.18.2\",\n    \"@google-cloud/vertexai\": \"^0.2.1\"\n  },\n  \"devDependencies\": {\n    \"@types/express\": \"^4.17.17\",\n    \"@types/node\": \"^20.4.2\",\n    \"ts-node\": \"^10.9.1\",\n    \"typescript\": \"^5.1.6\"\n  },\n  \"engines\": {\n    \"node\": \"&gt;=18.0.0\"\n  }\n}\n</code></pre> </li> <li> <p>Configure TypeScript:</p> tsconfig.json<pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"NodeNext\",\n    \"moduleResolution\": \"NodeNext\",\n    \"esModuleInterop\": true,\n    \"strict\": true,\n    \"outDir\": \"dist\",\n    \"rootDir\": \".\",\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true\n  },\n  \"include\": [\"src/**/*\", \"capital_agent/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n</code></pre> </li> <li> <p>Define the container image:</p> Dockerfile<pre><code>FROM node:18-slim\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm ci --only=production\n\n# Copy compiled TypeScript\nCOPY dist/ ./dist/\nCOPY capital_agent/ ./capital_agent/\n\n# Create a non-root user and use it\nRUN mkdir -p /home/nodeuser/.npm &amp;&amp; \\\n    chown -R node:node /home/nodeuser/.npm &amp;&amp; \\\n    chown -R node:node /app\n\nUSER node\n\n# Set the PORT environment variable for Cloud Run compatibility\nENV PORT=8080\n\n# Start the application\nCMD [ \"node\", \"dist/server.js\" ]\n</code></pre> </li> </ol>"},{"location":"deploy/gke/#build-steps","title":"Build steps","text":"<p>Before building the container image, compile your TypeScript code:</p> <pre><code>npm install\nnpm run build\n</code></pre>"},{"location":"deploy/gke/#build-the-container-image","title":"Build the container image","text":"<p>Build the container image using the <code>gcloud</code> command line tool. This example builds the image and tags it as <code>adk-repo/adk-agent:latest</code>.</p> <pre><code>gcloud builds submit \\\n    --tag $GOOGLE_CLOUD_LOCATION-docker.pkg.dev/$GOOGLE_CLOUD_PROJECT/adk-repo/adk-agent:latest \\\n    --project=$GOOGLE_CLOUD_PROJECT \\\n    .\n</code></pre>"},{"location":"deploy/gke/#configure-kubernetes-service-account-for-vertex-ai","title":"Configure Kubernetes Service Account for Vertex AI","text":"<p>If your agent uses Vertex AI, you need to create a Kubernetes service account with the necessary permissions. This example creates a service account named <code>adk-agent-sa</code> and binds it to the <code>Vertex AI User</code> role.</p> <pre><code>kubectl create serviceaccount adk-agent-sa\n</code></pre> <pre><code>gcloud projects add-iam-policy-binding projects/${GOOGLE_CLOUD_PROJECT} \\\n    --role=roles/aiplatform.user \\\n    --member=principal://iam.googleapis.com/projects/${GOOGLE_CLOUD_PROJECT_NUMBER}/locations/global/workloadIdentityPools/${GOOGLE_CLOUD_PROJECT}.svc.id.goog/subject/ns/default/sa/adk-agent-sa \\\n    --condition=None\n</code></pre>"},{"location":"deploy/gke/#create-the-kubernetes-manifest-files","title":"Create the Kubernetes manifest files","text":"<p>Create a Kubernetes deployment manifest file named <code>deployment.yaml</code> in your project directory. This file defines how to deploy your application on GKE.</p> deployment.yaml<pre><code>cat &lt;&lt;  EOF &gt; deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: adk-agent\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: adk-agent\n  template:\n    metadata:\n      labels:\n        app: adk-agent\n    spec:\n      serviceAccount: adk-agent-sa\n      containers:\n      - name: adk-agent\n        image: $GOOGLE_CLOUD_LOCATION-docker.pkg.dev/$GOOGLE_CLOUD_PROJECT/adk-repo/adk-agent:latest\n        resources:\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n            ephemeral-storage: \"128Mi\"\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n            ephemeral-storage: \"128Mi\"\n        ports:\n        - containerPort: 8080\n        env:\n          - name: PORT\n            value: \"8080\"\n          - name: GOOGLE_CLOUD_PROJECT\n            value: \"$GOOGLE_CLOUD_PROJECT\"\n          - name: GOOGLE_CLOUD_LOCATION\n            value: \"$GOOGLE_CLOUD_LOCATION\"\n          - name: NODE_ENV\n            value: \"production\"\n          # Add any other necessary environment variables your agent might need\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: adk-agent\nspec:       \n  type: LoadBalancer\n  ports:\n    - port: 80\n      targetPort: 8080\n  selector:\n    app: adk-agent\nEOF\n</code></pre>"},{"location":"deploy/gke/#deploy-the-application","title":"Deploy the Application","text":"<p>Deploy the application using the <code>kubectl</code> command line tool. This command applies the deployment and service manifest files to your GKE cluster.</p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre> <p>After a few moments, you can check the status of your deployment using:</p> <pre><code>kubectl get pods -l=app=adk-agent\n</code></pre> <p>This command lists the pods associated with your deployment. You should see a pod with a status of <code>Running</code>.</p> <p>Once the pod is running, you can check the status of the service using:</p> <pre><code>kubectl get service adk-agent\n</code></pre> <p>If the output shows a <code>External IP</code>, it means your service is accessible from the internet. It may take a few minutes for the external IP to be assigned.</p> <p>You can get the external IP address of your service using:</p> <pre><code>kubectl get svc adk-agent -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'\n</code></pre>"},{"location":"deploy/gke/#testing-your-agent","title":"Testing your agent","text":"<p>Once your agent is deployed to GKE, you can interact with it via the deployed UI (if enabled) or directly with its API endpoints using tools like <code>curl</code>. You'll need the service URL provided after deployment.</p> UI TestingAPI Testing (curl)"},{"location":"deploy/gke/#ui-testing","title":"UI Testing","text":"<p>If you deployed your agent with the UI enabled:</p> <p>You can test your agent by simply navigating to the kubernetes service URL in your web browser.</p> <p>The ADK dev UI allows you to interact with your agent, manage sessions, and view execution details directly in the browser.</p> <p>To verify your agent is working as intended, you can:</p> <ol> <li>Select your agent from the dropdown menu.</li> <li>Type a message and verify that you receive an expected response from your agent.</li> </ol> <p>If you experience any unexpected behavior, check the pod logs for your agent using:</p> <pre><code>kubectl logs -l app=adk-agent\n</code></pre>"},{"location":"deploy/gke/#api-testing-curl","title":"API Testing (curl)","text":"<p>You can interact with the agent's API endpoints using tools like <code>curl</code>. This is useful for programmatic interaction or if you deployed without the UI.</p>"},{"location":"deploy/gke/#set-the-application-url","title":"Set the application URL","text":"<p>Replace the example URL with the actual URL of your deployed Kubernetes service.</p> <pre><code>export APP_URL=\"KUBERNETES_SERVICE_URL\"\n</code></pre>"},{"location":"deploy/gke/#list-available-apps","title":"List available apps","text":"<p>Verify the deployed application name.</p> <pre><code>curl -X GET $APP_URL/list-apps\n</code></pre> <p>(Adjust the <code>app_name</code> in the following commands based on this output if needed. The default is often the agent directory name, e.g., <code>capital_agent</code>).</p>"},{"location":"deploy/gke/#create-or-update-a-session","title":"Create or Update a Session","text":"<p>Initialize or update the state for a specific user and session. Replace <code>capital_agent</code> with your actual app name if different. The values <code>user_123</code> and <code>session_abc</code> are example identifiers; you can replace them with your desired user and session IDs.</p> <pre><code>curl -X POST \\\n    $APP_URL/apps/capital_agent/users/user_123/sessions/session_abc \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"state\": {\"preferredLanguage\": \"English\", \"visitCount\": 5}}'\n</code></pre>"},{"location":"deploy/gke/#run-the-agent","title":"Run the Agent","text":"<p>Send a prompt to your agent. Replace <code>capital_agent</code> with your app name and adjust the user/session IDs and prompt as needed.</p> <pre><code>curl -X POST $APP_URL/run_sse \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\n    \"app_name\": \"capital_agent\",\n    \"user_id\": \"user_123\",\n    \"session_id\": \"session_abc\",\n    \"new_message\": {\n        \"role\": \"user\",\n        \"parts\": [{\n        \"text\": \"What is the capital of Canada?\"\n        }]\n    },\n    \"streaming\": false\n    }'\n</code></pre> <ul> <li>Set <code>\"streaming\": true</code> if you want to receive Server-Sent Events (SSE).</li> <li>The response will contain the agent's execution events, including the final answer.</li> </ul>"},{"location":"evaluate/","title":"Why Evaluate Agents","text":"<p>In traditional software development, unit tests and integration tests provide confidence that code functions as expected and remains stable through changes. These tests provide a clear \"pass/fail\" signal, guiding further development. However, LLM agents introduce a level of variability that makes traditional testing approaches insufficient.</p> <p>Due to the probabilistic nature of models, deterministic \"pass/fail\" assertions are often unsuitable for evaluating agent performance. Instead, we need qualitative evaluations of both the final output and the agent's trajectory - the sequence of steps taken to reach the solution. This involves assessing the quality of the agent's decisions, its reasoning process, and the final result.</p> <p>This may seem like a lot of extra work to set up, but the investment of automating evaluations pays off quickly. If you intend to progress beyond prototype, this is a highly recommended best practice.</p> <p></p>"},{"location":"evaluate/#preparing-for-agent-evaluations","title":"Preparing for Agent Evaluations","text":"<p>Before automating agent evaluations, define clear objectives and success criteria:</p> <ul> <li>Define Success: What constitutes a successful outcome for your agent?  </li> <li>Identify Critical Tasks: What are the essential tasks your agent must accomplish?  </li> <li>Choose Relevant Metrics: What metrics will you track to measure performance?</li> </ul> <p>These considerations will guide the creation of evaluation scenarios and enable effective monitoring of agent behavior in real-world deployments.</p>"},{"location":"evaluate/#what-to-evaluate","title":"What to Evaluate?","text":"<p>To bridge the gap between a proof-of-concept and a production-ready AI agent, a robust and automated evaluation framework is essential. Unlike evaluating generative models, where the focus is primarily on the final output, agent evaluation requires a deeper understanding of the decision-making process. Agent evaluation can be broken down into two components:</p> <ol> <li>Evaluating Trajectory and Tool Use: Analyzing the steps an agent takes to reach a solution, including its choice of tools, strategies, and the efficiency of its approach.  </li> <li>Evaluating the Final Response: Assessing the quality, relevance, and correctness of the agent's final output.</li> </ol> <p>The trajectory is just a list of steps the agent took before it returned to the user. We can compare that against the list of steps we expect the agent to have taken.</p>"},{"location":"evaluate/#evaluating-trajectory-and-tool-use","title":"Evaluating trajectory and tool use","text":"<p>Before responding to a user, an agent typically performs a series of actions, which we refer to as a 'trajectory.' It might compare the user input with session history to disambiguate a term, or lookup a policy document, search a knowledge base or invoke an API to save a ticket. We call this a 'trajectory' of actions. Evaluating an agent's performance requires comparing its actual trajectory to an expected, or ideal, one. This comparison can reveal errors and inefficiencies in the agent's process. The expected trajectory represents the ground truth -- the list of steps we anticipate the agent should take.</p> <p>For example:</p> <pre><code>// Trajectory evaluation will compare\nconst expectedSteps = [\"determine_intent\", \"use_tool\", \"review_results\", \"report_generation\"];\nconst actualSteps = [\"determine_intent\", \"use_tool\", \"review_results\", \"report_generation\"];\n</code></pre> <p>Several ground-truth-based trajectory evaluations exist:</p> <ol> <li>Exact match: Requires a perfect match to the ideal trajectory.  </li> <li>In-order match: Requires the correct actions in the correct order, allows for extra actions.  </li> <li>Any-order match: Requires the correct actions in any order, allows for extra actions.  </li> <li>Precision: Measures the relevance/correctness of predicted actions.  </li> <li>Recall: Measures how many essential actions are captured in the prediction.  </li> <li>Single-tool use: Checks for the inclusion of a specific action.</li> </ol> <p>Choosing the right evaluation metric depends on the specific requirements and goals of your agent. For instance, in high-stakes scenarios, an exact match might be crucial, while in more flexible situations, an in-order or any-order match might suffice.</p>"},{"location":"evaluate/#how-evaluation-works-with-the-adk","title":"How Evaluation works with the ADK","text":"<p>The ADK offers two methods for evaluating agent performance against predefined datasets and evaluation criteria. While conceptually similar, they differ in the amount of data they can process, which typically dictates the appropriate use case for each.</p>"},{"location":"evaluate/#first-approach-using-a-test-file","title":"First approach: Using a test file","text":"<p>This approach involves creating individual test files, each representing a single, simple agent-model interaction (a session). It's most effective during active agent development, serving as a form of unit testing. These tests are designed for rapid execution and should focus on simple session complexity. Each test file contains a single session, which may consist of multiple turns. A turn represents a single interaction between the user and the agent. Each turn includes</p> <ul> <li><code>query:</code> This is the user query.  </li> <li><code>expected_tool_use</code>: The tool call(s) that we expect the agent to make in order to respond correctly to the user <code>query</code>.  </li> <li><code>expected_intermediate_agent_responses</code>:  This field contains the natural language responses produced by the agent as it progresses towards a final answer. These responses are typical in multi-agent systems where a root agent relies on child agents to accomplish a task. While generally not directly relevant to end-users, these intermediate responses are valuable for developers. They provide insight into the agent's reasoning path and help verify that it followed the correct steps to generate the final response.</li> <li><code>reference</code>: The expected final response from the model.</li> </ul> <p>You can give the file any name for example <code>evaluation.test.json</code>.The framework only checks for the <code>.test.json</code> suffix, and the preceding part of the filename is not constrained. Here is a test file with a few examples:</p> <pre><code>[\n  {\n    \"query\": \"hi\",\n    \"expected_tool_use\": [],\n    \"expected_intermediate_agent_responses\": [],\n    \"reference\": \"Hello! What can I do for you?\\n\"\n  },\n  {\n    \"query\": \"roll a die for me\",\n    \"expected_tool_use\": [\n      {\n        \"tool_name\": \"roll_die\",\n        \"tool_input\": {\n          \"sides\": 6\n        }\n      }\n    ],\n    \"expected_intermediate_agent_responses\": [],\n  },\n  {\n    \"query\": \"what's the time now?\",\n    \"expected_tool_use\": [],\n    \"expected_intermediate_agent_responses\": [],\n    \"reference\": \"I'm sorry, I cannot access real-time information, including the current time. My capabilities are limited to rolling dice and checking prime numbers.\\n\"\n  }\n]\n</code></pre> <p>Test files can be organized into folders. Optionally, a folder can also include a <code>test_config.json</code> file that specifies the evaluation criteria.</p>"},{"location":"evaluate/#second-approach-using-an-evalset-file","title":"Second approach: Using An Evalset File","text":"<p>The evalset approach utilizes a dedicated dataset called an \"evalset\" for evaluating agent-model interactions. Similar to a test file, the evalset contains example interactions. However, an evalset can contain multiple, potentially lengthy sessions, making it ideal for simulating complex, multi-turn conversations. Due to its ability to represent complex sessions, the evalset is well-suited for integration tests. These tests are typically run less frequently than unit tests due to their more extensive nature.</p> <p>An evalset file contains multiple \"evals,\" each representing a distinct session. Each eval consists of one or more \"turns,\" which include the user query, expected tool use, expected intermediate agent responses, and a reference response. These fields have the same meaning as they do in the test file approach. Each eval is identified by a unique name. Furthermore, each eval includes an associated initial session state.</p> <p>Creating evalsets manually can be complex, therefore UI tools are provided to help capture relevant sessions and easily convert them into evals within your evalset. Learn more about using the web UI for evaluation below. Here is an example evalset containing two sessions.</p> <pre><code>[\n  {\n    \"name\": \"roll_16_sided_dice_and_then_check_if_6151953_is_prime\",\n    \"data\": [\n      {\n        \"query\": \"What can you do?\",\n        \"expected_tool_use\": [],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I can roll dice of different sizes and check if a number is prime. I can also use multiple tools in parallel.\\n\"\n      },\n      {\n        \"query\": \"Roll a 16 sided dice for me\",\n        \"expected_tool_use\": [\n          {\n            \"tool_name\": \"roll_die\",\n            \"tool_input\": {\n              \"sides\": 16\n            }\n          }\n        ],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I rolled a 16 sided die and got 13.\\n\"\n      },\n      {\n        \"query\": \"Is 6151953  a prime number?\",\n        \"expected_tool_use\": [\n          {\n            \"tool_name\": \"check_prime\",\n            \"tool_input\": {\n              \"nums\": [\n                6151953\n              ]\n            }\n          }\n        ],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"No, 6151953 is not a prime number.\\n\"\n      }\n    ],\n    \"initial_session\": {\n      \"state\": {},\n      \"app_name\": \"hello_world\",\n      \"user_id\": \"user\"\n    }\n  },\n  {\n    \"name\": \"roll_17_sided_dice_twice\",\n    \"data\": [\n      {\n        \"query\": \"What can you do?\",\n        \"expected_tool_use\": [],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I can roll dice of different sizes and check if a number is prime. I can also use multiple tools in parallel.\\n\"\n      },\n      {\n        \"query\": \"Roll a 17 sided dice twice for me\",\n        \"expected_tool_use\": [\n          {\n            \"tool_name\": \"roll_die\",\n            \"tool_input\": {\n              \"sides\": 17\n            }\n          },\n          {\n            \"tool_name\": \"roll_die\",\n            \"tool_input\": {\n              \"sides\": 17\n            }\n          }\n        ],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I have rolled a 17 sided die twice. The first roll was 13 and the second roll was 4.\\n\"\n      }\n    ],\n    \"initial_session\": {\n      \"state\": {},\n      \"app_name\": \"hello_world\",\n      \"user_id\": \"user\"\n    }\n  }\n]\n</code></pre>"},{"location":"evaluate/#evaluation-criteria","title":"Evaluation Criteria","text":"<p>The evaluation criteria define how the agent's performance is measured against the evalset. The following metrics are supported:</p> <ul> <li><code>tool_trajectory_avg_score</code>: This metric compares the agent's actual tool usage during the evaluation against the expected tool usage defined in the <code>expected_tool_use</code> field. Each matching tool usage step receives a score of 1, while a mismatch receives a score of 0. The final score is the average of these matches, representing the accuracy of the tool usage trajectory.  </li> <li><code>response_match_score</code>: This metric compares the agent's final natural language response to the expected final response, stored in the <code>reference</code> field. We use the ROUGE metric to calculate the similarity between the two responses.</li> </ul> <p>If no evaluation criteria are provided, the following default configuration is used:</p> <ul> <li><code>tool_trajectory_avg_score</code>: Defaults to 1.0, requiring a 100% match in the tool usage trajectory.  </li> <li><code>response_match_score</code>: Defaults to 0.8, allowing for a small margin of error in the agent's natural language responses.</li> </ul> <p>Here is an example of a <code>test_config.json</code> file specifying custom evaluation criteria:</p> <pre><code>{\n  \"criteria\": {\n    \"tool_trajectory_avg_score\": 1.0,\n    \"response_match_score\": 0.8\n  }\n}\n</code></pre>"},{"location":"evaluate/#how-to-run-evaluation-with-the-adk","title":"How to run Evaluation with the ADK","text":"<p>As a developer, you can evaluate your agents using the ADK in the following ways:</p> <ol> <li>Web-based UI (<code>npx adk web</code>): Evaluate agents interactively through a web-based interface.  </li> <li>Programmatically: Integrate evaluation into your testing pipeline using testing frameworks like Jest or Mocha.  </li> <li>Command Line Interface (<code>npx adk eval</code>): Run evaluations on an existing evaluation set file directly from the command line.</li> </ol>"},{"location":"evaluate/#1-npx-adk-web-run-evaluations-via-the-web-ui","title":"1. <code>npx adk web</code> - Run Evaluations via the Web UI","text":"<p>The web UI provides an interactive way to evaluate agents and generate evaluation datasets.</p> <p>Steps to run evaluation via the web ui:</p> <ol> <li>Start the web server by running: <code>npx adk web samples_for_testing</code> </li> <li>In the web interface:  <ul> <li>Select an agent (e.g., <code>hello_world</code>).  </li> <li>Interact with the agent to create a session that you want to save as a test case.  </li> <li>Click the \"Eval tab\" on the right side of the interface.  </li> <li>If you already have an existing eval set, select that or create a new one by clicking on \"Create new eval set\" button. Give your eval set a contextual name. Select the newly created evaluation set.  </li> <li>Click \"Add current session\" to save the current session as an eval in the eval set file. You will be asked to provide a name for this eval, again give it a contextual name.  </li> <li>Once created, the newly created eval will show up in the list of available evals in the eval set file. You can run all or select specific ones to run the eval.  </li> <li>The status of each eval will be shown in the UI.</li> </ul> </li> </ol>"},{"location":"evaluate/#2-programmatic-evaluation-with-testing-frameworks","title":"2. Programmatic Evaluation with Testing Frameworks","text":"<p>You can integrate agent evaluation into your testing pipeline using testing frameworks like Jest or Mocha.</p>"},{"location":"evaluate/#example-jest-test","title":"Example Jest Test","text":"<pre><code>import { AgentEvaluator } from 'adk-typescript';\nimport path from 'path';\n\ndescribe('Agent Evaluation', () =&gt; {\n  test('Basic functionality test', async () =&gt; {\n    await AgentEvaluator.evaluate({\n      agentModule: 'tests/integration/fixture/home_automation_agent',\n      evalDataset: 'tests/integration/fixture/home_automation_agent/simple_test.test.json',\n    });\n  });\n});\n</code></pre> <p>This approach allows you to integrate agent evaluations into your CI/CD pipelines or larger test suites. If you want to specify the initial session state for your tests, you can do that by storing the session details in a file and passing that to the <code>AgentEvaluator.evaluate</code> method.</p> <p>Here is a sample session JSON file:</p> <pre><code>{\n  \"id\": \"test_id\",\n  \"app_name\": \"trip_planner_agent\",\n  \"user_id\": \"test_user\",\n  \"state\": {\n    \"origin\": \"San Francisco\",\n    \"interests\": \"Mountains, Hikes\",\n    \"range\": \"1000 miles\",\n    \"cities\": \"\"\n  },\n  \"events\": [],\n  \"last_update_time\": 1741218714.258285\n}\n</code></pre> <p>And the sample code will look like this:</p> <pre><code>import { AgentEvaluator } from 'adk-typescript';\n\ntest('Trip planner with initial state', async () =&gt; {\n  await AgentEvaluator.evaluate({\n    agentModule: 'tests/integration/fixture/trip_planner_agent',\n    evalDataset: 'tests/integration/fixture/trip_planner_agent/simple_test.test.json',\n    initialSessionFile: 'tests/integration/fixture/trip_planner_agent/initial.session.json'\n  });\n});\n</code></pre>"},{"location":"evaluate/#3-npx-adk-eval-run-evaluations-via-the-cli","title":"3. <code>npx adk eval</code> - Run Evaluations via the CLI","text":"<p>You can also run evaluation of an eval set file through the command line interface (CLI). This runs the same evaluation that runs on the UI, but it helps with automation, i.e. you can add this command as a part of your regular build generation and verification process.</p> <p>Here is the command:</p> <pre><code>npx adk eval \\\n    &lt;AGENT_MODULE_FILE_PATH&gt; \\\n    &lt;EVAL_SET_FILE_PATH&gt; \\\n    [--config_file_path=&lt;PATH_TO_TEST_JSON_CONFIG_FILE&gt;] \\\n    [--print_detailed_results]\n</code></pre> <p>For example:</p> <pre><code>npx adk eval \\\n    samples_for_testing/hello_world \\\n    samples_for_testing/hello_world/hello_world_eval_set_001.evalset.json\n</code></pre> <p>Here are the details for each command line argument:</p> <ul> <li><code>AGENT_MODULE_FILE_PATH</code>: The path to the entry point file that exports the agent. This is typically the file that contains the root agent.  </li> <li><code>EVAL_SET_FILE_PATH</code>: The path to evaluations file(s). You can specify one or more eval set file paths. For all evals in the file will be run by default. If you want to run only specific evals from an eval set, first create a comma-separated list of eval names and then add that as a suffix to the eval set file name, demarcated by a colon <code>:</code> .</li> <li>For example: <code>sample_eval_set_file.json:eval_1,eval_2,eval_3</code> <code>This will only run eval_1, eval_2 and eval_3 from sample_eval_set_file.json</code> </li> <li><code>CONFIG_FILE_PATH</code>: The path to the config file.  </li> <li><code>PRINT_DETAILED_RESULTS</code>: Prints detailed results on the console.</li> </ul>"},{"location":"events/","title":"Events:","text":"<p>Events are the fundamental units of information flow within the Agent Development Kit (ADK). They represent every significant occurrence during an agent's interaction lifecycle, from initial user input to the final response and all the steps in between. Understanding events is crucial because they are the primary way components communicate, state is managed, and control flow is directed.</p>"},{"location":"events/#what-events-are-and-why-they-matter","title":"What Events Are and Why They Matter","text":"<p>An <code>Event</code> in ADK is an immutable record representing a specific point in the agent's execution. It captures user messages, agent replies, requests to use tools (function calls), tool results, state changes, control signals, and errors. Technically, it's an instance of the <code>Event</code> class from the events directory, which builds upon the basic <code>LlmResponse</code> structure by adding essential ADK-specific metadata and an <code>actions</code> payload.</p> <pre><code>// Conceptual Structure of an Event\n// import { LlmResponse } from '../models/LlmResponse';\n// import { EventActions } from './EventActions';\n// import { FunctionCall, FunctionResponse } from '../models/types';\n\n// export class Event extends LlmResponse {\n//     // --- LlmResponse fields ---\n//     content?: any;\n//     partial?: boolean;\n//     turnComplete?: boolean;\n//     errorCode?: string;\n//     errorMessage?: string;\n//     interrupted?: boolean;\n//     customMetadata?: Record&lt;string, any&gt;;\n//     // ... other response fields ...\n\n//     // --- ADK specific additions ---\n//     author: string;       // 'user' or agent name\n//     invocationId: string; // ID for the whole interaction run\n//     id: string;           // Unique ID for this specific event\n//     timestamp: number;    // Creation time (seconds since epoch)\n//     actions: EventActions; // Important for side-effects &amp; control\n//     longRunningToolIds?: Set&lt;string&gt;; // IDs of long-running tool calls\n//     branch?: string;      // Hierarchy path\n//     // ...\n// }\n</code></pre> <p>Events are central to ADK's operation for several key reasons:</p> <ol> <li>Communication: They serve as the standard message format between the user interface, the <code>Runner</code>, agents, the LLM, and tools. Everything flows as an <code>Event</code>.</li> <li>Signaling State &amp; Artifact Changes: Events carry instructions for state modifications via <code>event.actions.stateDelta</code> and track artifact updates via <code>event.actions.artifactDelta</code>. The <code>BaseSessionService</code> (and its implementations) use these signals to ensure persistence.</li> <li>Control Flow: Specific fields like <code>event.actions.transferToAgent</code> or <code>event.actions.escalate</code> act as signals that direct the framework, determining which agent runs next or if a loop should terminate.</li> <li>History &amp; Observability: The sequence of events recorded in <code>session.events</code> provides a complete, chronological history of an interaction, invaluable for debugging, auditing, and understanding agent behavior step-by-step.</li> </ol> <p>In essence, the entire process, from a user's query to the agent's final answer, is orchestrated through the generation, interpretation, and processing of <code>Event</code> objects.</p>"},{"location":"events/#understanding-and-using-events","title":"Understanding and Using Events","text":"<p>As a developer, you'll primarily interact with the stream of events yielded by the <code>Runner</code>. Here's how to understand and extract information from them:</p>"},{"location":"events/#identifying-event-origin-and-type","title":"Identifying Event Origin and Type","text":"<p>Quickly determine what an event represents by checking:</p> <ul> <li>Who sent it? (<code>event.author</code>)<ul> <li><code>'user'</code>: Indicates input directly from the end-user.</li> <li><code>'AgentName'</code>: Indicates output or action from a specific agent (e.g., <code>'WeatherAgent'</code>, <code>'SummarizerAgent'</code>).</li> </ul> </li> <li>What's the main payload? (<code>event.content</code> and <code>event.content.parts</code>)<ul> <li>Text: If <code>event.content.parts[0].text</code> exists, it's likely a conversational message.</li> <li>Tool Call Request: Check <code>event.getFunctionCalls()</code>. If not empty, the LLM is asking to execute one or more tools. Each item in the list has <code>.name</code> and <code>.args</code>.</li> <li>Tool Result: Check <code>event.getFunctionResponses()</code>. If not empty, this event carries the result(s) from tool execution(s). Each item has <code>.name</code> and <code>.response</code> (the object returned by the tool). Note: For history structuring, the <code>role</code> inside the <code>content</code> is often <code>'user'</code>, but the event <code>author</code> is typically the agent that requested the tool call.</li> </ul> </li> <li>Is it streaming output? (<code>event.partial</code>)<ul> <li><code>true</code>: This is an incomplete chunk of text from the LLM; more will follow.</li> <li><code>false</code> or <code>undefined</code>: This part of the content is complete (though the overall turn might not be finished if <code>turnComplete</code> is also false).</li> </ul> </li> </ul> <pre><code>// TypeScript: Basic event identification\n// (async () =&gt; {\n//   for await (const event of runner.runAsync(...)) {\n//     console.log(`Event from: ${event.author}`);\n//\n//     if (event.content &amp;&amp; event.content.parts) {\n//       if (event.getFunctionCalls().length &gt; 0) {\n//         console.log(\"  Type: Tool Call Request\");\n//       } else if (event.getFunctionResponses().length &gt; 0) {\n//         console.log(\"  Type: Tool Result\");\n//       } else if (event.content.parts[0].text) {\n//         if (event.partial) {\n//           console.log(\"  Type: Streaming Text Chunk\");\n//         } else {\n//           console.log(\"  Type: Complete Text Message\");\n//         }\n//       } else {\n//         console.log(\"  Type: Other Content (e.g., code result)\");\n//       }\n//     } else if (event.actions &amp;&amp; \n//                (Object.keys(event.actions.stateDelta).length &gt; 0 || \n//                 Object.keys(event.actions.artifactDelta).length &gt; 0)) {\n//       console.log(\"  Type: State/Artifact Update\");\n//     } else {\n//       console.log(\"  Type: Control Signal or Other\");\n//     }\n//   }\n// })();\n</code></pre>"},{"location":"events/#extracting-key-information","title":"Extracting Key Information","text":"<p>Once you know the event type, access the relevant data:</p> <ul> <li>Text Content: <code>text = event.content.parts[0].text</code> (Always check <code>event.content</code> and <code>event.content.parts</code> first).</li> <li>Function Call Details: <pre><code>const calls = event.getFunctionCalls();\nif (calls.length &gt; 0) {\n  for (const call of calls) {\n    const toolName = call.name;\n    const arguments = call.args; // This is usually an object\n    console.log(`  Tool: ${toolName}, Args:`, arguments);\n    // Application might dispatch execution based on this\n  }\n}\n</code></pre></li> <li>Function Response Details: <pre><code>const responses = event.getFunctionResponses();\nif (responses.length &gt; 0) {\n  for (const response of responses) {\n    const toolName = response.name;\n    const resultObj = response.response; // The object returned by the tool\n    console.log(`  Tool Result: ${toolName} -&gt;`, resultObj);\n  }\n}\n</code></pre></li> <li>Identifiers:<ul> <li><code>event.id</code>: Unique ID for this specific event instance (an 8-character random string generated by <code>Event.newId()</code>).</li> <li><code>event.invocationId</code>: ID for the entire user-request-to-final-response cycle this event belongs to. Useful for logging and tracing.</li> </ul> </li> </ul>"},{"location":"events/#detecting-actions-and-side-effects","title":"Detecting Actions and Side Effects","text":"<p>The <code>event.actions</code> object signals changes that occurred or should occur. Always check if <code>event.actions</code> exists before accessing its fields.</p> <ul> <li>State Changes: <code>delta = event.actions.stateDelta</code> gives you an object of <code>{key: value}</code> pairs that were modified in the session state during the step that produced this event.     <pre><code>if (event.actions &amp;&amp; Object.keys(event.actions.stateDelta).length &gt; 0) {\n  console.log(`  State changes:`, event.actions.stateDelta);\n  // Update local UI or application state if necessary\n}\n</code></pre></li> <li>Artifact Saves: <code>artifactChanges = event.actions.artifactDelta</code> gives you an object of <code>{filename: version}</code> indicating which artifacts were saved and their new version number.     <pre><code>if (event.actions &amp;&amp; Object.keys(event.actions.artifactDelta).length &gt; 0) {\n  console.log(`  Artifacts saved:`, event.actions.artifactDelta);\n  // UI might refresh an artifact list\n}\n</code></pre></li> <li>Control Flow Signals: Check boolean flags or string values:<ul> <li><code>event.actions.transferToAgent</code> (string): Control should pass to the named agent.</li> <li><code>event.actions.escalate</code> (boolean): A loop should terminate.</li> <li><code>event.actions.skipSummarization</code> (boolean): A tool result should not be summarized by the LLM.</li> <li><code>event.actions.requestedAuthConfigs</code> (Map): Authentication configurations requested by tools. <pre><code>if (event.actions) {\n  if (event.actions.transferToAgent) {\n    console.log(`  Signal: Transfer to ${event.actions.transferToAgent}`);\n  }\n  if (event.actions.escalate) {\n    console.log(\"  Signal: Escalate (terminate loop)\");\n  }\n  if (event.actions.skipSummarization) {\n    console.log(\"  Signal: Skip summarization for tool result\");\n  }\n  if (event.actions.requestedAuthConfigs.size &gt; 0) {\n    console.log(\"  Signal: Authentication requested for tools\");\n  }\n}\n</code></pre>"},{"location":"events/#determining-if-an-event-is-a-final-response","title":"Determining if an Event is a \"Final\" Response","text":"<p>Use the built-in helper method <code>event.isFinalResponse()</code> to identify events suitable for display as the agent's complete output for a turn.</p> <ul> <li>Purpose: Filters out intermediate steps (like tool calls, partial streaming text, internal state updates) from the final user-facing message(s).</li> <li>When <code>true</code>? The implementation in code checks:<ol> <li>If <code>this.actions.skipSummarization</code> is true (regardless of event content).</li> <li>If <code>this.longRunningToolIds</code> is set (indicating a tool is running in the background).</li> <li>OR, all of the following are met:<ul> <li>No function calls (<code>getFunctionCalls()</code> is empty).</li> <li>No function responses (<code>getFunctionResponses()</code> is empty).</li> <li>Not a partial stream chunk (<code>partial</code> is not <code>true</code>).</li> <li>Doesn't end with a code execution result that might need further processing/display.</li> </ul> </li> </ol> </li> <li> <p>Usage: Filter the event stream in your application logic.</p> <pre><code>// TypeScript: Handling final responses in application\n// let fullResponseText = \"\";\n// (async () =&gt; {\n//   for await (const event of runner.runAsync(...)) {\n//     // Accumulate streaming text if needed...\n//     if (event.partial &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; \n//         event.content.parts[0].text) {\n//       fullResponseText += event.content.parts[0].text;\n//     }\n//\n//     // Check if it's a final, displayable event\n//     if (event.isFinalResponse()) {\n//       console.log(\"\\n--- Final Output Detected ---\");\n//       if (event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n//         // If it's the final part of a stream, use accumulated text\n//         const finalText = fullResponseText + (event.content.parts[0].text || \"\");\n//         console.log(`Display to user: ${finalText.trim()}`);\n//         fullResponseText = \"\"; // Reset accumulator\n//       } else if (event.actions.skipSummarization) {\n//         // Handle displaying the raw tool result if needed\n//         const responseData = event.getFunctionResponses()[0].response;\n//         console.log(\"Display raw tool result:\", responseData);\n//       } else if (event.longRunningToolIds) {\n//         console.log(\"Display message: Tool is running in background...\");\n//       } else {\n//         // Handle other types of final responses if applicable\n//         console.log(\"Display: Final non-textual response or signal.\");\n//       }\n//     }\n//   }\n// })();\n</code></pre> </li> </ul> <p>By carefully examining these aspects of an event, you can build robust applications that react appropriately to the rich information flowing through the ADK system.</p>"},{"location":"events/#how-events-flow-generation-and-processing","title":"How Events Flow: Generation and Processing","text":"<p>Events are created at different points and processed systematically by the framework. Understanding this flow helps clarify how actions and history are managed.</p> <ul> <li> <p>Generation Sources:</p> <ul> <li>User Input: The <code>Runner</code> typically wraps initial user messages or mid-conversation inputs into an <code>Event</code> with <code>author='user'</code>.</li> <li>Agent Logic: Agents (<code>BaseAgent</code>, <code>LlmAgent</code>) explicitly create and yield <code>new Event({author: this.name, ...})</code> objects to communicate responses or signal actions.</li> <li>LLM Responses: The ADK model integration layer translates raw LLM output (text, function calls, errors) into <code>Event</code> objects, authored by the calling agent.</li> <li>Tool Results: After a tool executes, the framework generates an <code>Event</code> containing the <code>functionResponse</code>. The <code>author</code> is typically the agent that requested the tool, while the <code>role</code> inside the <code>content</code> is set to <code>'user'</code> for the LLM history.</li> </ul> </li> <li> <p>Processing Flow:</p> <ol> <li>Yield: An event is generated and yielded by its source.</li> <li>Runner Receives: The main <code>Runner</code> executing the agent receives the event.</li> <li>SessionService Processing (<code>appendEvent</code>): The <code>Runner</code> sends the event to the configured <code>SessionService</code> (an implementation of <code>BaseSessionService</code>). This is a critical step:<ul> <li>Processes State Delta: The <code>BaseSessionService._updateSessionStateFromEvent</code> method processes <code>event.actions.stateDelta</code> and applies it to <code>session.state</code>, filtering out keys with <code>temp:</code> prefix.</li> <li>Artifact Processing: Note that while <code>event.actions.artifactDelta</code> tracks which artifacts were saved, the actual artifact handling is implementation-specific and not directly handled in the base <code>appendEvent</code> method.</li> <li>Finalizes Metadata: The event ID and timestamp are usually set during construction of the Event object.</li> <li>Persists to History: Appends the processed event to the <code>session.events</code> list.</li> </ul> </li> <li>External Yield: The <code>Runner</code> yields the processed event outwards to the calling application (e.g., the code that invoked <code>runner.runAsync</code>).</li> </ol> </li> </ul> <p>This flow ensures that state changes and history are consistently recorded alongside the communication content of each event.</p>"},{"location":"events/#common-event-examples-illustrative-patterns","title":"Common Event Examples (Illustrative Patterns)","text":"<p>Here are concise examples of typical events you might see in the stream:</p> <ul> <li>User Input: <pre><code>{\n  \"author\": \"user\",\n  \"invocationId\": \"e-xyz...\",\n  \"content\": {\"parts\": [{\"text\": \"Book a flight to London for next Tuesday\"}]}\n  // actions usually empty\n}\n</code></pre></li> <li>Agent Final Text Response: (<code>isFinalResponse() === true</code>)     <pre><code>{\n  \"author\": \"TravelAgent\",\n  \"invocationId\": \"e-xyz...\",\n  \"content\": {\"parts\": [{\"text\": \"Okay, I can help with that. Could you confirm the departure city?\"}]},\n  \"partial\": false,\n  \"turnComplete\": true\n  // actions might have state delta, etc.\n}\n</code></pre></li> <li>Agent Streaming Text Response: (<code>isFinalResponse() === false</code>)     <pre><code>{\n  \"author\": \"SummaryAgent\",\n  \"invocationId\": \"e-abc...\",\n  \"content\": {\"parts\": [{\"text\": \"The document discusses three main points:\"}]},\n  \"partial\": true,\n  \"turnComplete\": false\n}\n// ... more partial=true events follow ...\n</code></pre></li> <li>Tool Call Request (by LLM): (<code>isFinalResponse() === false</code>)     <pre><code>{\n  \"author\": \"TravelAgent\",\n  \"invocationId\": \"e-xyz...\",\n  \"content\": {\"parts\": [{\"functionCall\": {\"name\": \"findAirports\", \"args\": {\"city\": \"London\"}}}]}\n  // actions usually empty\n}\n</code></pre></li> <li>Tool Result Provided (to LLM): (<code>isFinalResponse()</code> depends on <code>skipSummarization</code>)     <pre><code>{\n  \"author\": \"TravelAgent\", // Author is agent that requested the call\n  \"invocationId\": \"e-xyz...\",\n  \"content\": {\n    \"role\": \"user\", // Role for LLM history\n    \"parts\": [{\"functionResponse\": {\"name\": \"findAirports\", \"response\": {\"result\": [\"LHR\", \"LGW\", \"STN\"]}}}]\n  },\n  \"actions\": {\n    \"skipSummarization\": true // This would make isFinalResponse() return true\n  }\n}\n</code></pre></li> <li>State/Artifact Update Only: (<code>isFinalResponse() === false</code>)     <pre><code>{\n  \"author\": \"InternalUpdater\",\n  \"invocationId\": \"e-def...\",\n  \"content\": null,\n  \"actions\": {\n    \"stateDelta\": {\"userStatus\": \"verified\"},\n    \"artifactDelta\": {\"verification_doc.pdf\": 2}\n  }\n}\n</code></pre></li> <li>Agent Transfer Signal: (<code>isFinalResponse() === false</code>)     <pre><code>{\n  \"author\": \"OrchestratorAgent\",\n  \"invocationId\": \"e-789...\",\n  \"content\": {\"parts\": [{\"functionCall\": {\"name\": \"transferToAgent\", \"args\": {\"agentName\": \"BillingAgent\"}}}]},\n  \"actions\": {\"transferToAgent\": \"BillingAgent\"} // Added by framework\n}\n</code></pre></li> <li>Loop Escalation Signal: (<code>isFinalResponse() === false</code>)     <pre><code>{\n  \"author\": \"CheckerAgent\",\n  \"invocationId\": \"e-loop...\",\n  \"content\": {\"parts\": [{\"text\": \"Maximum retries reached.\"}]}, // Optional content\n  \"actions\": {\"escalate\": true}\n}\n</code></pre></li> <li>Authentication Request: (<code>isFinalResponse() === false</code>)     <pre><code>{\n  \"author\": \"APIAgent\",\n  \"invocationId\": \"e-auth...\",\n  \"content\": {\"parts\": [{\"text\": \"Need authentication to proceed\"}]},\n  \"actions\": {\n    \"requestedAuthConfigs\": {\n      \"func-123\": {\n        \"type\": \"oauth\",\n        \"provider\": \"gmail\"\n      }\n    }\n  }\n}\n</code></pre></li> </ul>"},{"location":"events/#additional-context-and-event-details","title":"Additional Context and Event Details","text":"<p>Beyond the core concepts, here are a few specific details about context and events that are important for certain use cases:</p> <ol> <li> <p><code>ToolContext.functionCallId</code> (Linking Tool Actions):</p> <ul> <li>When an LLM requests a tool (<code>FunctionCall</code>), that request has an ID. The <code>ToolContext</code> provided to your tool function includes this <code>functionCallId</code>.</li> <li>Importance: This ID is crucial for linking actions like authentication (<code>requestCredential</code>, <code>getAuthResponse</code>) back to the specific tool request that initiated them, especially if multiple tools are called in one turn. The framework uses this ID internally for associating auth requests with the right tool call.</li> </ul> </li> <li> <p>How State/Artifact Changes are Recorded:</p> <ul> <li>When you modify state (<code>context.state['key'] = value</code>) or save an artifact (<code>context.saveArtifact(...)</code>) using <code>CallbackContext</code> or <code>ToolContext</code>, these changes aren't immediately written to persistent storage.</li> <li>Instead, they populate the <code>stateDelta</code> and <code>artifactDelta</code> fields within the <code>EventActions</code> object.</li> <li>This <code>EventActions</code> object is attached to the next event generated after the change (e.g., the agent's response or a tool result event).</li> <li>The <code>BaseSessionService.appendEvent</code> method reads the state deltas from the incoming event and applies non-temporary ones to the session's state. The handling of artifact deltas depends on the specific SessionService implementation.</li> </ul> </li> <li> <p>State Scope Prefixes (<code>app:</code>, <code>user:</code>, <code>temp:</code>):</p> <ul> <li>When managing state via <code>context.state</code>, you can optionally use prefixes:<ul> <li><code>app:mySetting</code>: Suggests state relevant to the entire application (requires a persistent <code>SessionService</code>).</li> <li><code>user:userPreference</code>: Suggests state relevant to the specific user across sessions (requires a persistent <code>SessionService</code>).</li> <li><code>temp:intermediateResult</code> or no prefix: Typically session-specific or temporary state for the current invocation.</li> </ul> </li> <li>The <code>BaseSessionService._updateSessionStateFromEvent</code> method specifically excludes keys with the <code>temp:</code> prefix from being persisted to the session state.</li> </ul> </li> <li> <p>Conversation History vs Events:</p> <ul> <li>The <code>Session</code> class maintains both <code>events: Event[]</code> and a private <code>conversationHistory: Content[]</code> property.</li> <li>The <code>events</code> array contains the complete record of all events in chronological order, while the <code>conversationHistory</code> specifically stores semantic content for LLM context.</li> <li>Use <code>session.addConversationHistory(content)</code> to add to the conversation history and <code>session.getConversationHistory()</code> to retrieve it.</li> </ul> </li> <li> <p>Error Events:</p> <ul> <li>An <code>Event</code> can represent an error. Check the <code>event.errorCode</code> and <code>event.errorMessage</code> fields (inherited from <code>LlmResponse</code>).</li> <li>Errors might originate from the LLM (e.g., safety filters, resource limits) or potentially be packaged by the framework if a tool fails critically. Check tool <code>FunctionResponse</code> content for typical tool-specific errors. <pre><code>// Example Error Event (conceptual)\n{\n  \"author\": \"LLMAgent\",\n  \"invocationId\": \"e-err...\",\n  \"content\": null,\n  \"errorCode\": \"SAFETY_FILTER_TRIGGERED\",\n  \"errorMessage\": \"Response blocked due to safety settings.\",\n  \"actions\": {}\n}\n</code></pre></li> </ul> </li> </ol> <p>These details provide a more complete picture for advanced use cases involving tool authentication, state persistence scope, and error handling within the event stream.</p>"},{"location":"events/#best-practices-for-working-with-events","title":"Best Practices for Working with Events","text":"<p>To use events effectively in your ADK applications:</p> <ul> <li>Clear Authorship: When building custom agents (<code>BaseAgent</code>), ensure <code>new Event({author: this.name, ...})</code> to correctly attribute agent actions in the history. The framework generally handles authorship correctly for LLM/tool events.</li> <li>Semantic Content &amp; Actions: Use <code>event.content</code> for the core message/data (text, function call/response). Use <code>event.actions</code> specifically for signaling side effects (state/artifact deltas) or control flow (<code>transferToAgent</code>, <code>escalate</code>, <code>skipSummarization</code>, <code>requestedAuthConfigs</code>).</li> <li>Idempotency Awareness: Understand that the <code>BaseSessionService</code> is responsible for applying the state changes signaled in <code>event.actions.stateDelta</code>. Implementation-specific sessionService classes may handle artifact deltas differently.</li> <li>Use <code>isFinalResponse()</code>: Rely on this helper method in your application/UI layer to identify complete, user-facing text responses. Avoid manually replicating its logic.</li> <li>Leverage History: The <code>session.events</code> list is your primary debugging tool. Examine the sequence of authors, content, and actions to trace execution and diagnose issues.</li> <li>Use Metadata: Use <code>invocationId</code> to correlate all events within a single user interaction. Use <code>event.id</code> to reference specific, unique occurrences.</li> </ul> <p>Treating events as structured messages with clear purposes for their content and actions is key to building, debugging, and managing complex agent behaviors in ADK.</p>"},{"location":"get-started/","title":"Get Started with ADK TypeScript","text":"<p>Agent Development Kit (ADK) for TypeScript is designed to empower developers to build, manage, evaluate, and deploy AI-powered agents using TypeScript. It provides a robust and flexible environment for creating both conversational and non-conversational agents, capable of handling complex tasks and workflows.</p> <ul> <li> <p> Installation</p> <p>Install <code>adk-typescript</code> with <code>npm</code> or <code>yarn</code> and get set up in minutes.</p> <p> More information</p> </li> <li> <p> Quickstart</p> <p>Create your first ADK TypeScript agent with tools in minutes.</p> <p> More information</p> </li> <li> <p> Quickstart (Streaming)</p> <p>Create your first real-time streaming ADK TypeScript agent using Express.js and Socket.IO.</p> <p> More information</p> </li> <li> <p> Tutorial</p> <p>Build your first ADK TypeScript multi-agent system with memory and safety features.</p> <p> More information</p> </li> <li> <p> Discover sample agents</p> <p>Discover sample agents for various use cases. (Note: Current samples may primarily be in Python, but demonstrate concepts applicable to TypeScript.)</p> <p> Discover adk-samples</p> </li> <li> <p> About ADK TypeScript</p> <p>Learn about the key components and concepts for building and deploying ADK TypeScript agents.</p> <p> More information</p> </li> </ul>"},{"location":"get-started/about/","title":"Agent Development Kit (ADK) for TypeScript","text":"<p>  Build, Evaluate and Deploy agents, seamlessly!  </p> <p>ADK for TypeScript is designed to empower developers to build, manage, evaluate, and deploy AI-powered agents using TypeScript. It provides a robust and flexible environment for creating both conversational and non-conversational agents, capable of handling complex tasks and workflows.</p> <p> </p>"},{"location":"get-started/about/#core-concepts","title":"Core Concepts","text":"<p>ADK TypeScript is built around a few key primitives and concepts that make it powerful and flexible. Here are the essentials:</p> <ul> <li>Agent (<code>BaseAgent</code>, <code>LlmAgent</code>): The fundamental worker unit designed for specific tasks. Agents can use language models (<code>LlmAgent</code>) for complex reasoning or act as deterministic controllers of execution using workflow agents like <code>SequentialAgent</code>, <code>ParallelAgent</code>, or <code>LoopAgent</code>.</li> <li>Tool (<code>BaseTool</code>, <code>FunctionTool</code>, <code>AgentTool</code>, etc.): Gives agents abilities beyond conversation, letting them interact with external APIs (<code>RestApiTool</code>), search information (<code>GoogleSearchTool</code>, Retrieval tools), run code (<code>CodeExecutionTool</code>), or call other agents (<code>AgentTool</code>). Custom functions are easily wrapped using <code>FunctionTool</code>.</li> <li>Callbacks (<code>beforeModelCallback</code>, <code>afterModelCallback</code>, etc.): Custom TypeScript functions you provide to run at specific points in the agent's process (like before/after LLM calls or tool execution), allowing for checks, logging, or behavior modifications.</li> <li>Session Management (<code>Session</code>, <code>State</code>, <code>SessionService</code>): Handles the context of a single conversation (<code>Session</code>), including its history (<code>events</code>) and the agent's working memory for that conversation (<code>State</code>). <code>SessionService</code> (e.g., <code>InMemorySessionService</code>, <code>DatabaseSessionService</code>) manages session persistence.</li> <li>Memory (<code>BaseMemoryService</code>): Enables agents to recall information about a user across multiple sessions, providing long-term context (distinct from short-term session <code>State</code>). Implementations like <code>InMemoryMemoryService</code> and <code>VertexAiRagMemoryService</code> are provided.</li> <li>Artifact Management (<code>BaseArtifactService</code>): Allows agents to save, load, and manage files or binary data (like images, PDFs represented as <code>Part</code> with <code>inlineData</code>) associated with a session or user. Implementations like <code>InMemoryArtifactService</code> and <code>GcsArtifactService</code> exist.</li> <li>Code Execution (<code>BaseCodeExecutor</code>): The ability for agents (usually via Tools like <code>CodeExecutionTool</code> or the built-in model capability via <code>BuiltInCodeExecutionTool</code>) to generate and execute code.</li> <li>Planning (<code>BasePlanner</code>, <code>PlanReActPlanner</code>): An advanced capability where agents can break down complex goals into smaller steps and plan how to achieve them, like using a ReAct planner.</li> <li>Models (<code>BaseLlm</code>, <code>LlmRegistry</code>, <code>LiteLlm</code>): The underlying LLM that powers <code>LlmAgent</code>s. <code>LlmRegistry</code> manages built-in support (like <code>Gemini</code>, <code>Claude</code>), while <code>LiteLlm</code> provides a wrapper for broader compatibility via the LiteLLM standard.</li> <li>Event (<code>Event</code>): The basic unit of communication representing things that happen during a session (user message, agent reply, tool use), forming the conversation history stored in <code>Session.events</code>. Contains <code>Content</code>.</li> <li>Content &amp; Part (<code>Content</code>, <code>Part</code>): Structures defining messages. <code>Content</code> has a <code>role</code> (user, model, etc.) and an array of <code>Part</code>s. A <code>Part</code> can contain <code>text</code>, <code>functionCall</code>, <code>functionResponse</code>, or <code>inlineData</code>.</li> <li>Runner (<code>Runner</code>, <code>InMemoryRunner</code>): The engine that manages the execution flow, orchestrates agent interactions based on <code>Events</code>, and coordinates with backend services like <code>SessionService</code> and <code>ArtifactService</code>. <code>InMemoryRunner</code> bundles the agent with in-memory services for easy local testing.</li> <li>Flow (<code>BaseLlmFlow</code>, <code>AutoFlow</code>, <code>SingleFlow</code>): Defines the control logic within an <code>LlmAgent</code>, managing the sequence of LLM calls, tool executions, and processing steps. <code>AutoFlow</code> provides default behavior including delegation.</li> </ul> <p>Note: Features like Multimodal Streaming, Evaluation, Deployment, Debugging, and Trace are also part of the broader ADK TypeScript ecosystem, supporting real-time interaction and the development lifecycle.</p>"},{"location":"get-started/about/#key-capabilities","title":"Key Capabilities","text":"<p>ADK TypeScript offers several key advantages for developers building agentic applications:</p> <ol> <li>Multi-Agent System Design: Easily build applications composed of multiple, specialized agents (<code>BaseAgent</code>, <code>LlmAgent</code>) arranged hierarchically using <code>subAgents</code>. Agents can coordinate complex tasks, delegate using LLM-driven transfer (via <code>AutoFlow</code>) or explicit <code>AgentTool</code> invocation, enabling modular and scalable solutions.</li> <li>Rich Tool Ecosystem: Equip agents with diverse capabilities. ADK TypeScript supports integrating custom functions (<code>FunctionTool</code>), using other agents as tools (<code>AgentTool</code>), leveraging built-in functionalities like code execution (<code>CodeExecutionTool</code>, <code>BuiltInCodeExecutionTool</code>), and interacting with external data sources and APIs (e.g., <code>GoogleSearchTool</code>, <code>VertexAISearchTool</code>, <code>RestApiTool</code>, <code>APIHubToolset</code>). Support for long-running tools (<code>LongRunningFunctionTool</code>) allows handling asynchronous operations effectively.</li> <li>Flexible Orchestration: Define complex agent workflows using built-in workflow agents (<code>SequentialAgent</code>, <code>ParallelAgent</code>, <code>LoopAgent</code>) alongside LLM-driven dynamic routing via <code>AutoFlow</code>. This allows for both predictable pipelines and adaptive agent behavior.</li> <li>Integrated Developer Tooling: Develop and iterate locally with ease. ADK TypeScript includes tools like a command-line interface (<code>adk-ts</code>) and a Developer UI (<code>adk-ts web</code>) for running agents, inspecting execution steps (<code>Event</code> logs, state changes), debugging interactions, and visualizing agent definitions (<code>adk-ts graph</code>).</li> <li>Native Streaming Support: Build real-time, interactive experiences with native support for bidirectional streaming (text and potentially audio/video) using <code>Runner.runLive</code>, <code>LiveRequestQueue</code>, and compatible models/connections (<code>GeminiLlmConnection</code>).</li> <li>Built-in Agent Evaluation: Assess agent performance systematically using the <code>evaluation</code> module (<code>AgentEvaluator</code>, <code>ResponseEvaluator</code>, <code>TrajectoryEvaluator</code>). Create multi-turn evaluation datasets (<code>.test.json</code> files) and run evaluations locally (via CLI or potentially the dev UI) to measure quality and guide improvements.</li> <li>Broad LLM Support: While optimized for Google's Gemini models (via <code>LlmRegistry</code> and <code>Gemini</code>), the framework is designed for flexibility. Integrate various LLMs using the <code>LiteLlm</code> wrapper or by implementing the <code>BaseLlm</code> interface for custom models.</li> <li>Artifact Management: Enable agents to handle files and binary data. The framework provides mechanisms (<code>BaseArtifactService</code>, <code>InMemoryArtifactService</code>, <code>GcsArtifactService</code>) and context methods (<code>ToolContext.saveArtifact</code>, <code>ToolContext.loadArtifact</code>) for managing versioned artifacts.</li> <li>Extensibility and Interoperability: ADK TypeScript promotes an open ecosystem. Easily integrate and reuse tools from other popular agent frameworks like LangChain (<code>LangchainTool</code>) and CrewAI (<code>CrewaiTool</code>).</li> <li>State and Memory Management: Automatically handles short-term conversational memory (<code>State</code> within a <code>Session</code>) managed by the <code>SessionService</code>. Provides integration points for longer-term <code>Memory</code> services (<code>BaseMemoryService</code>) for cross-session recall. <code>ToolContext</code> provides access to state within tools.</li> </ol> <p> </p>"},{"location":"get-started/about/#get-started","title":"Get Started","text":"<ul> <li>Ready to build your first agent? Try the quickstart</li> </ul>"},{"location":"get-started/installation/","title":"Installing ADK TypeScript","text":"<p>This guide explains how to install the Agent Development Kit (ADK) for TypeScript and set up your development environment.</p>"},{"location":"get-started/installation/#prerequisites","title":"Prerequisites","text":"<p>ADK TypeScript requires: - Node.js (v18 or higher) - npm (included with Node.js) or yarn</p> <p>If you don't have Node.js installed, download and install it from nodejs.org.</p>"},{"location":"get-started/installation/#installation","title":"Installation","text":"<p>Install ADK TypeScript locally in your project and use <code>npx</code> to run commands. This ensures consistent versions across development and production environments.</p> <pre><code># Create your project directory\nmkdir my-adk-project\ncd my-adk-project\n\n# Create your first agent (this will set up everything automatically)\nnpx adk create my-weather-agent\n</code></pre> <p>The <code>npx adk create</code> command will automatically: - Initialize your project with <code>package.json</code> and <code>tsconfig.json</code> (if not already present) - Install all necessary dependencies including ADK TypeScript - Set up the project structure - Create your agent with sample code - Walk you through configuring your LLM backend</p>"},{"location":"get-started/installation/#using-the-adk-commands","title":"Using the ADK Commands","text":"<p>Use <code>npx adk</code> to run all commands:</p> <pre><code># Create a new agent project\nnpx adk create my-weather-agent\n\n# Run an agent in terminal\nnpx adk run my-weather-agent\n\n# Start the web UI\nnpx adk web my-weather-agent\n\n# Run the API server\nnpx adk api_server --agent_dir my-weather-agent\n\n# Evaluate an agent\nnpx adk eval my-weather-agent eval_data.test.json\n\n# Generate agent graph\nnpx adk graph my-weather-agent --output graph.png\n</code></pre>"},{"location":"get-started/installation/#project-structure","title":"Project Structure","text":"<p>When you create an agent with <code>npx adk create</code>, it generates an efficient, scalable project structure:</p> <pre><code>my-adk-project/               # Your parent project folder\n\u251c\u2500\u2500 my-weather-agent/         # Your agent's code folder\n\u2502   \u251c\u2500\u2500 agent.ts              # Agent definition\n\u2502   \u2514\u2500\u2500 .env                  # API keys for this agent\n\u251c\u2500\u2500 package.json              # SHARED Node.js project manifest\n\u251c\u2500\u2500 tsconfig.json             # SHARED TypeScript configuration\n\u2514\u2500\u2500 dist/                     # (Created after build) Compiled output\n</code></pre> <p>This structure allows multiple agents to share dependencies while keeping their code and configuration separate.</p>"},{"location":"get-started/installation/#building-and-running","title":"Building and Running","text":"<p>After creating your agent, you need to build and run it:</p> <pre><code># Install dependencies (only needed once, or if you add more agents)\nnpm install\n\n# Build your TypeScript code\nnpm run build\n\n# Run your agent\nnpx adk run my-weather-agent\n# or start the web UI\nnpx adk web my-weather-agent\n</code></pre>"},{"location":"get-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Jump into the Quickstart to create your first agent</li> <li>Learn about ADK TypeScript Concepts to understand the core components</li> <li>Explore the Tutorial for building multi-agent systems</li> </ul>"},{"location":"get-started/quickstart-streaming/","title":"ADK TypeScript Streaming Quickstart","text":"<p>This quickstart guides you through creating a simple agent and using ADK TypeScript Streaming to enable voice and video communication with it that is low-latency and bidirectional. You'll learn how to install ADK TypeScript, set up a basic \"Google Search\" agent, and run the agent with Streaming using the <code>npx adk web</code> tool.</p> <p>This quickstart assumes a local development environment with Node.js (v18+ recommended), npm, and terminal access in Windows, Mac, or Linux environments.</p>"},{"location":"get-started/quickstart-streaming/#supported-models","title":"Supported models for voice/video streaming","text":"<p>In order to use voice/video streaming in ADK TypeScript, you will need to use Gemini models that support the necessary APIs for bidirectional streaming. You can find the model ID(s) that support these capabilities in the documentation:</p> <ul> <li>Google AI Studio: Gemini API Models (Look for models supporting streaming/multimodal features)</li> <li>Vertex AI: Gemini API Models (Look for models supporting streaming/multimodal features)</li> </ul>"},{"location":"get-started/quickstart-streaming/#1.-setup-installation-typescript","title":"1. Create Your Streaming Agent Project","text":"<p>Environment Setup:</p> <ul> <li>Ensure you have Node.js (version 18 or higher recommended) and npm installed.</li> </ul> <p>Create Project:</p> <pre><code># Create your project directory\nmkdir adk-streaming\ncd adk-streaming\n\n# Create your first agent (this will set up everything automatically)\nnpx adk create google_search_agent\n</code></pre> <p>The <code>npx adk create</code> command will automatically: - Initialize your project with <code>package.json</code> and <code>tsconfig.json</code> - Install all necessary dependencies including ADK TypeScript - Set up the project structure - Create your agent with sample code - Walk you through configuring your LLM backend</p> <p>Note: The command-line tool uses the prefix <code>npx adk</code> when running commands locally.</p>"},{"location":"get-started/quickstart-streaming/#2.-project-structure-typescript","title":"2. Update Agent for Google Search","text":""},{"location":"get-started/quickstart-streaming/#project-structure","title":"Project structure","text":"<p>After running <code>npx adk create</code>, your project will have this structure:</p> <pre><code>adk-streaming/                # Your project folder  \n\u251c\u2500\u2500 google_search_agent/      # Your agent's code folder\n\u2502   \u251c\u2500\u2500 agent.ts              # Agent definition\n\u2502   \u2514\u2500\u2500 .env                  # API keys for this agent\n\u251c\u2500\u2500 package.json              # SHARED Node.js project manifest\n\u251c\u2500\u2500 tsconfig.json             # SHARED TypeScript configuration\n\u2514\u2500\u2500 dist/                     # (Created after build) Compiled output\n</code></pre>"},{"location":"get-started/quickstart-streaming/#update-the-agent-for-google-search","title":"Update the agent for Google Search","text":"<p>Replace the generated <code>google_search_agent/agent.ts</code> with the following code optimized for streaming and Google Search:</p> <pre><code>// google_search_agent/agent.ts\nimport { LlmAgent as Agent } from 'adk-typescript/agents';\nimport { LlmRegistry } from 'adk-typescript/models';\nimport { googleSearch } from 'adk-typescript/tools';\n\n// Get the model instance using LlmRegistry\nconst geminiModel = LlmRegistry.newLlm(\n   \"gemini-1.5-flash\" // Or another compatible model \n   // Note: Ensure the model chosen supports the Google Search tool and streaming.\n);\n\nexport const rootAgent = new Agent({\n   // A unique name for the agent.\n   name: \"basic_search_agent\",\n   // The Large Language Model (LLM) instance the agent will use.\n   model: geminiModel,\n   // A short description of the agent's purpose.\n   description: \"Agent to answer questions using Google Search.\",\n   // Instructions to set the agent's behavior.\n   instruction: \"You are an expert researcher. You always stick to the facts provided by the search tool.\",\n   // Add google_search tool to perform grounding with Google search.\n   tools: [googleSearch]\n});\n</code></pre> <p>Note: To enable both text and audio/video input, the model must support bidirectional streaming. Verify these capabilities by referring to the official Google AI / Vertex AI documentation for your chosen model.</p> <p><code>agent.ts</code> is where your agent's logic is defined. You must export a <code>rootAgent</code> for the ADK tools to find it.</p> <p>Notice how easily you integrated grounding with Google Search. The <code>Agent</code> class and the imported <code>googleSearch</code> tool handle the complex interactions with the LLM and grounding with the search API.</p>"},{"location":"get-started/quickstart-streaming/#3.-set-up-the-platform-typescript","title":"3. Set up the model","text":"<p>Your agent needs credentials to securely call the LLM service. The <code>npx adk create</code> command prompted you for these and saved them to a <code>.env</code> file located inside your agent's folder (<code>google_search_agent/.env</code>).</p> <p>You can edit this file at any time to update your configuration:</p> Gemini - Google AI StudioGemini - Google Cloud Vertex AI <ol> <li>Get an API key from Google AI Studio.</li> <li> <p>This content will be in your <code>google_search_agent/.env</code> file:</p> <pre><code># Use Google AI backend (value 0 or false)\nGOOGLE_GENAI_USE_VERTEXAI=0\n# Your API Key\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE\n</code></pre> </li> </ol> <ol> <li>You need an existing Google Cloud account and a project.<ul> <li>Set up a Google Cloud project.</li> <li>Set up the gcloud CLI.</li> <li>Authenticate to Google Cloud for Application Default Credentials (ADC): <code>gcloud auth application-default login</code>.</li> <li>Enable the Vertex AI API.</li> </ul> </li> <li> <p>This content will be in your <code>google_search_agent/.env</code> file:</p> <pre><code># Use Vertex AI backend (value 1 or true)\nGOOGLE_GENAI_USE_VERTEXAI=1\n# Your Project ID\nGOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID\n# Your Project Location (e.g., us-central1)\nGOOGLE_CLOUD_LOCATION=us-central1\n# GOOGLE_API_KEY is NOT needed when using Vertex AI with ADC\n</code></pre> </li> </ol>"},{"location":"get-started/quickstart-streaming/#4.-try-it-adk-web-typescript","title":"4. Build and Run Your Streaming Agent","text":""},{"location":"get-started/quickstart-streaming/#build-your-agent","title":"Build Your Agent","text":"<p>First, build your TypeScript code:</p> <pre><code># Install dependencies (only needed once)\nnpm install\n\n# Build your TypeScript code\nnpm run build\n</code></pre>"},{"location":"get-started/quickstart-streaming/#test-with-adk-web-ui","title":"Test with ADK Web UI","text":"<p>Now, it's time to try the agent using the built-in development UI:</p> <pre><code># Run the Dev UI\nnpx adk web google_search_agent\n</code></pre> <p>This launches the web UI with your streaming-enabled agent.</p> <p>Step 1: Open the URL provided (typically <code>http://localhost:3000</code>) directly in your browser.</p> <p>Step 2: Select <code>google_search_agent</code> from the available agents.</p> <p>Troubleshooting</p> <p>If you do not see \"google_search_agent\" in the dropdown menu, ensure you ran <code>npx adk web google_search_agent</code> from the correct directory (your project root <code>adk-streaming/</code>) where your agent folder is located.</p>"},{"location":"get-started/quickstart-streaming/#try-with-text","title":"Try with text","text":"<p>Try the following prompts by typing them in the UI:</p> <ul> <li>What is the weather in New York?</li> <li>What is the time in New York?</li> <li>What is the weather in Paris?</li> <li>What is the time in Paris?</li> </ul> <p>The agent will use the Google Search tool to get the latest information to answer these questions.</p>"},{"location":"get-started/quickstart-streaming/#try-with-voice-and-video","title":"Try with voice and video","text":"<p>If the UI shows a microphone button, click it to enable voice input and ask a question aloud. You should hear the answer streamed back.</p> <p>If the UI shows a camera button, click it to enable video input. Ask questions like \"What do you see?\". The agent should describe the video feed (requires a model with vision capabilities).</p>"},{"location":"get-started/quickstart-streaming/#stop-the-tool","title":"Stop the tool","text":"<p>Stop the <code>adk web</code> server by pressing <code>Ctrl-C</code> in the console where it's running.</p>"},{"location":"get-started/quickstart-streaming/#note-on-adk-typescript-streaming","title":"Note on ADK TypeScript Streaming","text":"<p>The <code>runLive</code> method in the <code>Runner</code> and the <code>LiveRequestQueue</code> class provide the foundation for streaming interactions in ADK TypeScript. Unlike the Python SDK's distinct <code>bidiGenerateContent</code>, the TypeScript version integrates live capabilities into the standard <code>Runner.runLive</code> flow, often relying on the agent's underlying <code>invoke</code> method switching to its <code>runLiveImpl</code>. Tools can interact with the live stream if designed to do so (e.g., using <code>ToolContext</code> potentially with custom stream handling, although this isn't explicitly shown in the provided codebase).</p>"},{"location":"get-started/quickstart-streaming/#5.-build-custom-app-typescript","title":"5. Building a Custom Streaming App (Optional)","text":"<p>In the previous section, we have checked that our basic search agent works with the ADK TypeScript Streaming using the <code>adk web</code> tool. In this section, we will learn how to build your own web application capable of the streaming communication using Express.js and Socket.IO.</p> <p>Add <code>static</code> directory and <code>server.ts</code> file to your project root, as in the following structure:</p> <pre><code>adk-streaming/                # Project folder\n\u251c\u2500\u2500 server.ts                 # Express.js web app\n\u251c\u2500\u2500 static/                   # Static content folder\n\u2502   \u2514\u2500\u2500 index.html            # The web client page\n\u251c\u2500\u2500 google_search_agent/      # Agent folder\n\u2502   \u251c\u2500\u2500 agent.ts              # Agent definition\n\u2502   \u2514\u2500\u2500 .env                  # API keys and environment variables \n\u251c\u2500\u2500 package.json              # Node.js package file\n\u251c\u2500\u2500 tsconfig.json             # TypeScript configuration\n\u2514\u2500\u2500 dist/                     # (Created after build) Compiled output\n</code></pre> <p>server.ts</p> <p>First, install the additional dependencies we'll need:</p> <pre><code>npm install express socket.io\nnpm install @types/express --save-dev\n</code></pre> <p>Copy-paste the following code block to the server.ts file.</p> <pre><code>// server.ts\nimport express from 'express';\nimport * as http from 'http';\nimport * as path from 'path';\nimport * as dotenv from 'dotenv';\nimport { Server as SocketIOServer } from 'socket.io';\n\n// Load environment variables from the agent's .env file\ndotenv.config({ path: './google_search_agent/.env' });\n\n// Import from specific modules\nimport { Runner } from 'adk-typescript/runners';\nimport { Content, Part } from 'adk-typescript/models';\nimport { RunConfig } from 'adk-typescript/agents/run_config';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { LiveRequestQueue } from 'adk-typescript/agents';\n\nimport { rootAgent } from './google_search_agent/agent';\n\n//\n// ADK Streaming\n//\n\nconst APP_NAME = \"ADK Streaming example\";\nconst sessionService = new InMemorySessionService();\n\nfunction startAgentSession(sessionId: string) {\n  // Create a Session\n  const session = sessionService.createSession({\n    appName: APP_NAME,\n    userId: sessionId,\n    sessionId: sessionId,\n  });\n\n  // Create a Runner\n  const runner = new Runner({\n    appName: APP_NAME,\n    agent: rootAgent,\n    sessionService: sessionService,\n  });\n\n  // Set response modality = TEXT\n  const runConfig = new RunConfig({ responseModalities: [\"TEXT\"] });\n\n  // Create a LiveRequestQueue for this session\n  const liveRequestQueue = new LiveRequestQueue();\n\n  // Start agent session\n  const liveEvents = runner.runLive({\n    userId: 'user_123',\n    sessionId: session.id,\n    liveRequestQueue: liveRequestQueue,\n    runConfig: runConfig,\n  });\n\n  return { liveEvents, liveRequestQueue };\n}\n\nasync function agentToClientMessaging(socket: any, liveEvents: AsyncIterable&lt;any&gt;) {\n  try {\n    for await (const event of liveEvents) {\n      // turn_complete\n      if (event.turnComplete) {\n        socket.emit('message', JSON.stringify({ turn_complete: true }));\n        console.log(\"[TURN COMPLETE]\");\n      }\n\n      if (event.interrupted) {\n        socket.emit('message', JSON.stringify({ interrupted: true }));\n        console.log(\"[INTERRUPTED]\");\n      }\n\n      // Read the Content and its first Part\n      const part = (\n        event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0]\n      );\n      if (!part || !event.partial) {\n        continue;\n      }\n\n      // Get the text\n      const text = event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text;\n      if (!text) {\n        continue;\n      }\n\n      // Send the text to the client\n      socket.emit('message', JSON.stringify({ message: text }));\n      console.log(`[AGENT TO CLIENT]: ${text}`);\n    }\n  } catch (error) {\n    console.error(\"Error in agent to client messaging:\", error);\n  }\n}\n\nasync function clientToAgentMessaging(socket: any, liveRequestQueue: LiveRequestQueue) {\n  socket.on('message', (message: string) =&gt; {\n    const content: Content = {\n      role: \"user\",\n      parts: [{ text: message } as Part]\n    };\n    liveRequestQueue.sendContent(content);\n    console.log(`[CLIENT TO AGENT]: ${message}`);\n  });\n}\n\n//\n// Express web app\n//\n\nconst app = express();\nconst server = http.createServer(app);\nconst io = new SocketIOServer(server);\n\nconst STATIC_DIR = path.join(__dirname, 'static');\napp.use('/static', express.static(STATIC_DIR));\n\napp.get(\"/\", (_req, res) =&gt; {\n  return res.sendFile(path.join(STATIC_DIR, \"index.html\"));\n});\n\nio.on('connection', (socket) =&gt; {\n  const sessionId = `session_${Date.now()}`;\n  console.log(`Client #${sessionId} connected`);\n\n  // Start agent session\n  const { liveEvents, liveRequestQueue } = startAgentSession(sessionId);\n\n  // Start tasks\n  agentToClientMessaging(socket, liveEvents);\n  clientToAgentMessaging(socket, liveRequestQueue);\n\n  socket.on('disconnect', () =&gt; {\n    console.log(`Client #${sessionId} disconnected`);\n    liveRequestQueue.sendClose();\n  });\n});\n\nconst PORT = process.env.PORT || 8080;\nserver.listen(PORT, () =&gt; {\n  console.log(`Server running at http://localhost:${PORT}`);\n});\n</code></pre> <p>This code creates a real-time chat application using ADK TypeScript and Express.js with Socket.IO. It sets up a WebSocket endpoint where clients can connect and interact with a Google Search Agent.</p> <p>Key functionalities:</p> <ul> <li>Loads environment variables from the agent's <code>.env</code> file</li> <li>Uses ADK TypeScript to manage agent sessions and run the <code>google_search_agent</code></li> <li><code>startAgentSession</code> initializes an agent session with a live request queue for real-time communication</li> <li><code>agentToClientMessaging</code> asynchronously streams the agent's responses to the client</li> <li><code>clientToAgentMessaging</code> handles user inputs from the client to the agent</li> <li>Express.js serves a static frontend and handles WebSocket connections</li> </ul> <p>index.html</p> <p>Create the <code>static</code> directory and add the web client frontend by copying this HTML to <code>static/index.html</code>:</p> <pre><code># Create static directory\nmkdir static\n</code></pre> <pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;ADK TypeScript Streaming Test&lt;/title&gt;\n    &lt;script src=\"/socket.io/socket.io.js\"&gt;&lt;/script&gt;\n  &lt;/head&gt;\n\n  &lt;body&gt;\n    &lt;h1&gt;ADK TypeScript Streaming Test&lt;/h1&gt;\n    &lt;div\n      id=\"messages\"\n      style=\"height: 300px; overflow-y: auto; border: 1px solid black\"&gt;&lt;/div&gt;\n    &lt;br /&gt;\n\n    &lt;form id=\"messageForm\"&gt;\n      &lt;label for=\"message\"&gt;Message:&lt;/label&gt;\n      &lt;input type=\"text\" id=\"message\" name=\"message\" /&gt;\n      &lt;button type=\"submit\" id=\"sendButton\" disabled&gt;Send&lt;/button&gt;\n    &lt;/form&gt;\n  &lt;/body&gt;\n\n  &lt;script&gt;\n    // Connect the server with a WebSocket connection\n    const socket = io();\n\n    // Get DOM elements\n    const messageForm = document.getElementById(\"messageForm\");\n    const messageInput = document.getElementById(\"message\");\n    const messagesDiv = document.getElementById(\"messages\");\n    let currentMessageId = null;\n\n    // Socket.IO handlers\n    socket.on('connect', function () {\n      console.log(\"Socket.IO connection opened.\");\n      document.getElementById(\"sendButton\").disabled = false;\n      document.getElementById(\"messages\").textContent = \"Connection opened\";\n    });\n\n    socket.on('message', function (eventData) {\n      // Parse the incoming message\n      const packet = JSON.parse(eventData);\n      console.log(packet);\n\n      // Check if the turn is complete\n      // if turn complete, reset current message\n      if (packet.turn_complete &amp;&amp; packet.turn_complete == true) {\n        currentMessageId = null;\n        return;\n      }\n\n      // add a new message for a new turn\n      if (currentMessageId == null &amp;&amp; packet.message) {\n        currentMessageId = Math.random().toString(36).substring(7);\n        const message = document.createElement(\"p\");\n        message.id = currentMessageId;\n        // Append the message element to the messagesDiv\n        messagesDiv.appendChild(message);\n      }\n\n      // Add message text to the existing message element\n      if (packet.message) {\n        const message = document.getElementById(currentMessageId);\n        message.textContent += packet.message;\n\n        // Scroll down to the bottom of the messagesDiv\n        messagesDiv.scrollTop = messagesDiv.scrollHeight;\n      }\n    });\n\n    // When the connection is closed, try reconnecting\n    socket.on('disconnect', function () {\n      console.log(\"Socket.IO connection closed.\");\n      document.getElementById(\"sendButton\").disabled = true;\n      document.getElementById(\"messages\").textContent = \"Connection closed\";\n    });\n\n    socket.on('error', function (e) {\n      console.log(\"Socket.IO error: \", e);\n    });\n\n    // Add submit handler to the form\n    messageForm.onsubmit = function (e) {\n      e.preventDefault();\n      const message = messageInput.value;\n      if (message) {\n        const p = document.createElement(\"p\");\n        p.textContent = \"&gt; \" + message;\n        messagesDiv.appendChild(p);\n        socket.emit('message', message);\n        messageInput.value = \"\";\n      }\n      return false;\n    };\n  &lt;/script&gt;\n&lt;/html&gt;\n</code></pre> <p>This HTML file sets up a basic webpage with:</p> <ul> <li>A form (<code>messageForm</code>) with an input field for typing messages and a \"Send\" button.</li> <li>JavaScript that:</li> <li>Connects to the Socket.IO server.</li> <li>Enables the \"Send\" button upon successful connection.</li> <li>Appends received messages from the server to the <code>messages</code> div, handling streaming responses and turn completion.</li> <li>Sends the text entered in the input field to the Socket.IO server when the form is submitted.</li> </ul>"},{"location":"get-started/quickstart-streaming/#6.-interact-with-your-streaming-app-typescript","title":"6. Interact with Your Streaming app","text":"<p>1. Navigate to the Correct Directory:</p> <p>Make sure you are in your project root directory (<code>adk-streaming/</code>)</p> <p>2. Build and Start the Express Server: Run the following commands to build and start the server:</p> <pre><code># Build the TypeScript files\nnpm run build\n\n# Run the server\nnode dist/server.js\n</code></pre> <p>3. Access the UI: Once the UI server starts, the terminal will display a local URL (e.g., http://localhost:8080). Click this link to open the UI in your browser.</p> <p>Try asking a question <code>What is Gemini?</code>. The agent will use Google Search to respond to your queries. You would notice that the UI shows the agent's response as streaming text. You can also send messages to the agent at any time, even while the agent is still responding. This demonstrates the bidirectional communication capability of ADK TypeScript Streaming.</p> <p>Benefits over conventional synchronous web apps:</p> <ul> <li>Real-time two-way communication: Seamless interaction.</li> <li>More responsive and engaging: No need to wait for full responses or constant refreshing. Feels like a live conversation.</li> <li>Can be extended to multimodal apps with audio, image and video streaming support.</li> </ul> <p>Congratulations! You've successfully created and interacted with your first Streaming agent using ADK TypeScript!</p>"},{"location":"get-started/quickstart-streaming/#next-steps","title":"\ud83d\udee3\ufe0f Next steps","text":"<ul> <li>Add Multimodal Capabilities: Modify the agent, server, and client to handle sending/receiving audio or video data using <code>LiveRequestQueue.sendBlob</code> and appropriate browser APIs (e.g., <code>MediaRecorder</code>, <code>getUserMedia</code>). Remember to use an LLM that supports multimodal input.</li> <li>Explore Other Tools: Integrate different ADK tools (like <code>FunctionTool</code>) into your streaming agent.</li> <li>Implement State: Add session state management using <code>ToolContext</code> or <code>outputKey</code> as shown in the Multi-Agent Weather Bot Tutorial.</li> <li>Error Handling: Enhance the error handling on both the server and client sides.</li> </ul>"},{"location":"get-started/quickstart/","title":"Quickstart (ADK TypeScript)","text":"<p>This quickstart guides you through installing the Agent Development Kit (ADK) for TypeScript, setting up a basic agent with multiple tools, and running it locally either in the terminal or in the interactive, browser-based dev UI.</p> <p>This quickstart assumes a local development environment (VS Code, WebStorm, etc.) with Node.js (v18+ recommended), npm, and terminal access. This method runs the application entirely on your machine and is recommended for development and testing.</p>"},{"location":"get-started/quickstart/#1-create-your-project-directory","title":"1. Create your Project Directory","text":"<p>Navigate to the directory where you want to create your project and create a new folder:</p> <pre><code># Create and navigate to a new project directory\nmkdir my-adk-project\ncd my-adk-project\n</code></pre> <p>Note: Use the prefix <code>npx adk</code> when running ADK commands. This ensures you're using the latest version of the CLI without needing a global installation.</p>"},{"location":"get-started/quickstart/#2-create-your-first-agent-project","title":"2. Create Your First Agent Project","text":"<p>The easiest way to get started is by using the <code>adk create</code> command. This will generate a new agent and set up all the necessary project files if they don't already exist.</p> <pre><code># From your project root (e.g., my-adk-project/)\nnpx adk create multi_tool_agent\n</code></pre> <p>Follow the prompts to select a model and provide your API keys. This single command creates a clean, multi-agent-ready project.</p>"},{"location":"get-started/quickstart/#project-structure","title":"Project Structure","text":"<p>The <code>adk create</code> command generates a project structure that is efficient and scalable, allowing multiple agents to share a single set of dependencies.</p> <pre><code>my-adk-project/               # Your parent project folder\n\u251c\u2500\u2500 multi_tool_agent/         # Your agent's code folder\n\u2502   \u251c\u2500\u2500 agent.ts              # Agent definition lives here\n\u2502   \u2514\u2500\u2500 .env                  # API keys for this agent\n\u251c\u2500\u2500 package.json              # SHARED Node.js project manifest\n\u251c\u2500\u2500 tsconfig.json             # SHARED TypeScript configuration\n\u2514\u2500\u2500 dist/                     # (Created after build) Compiled JavaScript output\n</code></pre>"},{"location":"get-started/quickstart/#generated-typescript-configuration-tsconfigjson","title":"Generated TypeScript Configuration (<code>tsconfig.json</code>)","text":"<p>The <code>adk create</code> command generates a <code>tsconfig.json</code> file in your project root with recommended settings. You do not need to create this file yourself.</p> <pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"Node16\",      // Required for proper module resolution\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"moduleResolution\": \"node16\", // Required for subpath imports\n    \"resolveJsonModule\": true,\n    \"declaration\": true      // Optional: generates .d.ts files\n  },\n  \"include\": [\"**/*.ts\"], // Includes all .ts files in the project\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n</code></pre>"},{"location":"get-started/quickstart/#generated-agent-code-agentts","title":"Generated Agent Code (<code>agent.ts</code>)","text":"<p>The command also creates a feature-rich <code>agent.ts</code> file inside your agent's folder (e.g., <code>multi_tool_agent/</code>). It includes two sample tools (<code>getWeather</code> and <code>getCurrentTime</code>) to give you a strong starting point.</p> <pre><code>import { LlmAgent as Agent } from 'adk-typescript/agents';\nimport { LlmRegistry } from 'adk-typescript/models';\nimport { FunctionTool, ToolContext } from 'adk-typescript/tools';\n\n// --- Tool Functions ---\n\n/**\n * Returns current weather information for a specified city\n * @param params Object containing city name\n * @param context Optional ToolContext\n * @returns Promise resolving to weather information or error\n */\nasync function getWeather(\n  params: Record&lt;string, any&gt;,\n  context?: ToolContext\n): Promise&lt;{ status: string; report?: string; error_message?: string }&gt; {\n  const city = params.city;\n  console.log(`--- Tool: getWeather called for city: ${city} ---`);\n  const cityNormalized = city.toLowerCase().trim();\n  const mockWeatherDb: Record&lt;string, { status: string; report: string }&gt; = {\n    \"newyork\": {status: \"success\", report: \"The weather in New York is sunny with a temperature of 25\u00b0C.\"},\n    \"london\": {status: \"success\", report: \"It's cloudy in London with a temperature of 15\u00b0C.\"},\n    \"tokyo\": {status: \"success\", report: \"Tokyo is experiencing light rain and a temperature of 18\u00b0C.\"},\n  };\n  if (mockWeatherDb[cityNormalized]) { return mockWeatherDb[cityNormalized]; }\n  else { return {status: \"error\", error_message: `Sorry, I don't have weather information for '${city}'.`}; }\n}\n\n/**\n * Gets the current local time and timezone.\n * @param params Empty object (no parameters needed)\n * @param context Optional ToolContext\n * @returns Promise resolving to time information\n */\nasync function getCurrentTime(\n  params: Record&lt;string, any&gt;, // Use Record&lt;string, any&gt; for compatibility with ToolFunction\n  context?: ToolContext\n): Promise&lt;{ currentTime: string; timezone: string; }&gt; {\n    console.log(`--- Tool: getCurrentTime called ---`);\n    const now = new Date();\n    return {\n        currentTime: now.toLocaleTimeString(),\n        timezone: Intl.DateTimeFormat().resolvedOptions().timeZone\n    };\n}\n\n// --- Tool Wrappers ---\n\nconst getWeatherTool = new FunctionTool({\n  name: \"getWeather\",\n  description: \"Returns current weather information for a specified city\",\n  fn: getWeather,\n  functionDeclaration: {\n    name: \"getWeather\",\n    description: \"Returns current weather information for a specified city\",\n    parameters: {\n      type: 'object',\n      properties: {\n        city: { type: 'string', description: 'The name of the city (e.g., \"New York\")'}\n      },\n      required: ['city']\n    }\n  }\n});\n\nconst getCurrentTimeTool = new FunctionTool({\n    name: \"getCurrentTime\",\n    description: \"Gets the current local time and timezone.\",\n    fn: getCurrentTime,\n    functionDeclaration: {\n        name: \"getCurrentTime\",\n        description: \"Gets the current local time and timezone.\",\n        parameters: { type: 'object', properties: {} } // No parameters\n    }\n});\n\n\n// --- Agent Definition ---\n\n// Use LlmRegistry to get a model instance\nconst agentLlm = LlmRegistry.newLlm(\"gemini-1.5-flash\"); // Or another compatible model\n\n// Export the root agent for ADK tools to find\nexport const rootAgent = new Agent({\n  name: \"weather_time_agent\", // Unique agent name\n  model: agentLlm,             // LLM instance\n  description: \"Provides current weather and time information for cities.\",\n  instruction: \"You are a helpful assistant. Use the 'getWeather' tool for weather queries \" +\n               \"and the 'getCurrentTime' tool for time queries. Provide clear answers based on tool results. \" +\n               \"If asked for weather AND time, use both tools.\",\n  tools: [getWeatherTool, getCurrentTimeTool], // List of available tools\n});\n</code></pre>"},{"location":"get-started/quickstart/#set-up-the-model-typescript","title":"3. Set up the model","text":"<p>Your agent needs credentials to securely call the LLM service. The <code>npx adk create</code> command prompted you for these and saved them to a <code>.env</code> file located inside your agent's folder (e.g., <code>multi_tool_agent/.env</code>).</p> <p>You can edit this file at any time.</p> Gemini - Google AI StudioGemini - Google Cloud Vertex AI <ol> <li>Get an API key from Google AI Studio.</li> <li> <p>This content will be in your <code>multi_tool_agent/.env</code> file:</p> <pre><code># Use Google AI backend (value 0 or false)\nGOOGLE_GENAI_USE_VERTEXAI=0\n# Your API Key\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE\n</code></pre> </li> </ol> <ol> <li>You need an existing Google Cloud account and project.<ul> <li>Set up a Google Cloud project.</li> <li>Set up the gcloud CLI.</li> <li>Authenticate to Google Cloud for Application Default Credentials (ADC): <code>gcloud auth application-default login</code>.</li> <li>Enable the Vertex AI API.</li> </ul> </li> <li> <p>This content will be in your <code>multi_tool_agent/.env</code> file:</p> .env<pre><code># Use Vertex AI backend (value 1 or true)\nGOOGLE_GENAI_USE_VERTEXAI=1\n# Your Project ID\nYOUR_PROJECT_ID\n# Your Project Location (e.g., us-central1)\nGOOGLE_CLOUD_LOCATION=us-central1\n# GOOGLE_API_KEY is NOT needed when using Vertex AI with ADC\n</code></pre> </li> </ol>"},{"location":"get-started/quickstart/#4-install-compile-and-run-your-agent","title":"4. Install, Compile, and Run Your Agent","text":""},{"location":"get-started/quickstart/#step-1-install-dependencies","title":"Step 1: Install Dependencies","text":"<p>Now that your project files are created, run <code>npm install</code> to download the required packages from your <code>package.json</code>. You only need to do this once.</p> <pre><code># Make sure you are in your project root (my-adk-project/)\nnpm install\n</code></pre>"},{"location":"get-started/quickstart/#step-2-build-your-agent","title":"Step 2: Build Your Agent","text":"<p>Compile your TypeScript code into JavaScript using the pre-configured <code>build</code> script.</p> <pre><code># Make sure you are in your project root (my-adk-project/)\nnpm run build\n</code></pre> <p>Run this command whenever you make changes to your <code>.ts</code> files.</p>"},{"location":"get-started/quickstart/#step-3-run-your-agent","title":"Step 3: Run Your Agent","text":"<p>You can now interact with your agent using the ADK's CLI tools.</p> Dev UI (npx adk web)Terminal (npx adk run) <p>Run the following command to launch the dev UI:</p> <pre><code># Run from the project root (my-adk-project/)\nnpx adk web multi_tool_agent\n</code></pre> <p>Open the URL provided (usually <code>http://localhost:3000</code>) in your browser and start chatting.</p> <p></p> <p>Run the following command to chat with your agent directly in the terminal:</p> <pre><code># Run from the project root (my-adk-project/)\nnpx adk run multi_tool_agent\n</code></pre> <p></p> <p>Type your prompts and press Enter. To exit, use Cmd/Ctrl+C or type \"exit\".</p>"},{"location":"get-started/quickstart/#example-prompts-to-try","title":"\ud83d\udcdd Example prompts to try","text":"<ul> <li>What is the weather in New York?</li> <li>What is the time in New York?</li> <li>What is the weather in Paris?</li> <li>What is the time in Paris?</li> <li>What time is it in London and what's the weather like?</li> </ul>"},{"location":"get-started/quickstart/#congratulations","title":"\ud83c\udf89 Congratulations!","text":"<p>You've successfully created and interacted with your first agent using ADK TypeScript!</p>"},{"location":"get-started/quickstart/#next-steps","title":"\ud83d\udee3\ufe0f Next steps","text":"<ul> <li>Add another agent: Run <code>npx adk create another_agent</code> to add a second agent to your project. Notice how it won't create a new <code>package.json</code>.</li> <li>Go to the tutorial: Learn how to build a multi-agent system, add memory, session state, and safety guardrails: tutorial.</li> <li>Understand Core Concepts: Learn about ADK TypeScript Concepts.</li> </ul>"},{"location":"get-started/testing/","title":"Testing your Agents (ADK TypeScript)","text":"<p>Before you deploy your agent, you should test it to ensure that it is working as intended. The easiest way to test your agent in your development environment is to use the <code>adk api_server</code> command. This command will launch a local Express.js server, where you can run cURL commands or send API requests to test your agent.</p>"},{"location":"get-started/testing/#local-testing","title":"Local testing","text":"<p>Local testing involves launching a local API server, creating a session, and sending queries to your agent.</p> <p>1. Directory Structure</p> <p>Ensure you are in the correct working directory relative to your agent code. The testing commands often expect to be run from the parent directory containing your agent folder(s), or within the agent folder itself if specifying <code>.</code> as the agent directory.</p> <p>A common structure might be:</p> <pre><code>parent_folder/  &lt;-- Run commands from here, specifying '--agent_dir my_sample_agent' or '.'\n|- my_sample_agent/\n  |- src/\n  |  |- agent.ts       &lt;-- Your main agent definition\n  |- .env             &lt;-- Environment variables (optional)\n  |- package.json\n  |- tsconfig.json\n</code></pre> <p>Or, if running commands inside the agent folder:</p> <pre><code>my_sample_agent/ &lt;-- Run commands from here, specifying '--agent_dir .'\n|- src/\n|  |- agent.ts\n|- .env\n|- package.json\n|- tsconfig.json\n</code></pre> <p>2. Launch the Local Server</p> <p>Navigate to your project's root or the appropriate directory and launch the local API server using the ADK TypeScript CLI command. You need to specify the directory containing your agent modules.</p> <pre><code># If run from the parent_folder containing 'my_sample_agent':\nnpx adk api_server --agent_dir my_sample_agent\n\n# Or, if run from inside the 'my_sample_agent' directory:\nnpx adk api_server --agent_dir .\n</code></pre> <p>The output should appear similar to:</p> <pre><code>API server started on port 8000\nAgent directory: /path/to/your/project/parent_folder/my_sample_agent\n</code></pre> <p>Your server is now running locally, typically at <code>http://localhost:8000</code> (the default port can be changed with <code>--port</code>).</p> <p>3. Create a new session</p> <p>With the API server still running, open a new terminal window or tab and create a new session with the agent using <code>curl</code> or a similar tool:</p> <pre><code>curl -X POST http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_123 \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"state\": {\"key1\": \"value1\", \"key2\": 42}}'\n</code></pre> <p>Let's break down what's happening:</p> <ul> <li><code>http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_123</code>: This API endpoint (matching the implementation in <code>apiServer.ts</code>) creates a new session for your agent <code>my_sample_agent</code> (which should match the folder name specified in <code>--agent_dir</code>), for a user ID (<code>u_123</code>) and for a session ID (<code>s_123</code>).</li> <li><code>{\"state\": {\"key1\": \"value1\", \"key2\": 42}}</code>: This optional JSON body sets the initial state for the session. The ADK TypeScript library uses a <code>State</code> class internally, but the API accepts a plain JavaScript object.</li> </ul> <p>This should return the session information if it was created successfully. The output will be a JSON representation of the <code>Session</code> object (see <code>src/sessions/types.ts</code>):</p> <pre><code>{\n  \"id\": \"s_123\",\n  \"appName\": \"my_sample_agent\",\n  \"userId\": \"u_123\",\n  \"state\": {\n    \"key1\": \"value1\",\n    \"key2\": 42\n  },\n  \"events\": []\n}\n</code></pre> <p>Info</p> <p>You cannot create multiple sessions with exactly the same <code>appName</code>, <code>userId</code>, and <code>sessionId</code>. If you try to, the API server (depending on the session service implementation) might return an error like <code>{\"error\":\"Session already exists: s_123\"}</code>. To fix this, you can either delete that session (if the API supports it) or choose a different <code>sessionId</code>.</p> <p>4. Send a query</p> <p>There are two ways to send queries via POST to your agent, via the <code>/run</code> or <code>/run_sse</code> routes, similar to the Python version.</p> <ul> <li><code>POST http://localhost:8000/run</code>: Collects all events generated during the agent's turn and returns them as a JSON array in the response body.</li> <li><code>POST http://localhost:8000/run_sse</code>: Returns a stream of Server-Sent Events (SSE). Each event object is sent as soon as it's generated by the agent. Suitable for real-time updates. With <code>/run_sse</code>, you can also set <code>\"streaming\": true</code> in the request body to enable token-level streaming from the LLM (if the underlying model and flow support it).</li> </ul> <p>Using <code>/run</code></p> <p>Send a POST request with your query:</p> <pre><code>curl -X POST http://localhost:8000/run \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"appName\": \"my_sample_agent\",\n    \"userId\": \"u_123\",\n    \"sessionId\": \"s_123\",\n    \"newMessage\": {\n      \"role\": \"user\",\n      \"parts\": [{\n        \"text\": \"Hey whats the weather in new york today\"\n      }]\n    }\n  }'\n</code></pre> <p>(Note: The keys in the JSON body are <code>appName</code>, <code>userId</code>, <code>sessionId</code>, <code>newMessage</code>)</p> <p>The response will be a JSON array containing all the <code>Event</code> objects generated during that turn. Each event object follows the structure defined in <code>src/events/Event.ts</code>.</p> <pre><code>[\n  {\n    \"invocationId\": \"inv-abcdef12\",\n    \"author\": \"weather_agent_v1\",\n    \"actions\": {\n      \"stateDelta\": {},\n      \"artifactDelta\": {},\n      \"requestedAuthConfigs\": {}\n    },\n    \"id\": \"Evt1AbCd\",\n    \"timestamp\": 1710000100.123,\n    \"content\": {\n      \"role\": \"model\",\n      \"parts\": [\n        {\n          \"functionCall\": {\n            \"name\": \"getWeather\",\n            \"args\": { \"city\": \"new york\" },\n            \"id\": \"adk-uuid-...\"\n          }\n        }\n      ]\n    },\n    \"longRunningToolIds\": []\n  },\n  {\n    \"invocationId\": \"inv-abcdef12\",\n    \"author\": \"weather_agent_v1\",\n    \"actions\": {\n      \"stateDelta\": {},\n      \"artifactDelta\": {},\n      \"requestedAuthConfigs\": {}\n    },\n    \"id\": \"Evt2EfGh\",\n    \"timestamp\": 1710000101.456,\n    \"content\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"functionResponse\": {\n            \"name\": \"getWeather\",\n            \"response\": {\n              \"status\": \"success\",\n              \"report\": \"The weather in New York is sunny with a temperature of 25\u00b0C.\"\n            },\n            \"id\": \"adk-uuid-...\"\n          }\n        }\n      ]\n    }\n  },\n  {\n    \"invocationId\": \"inv-abcdef12\",\n    \"author\": \"weather_agent_v1\",\n    \"actions\": {\n      \"stateDelta\": {\n         \"last_weather_report\": \"The weather in New York is sunny with a temperature of 25\u00b0C.\"\n       },\n      \"artifactDelta\": {},\n      \"requestedAuthConfigs\": {}\n    },\n    \"id\": \"Evt3IjKl\",\n    \"timestamp\": 1710000102.789,\n    \"content\": {\n      \"role\": \"model\",\n      \"parts\": [\n        {\n          \"text\": \"The weather in New York is sunny with a temperature of 25\u00b0C.\"\n        }\n      ]\n    },\n    \"partial\": false,\n    \"turnComplete\": false\n  }\n]\n</code></pre> <p>Using <code>/run_sse</code></p> <pre><code>curl -X POST http://localhost:8000/run_sse \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"appName\": \"my_sample_agent\",\n    \"userId\": \"u_123\",\n    \"sessionId\": \"s_123\",\n    \"newMessage\": {\n      \"role\": \"user\",\n      \"parts\": [{\n        \"text\": \"Hey whats the weather in new york today\"\n      }]\n    },\n    \"streaming\": false\n  }'\n</code></pre> <p>You can set <code>\"streaming\": true</code> to attempt token-level streaming from the LLM. The output will be a stream of Server-Sent Events:</p> <pre><code>data: {\"invocationId\":\"inv-abcdef12\",\"author\":\"weather_agent_v1\", ... ,\"content\":{\"role\":\"model\",\"parts\":[{\"functionCall\":{...}}]}}\n\ndata: {\"invocationId\":\"inv-abcdef12\",\"author\":\"weather_agent_v1\", ... ,\"content\":{\"role\":\"user\",\"parts\":[{\"functionResponse\":{...}}]}}\n\ndata: {\"invocationId\":\"inv-abcdef12\",\"author\":\"weather_agent_v1\", ... ,\"content\":{\"role\":\"model\",\"parts\":[{\"text\":\"The weather in New York is sunny with a temperature of 25\u00b0C.\"}]}}\n</code></pre> <p>Info</p> <p>With <code>/run_sse</code>, each <code>data:</code> line represents a complete JSON <code>Event</code> object sent as soon as it's available from the agent. If token streaming (<code>\"streaming\": true</code>) is enabled, you might receive multiple events with <code>partial: true</code> for text content before the final non-partial text event.</p>"},{"location":"get-started/testing/#integrations","title":"Integrations","text":"<p>ADK TypeScript utilizes Callbacks (like <code>beforeModelCallback</code>, <code>afterModelCallback</code>, <code>beforeToolCallback</code>, <code>afterToolCallback</code>) to hook into the agent execution lifecycle. The library also includes basic OpenTelemetry tracing capabilities (see <code>src/telemetry.ts</code>).</p> <p>These mechanisms allow integration with third-party observability tools. While specific integrations like Comet Opik aren't explicitly built into this codebase version, the callback and tracing foundation enables you to capture detailed traces of agent calls and interactions for understanding behavior, debugging, and evaluation. You can implement custom callbacks to send data to your preferred observability platform.</p>"},{"location":"get-started/testing/#deploying-your-agent","title":"Deploying your agent","text":"<p>Now that you've verified the local operation of your agent, you're ready to move on to deploying your agent! Here are some ways you can deploy your ADK TypeScript agent:</p> <ul> <li>Deploy to Agent Engine on Vertex AI (if compatible): Check the official Agent Engine documentation for compatibility with custom ADK TypeScript agents.</li> <li>Deploy to Cloud Run: Use the <code>adk deploy cloud_run</code> command (see <code>src/cli/cliDeploy.ts</code>) to containerize and deploy your agent as a serverless application on Google Cloud, giving you full control over scaling and management.</li> </ul>"},{"location":"runtime/","title":"Runtime","text":""},{"location":"runtime/#what-is-runtime","title":"What is runtime?","text":"<p>The ADK Runtime is the underlying engine that powers your agent application during user interactions. It's the system that takes your defined agents, tools, and callbacks and orchestrates their execution in response to user input, managing the flow of information, state changes, and interactions with external services like LLMs or storage.</p> <p>Think of the Runtime as the \"engine\" of your agentic application. You define the parts (agents, tools), and the Runtime handles how they connect and run together to fulfill a user's request.</p>"},{"location":"runtime/#core-idea-the-event-loop","title":"Core Idea: The Event Loop","text":"<p>At its heart, the ADK Runtime operates on an Event Loop. This loop facilitates a back-and-forth communication between the <code>Runner</code> component and your defined \"Execution Logic\" (which includes your Agents, the LLM calls they make, Callbacks, and Tools).</p> <p></p> <p>In simple terms:</p> <ol> <li>The <code>Runner</code> receives a user query and asks the main <code>Agent</code> to start processing.</li> <li>The <code>Agent</code> (and its associated logic) runs until it has something to report (like a response, a request to use a tool, or a state change) \u2013 it then returns an <code>Event</code> as part of an async generator.</li> <li>The <code>Runner</code> receives this <code>Event</code>, processes any associated actions (like saving state changes via <code>Services</code>), and forwards the event onwards (e.g., to the user interface).</li> <li>Only after the <code>Runner</code> has processed the event does the <code>Agent</code>'s logic continue from where it was, now potentially seeing the effects of the changes committed by the Runner.</li> <li>This cycle repeats until the agent has no more events to yield for the current user query.</li> </ol> <p>This event-driven loop is the fundamental pattern governing how ADK executes your agent code.</p>"},{"location":"runtime/#the-heartbeat-the-event-loop-inner-workings","title":"The Heartbeat: The Event Loop - Inner workings","text":"<p>The Event Loop is the core operational pattern defining the interaction between the <code>Runner</code> and your custom code (Agents, Tools, Callbacks, collectively referred to as \"Execution Logic\" or \"Logic Components\"). It establishes a clear division of responsibilities:</p>"},{"location":"runtime/#runners-role-orchestrator","title":"Runner's Role (Orchestrator)","text":"<p>The <code>Runner</code> acts as the central coordinator for a single user invocation. Its responsibilities in the loop are:</p> <ol> <li>Initiation: Receives the end user's query (<code>newMessage</code>) and typically appends it to the session history via the <code>SessionService</code>.</li> <li>Kick-off: Starts the event generation process by calling the main agent's execution method (e.g., <code>agent.invoke(invocationContext)</code>).</li> <li>Receive &amp; Process: Waits for the agent logic to return an <code>Event</code> from its async generator. Upon receiving an event, the Runner promptly processes it. This involves:<ul> <li>Using configured <code>Services</code> (<code>SessionService</code>, <code>ArtifactService</code>, <code>MemoryService</code>) to commit changes indicated in <code>event.actions</code> (like <code>stateDelta</code>, <code>artifactDelta</code>).</li> <li>Performing other internal bookkeeping.</li> </ul> </li> <li>Yield Upstream: Forwards the processed event onwards (e.g., to the calling application or UI for rendering).</li> <li>Iterate: Signals the agent logic that processing is complete for the current event, allowing it to continue and generate the next event.</li> </ol> <p>Conceptual Runner Loop:</p> <pre><code>// Simplified view of Runner's main runAsync method\nasync *runAsync(params: {\n  userId: string;\n  sessionId: string;\n  newMessage: Content;\n}): AsyncGenerator&lt;Event, void, unknown&gt; {\n  // 1. Get session and append new message to session event history (via SessionService)\n  const session = await this.sessionService.getSession({\n    appName: this.appName,\n    userId: params.userId,\n    sessionId: params.sessionId\n  });\n\n  // Add user message as an event\n  await this._appendNewMessageToSession({\n    session,\n    newMessage: params.newMessage,\n    invocationContext\n  });\n\n  // 2. Kick off event loop by creating an invocation context and calling the agent\n  const invocationContext = this._newInvocationContext({...});\n  invocationContext.agent = this._findAgentToRun(session, this.agent);\n\n  // 3-5. Process events from the agent generator\n  for await (const event of invocationContext.agent.invoke(invocationContext)) {\n    // Process non-partial events (commit state/artifact changes)\n    if (!event.partial) {\n      await this.sessionService.appendEvent({\n        session,\n        event\n      });\n    }\n\n    // 4. Yield event for upstream processing (e.g., UI rendering)\n    yield event;\n    // Runner implicitly signals agent generator can continue after yielding\n  }\n}\n</code></pre>"},{"location":"runtime/#execution-logics-role-agent-tool-callback","title":"Execution Logic's Role (Agent, Tool, Callback)","text":"<p>Your code within agents, tools, and callbacks is responsible for the actual computation and decision-making. Its interaction with the loop involves:</p> <ol> <li>Execute: Runs its logic based on the current <code>InvocationContext</code>, including the session state as it was when execution started or resumed.</li> <li>Yield: When the logic needs to communicate (send a message, call a tool, report a state change), it constructs an <code>Event</code> containing the relevant content and actions, and then returns this event as part of the async generator.</li> <li>Pause: Execution of the agent logic pauses after the <code>yield</code> statement within the async generator. It waits for the <code>Runner</code> to process the event.</li> <li>Resume: Only after the <code>Runner</code> has processed the yielded event does the agent logic resume execution from the statement immediately following the <code>yield</code>.</li> <li>See Updated State: Upon resumption, the agent logic can now reliably access the session state (<code>ctx.session.state</code>) reflecting the changes that were committed by the <code>Runner</code> from the previously yielded event.</li> </ol> <p>Conceptual Execution Logic:</p> <pre><code>// Simplified view of logic inside Agent.invoke\nasync *invoke(ctx: InvocationContext): AsyncGenerator&lt;Event, void, unknown&gt; {\n  // ... previous code runs based on current state ...\n\n  // 1. Determine a change or output is needed, construct the event\n  // Example: Updating state\n  const updateData = { 'field_1': 'value_2' };\n  const eventWithStateChange: Event = {\n    author: this.name,\n    invocationId: ctx.invocationId,\n    content: {\n      role: 'assistant',\n      parts: [{ text: 'State updated.' }]\n    },\n    actions: {\n      stateDelta: updateData\n    }\n    // ... other event fields ...\n  };\n\n  // 2. Yield the event to the Runner for processing &amp; commit\n  yield eventWithStateChange;\n  // &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; EXECUTION PAUSES HERE UNTIL THE NEXT ITERATION &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n\n  // &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; RUNNER PROCESSES &amp; COMMITS THE EVENT &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n\n  // 3. Resume execution ONLY after Runner processes the above event\n  // Now, the state committed by the Runner is reliably reflected\n  // Subsequent code can safely assume the change from the yielded event happened\n  const val = ctx.session.state['field_1'];\n  // here `val` is guaranteed to be \"value_2\" (assuming Runner committed successfully)\n  console.log(`Resumed execution. Value of field_1 is now: ${val}`);\n\n  // ... subsequent code continues ...\n  // Maybe yield another event later...\n}\n</code></pre> <p>This cooperative async generator pattern between the <code>Runner</code> and your Execution Logic, mediated by <code>Event</code> objects, forms the core of the ADK Runtime.</p>"},{"location":"runtime/#key-components-of-the-runtime","title":"Key components of the Runtime","text":"<p>Several components work together within the ADK Runtime to execute an agent invocation. Understanding their roles clarifies how the event loop functions:</p> <p>These players interact continuously through the Event Loop to process a user's request.</p>"},{"location":"runtime/#runner","title":"<code>Runner</code>","text":"<ul> <li>Role: The main entry point and orchestrator for a single user query (<code>runAsync</code>).</li> <li>Function: Manages the overall Event Loop, receives events yielded by the Execution Logic, coordinates with Services to process and commit event actions (state/artifact changes), and forwards processed events upstream (e.g., to the UI). It essentially drives the conversation turn by turn based on generated events. (Defined in <code>runners.ts</code>).</li> </ul>"},{"location":"runtime/#execution-logic-components","title":"Execution Logic Components","text":"<ul> <li>Role: The parts containing your custom code and the core agent capabilities.</li> <li>Components:</li> <li><code>Agent</code> (<code>BaseAgent</code>, <code>LlmAgent</code>, etc.): Your primary logic units that process information and decide on actions. They implement the <code>invoke</code> method which yields events.</li> <li><code>Tools</code> (<code>BaseTool</code>, <code>FunctionTool</code>, etc.): External functions or capabilities used by agents (often <code>LlmAgent</code>) to interact with the outside world or perform specific tasks. They execute and return results, which are then wrapped in events.</li> <li><code>Callbacks</code> (Functions): User-defined functions attached to agents (e.g., callbacks) that hook into specific points in the execution flow, potentially modifying behavior or state, whose effects are captured in events.</li> <li>Function: Perform the actual thinking, calculation, or external interaction. They communicate their results or needs by yielding <code>Event</code> objects via async generators.</li> </ul>"},{"location":"runtime/#event","title":"<code>Event</code>","text":"<ul> <li>Role: The message passed back and forth between the <code>Runner</code> and the Execution Logic.</li> <li>Function: Represents an atomic occurrence (user input, agent text, tool call/result, state change request, control signal). It carries both the content of the occurrence and the intended side effects (<code>actions</code> like <code>stateDelta</code>). (Defined in <code>events/Event.ts</code>).</li> </ul>"},{"location":"runtime/#services","title":"<code>Services</code>","text":"<ul> <li>Role: Backend components responsible for managing persistent or shared resources. Used primarily by the <code>Runner</code> during event processing.</li> <li>Components:</li> <li><code>SessionService</code> (<code>BaseSessionService</code>, <code>InMemorySessionService</code>, etc.): Manages <code>Session</code> objects, including saving/loading them, applying <code>stateDelta</code> to the session state, and appending events to the <code>event history</code>.</li> <li><code>ArtifactService</code> (<code>BaseArtifactService</code>, <code>InMemoryArtifactService</code>, etc.): Manages the storage and retrieval of binary artifact data. Although <code>saveArtifact</code> is called via context during execution logic, the <code>artifactDelta</code> in the event confirms the action for the Runner/SessionService.</li> <li><code>MemoryService</code> (<code>BaseMemoryService</code>, etc.): (Optional) Manages long-term semantic memory across sessions for a user.</li> <li>Function: Provide the persistence layer. The <code>Runner</code> interacts with them to ensure changes signaled by <code>event.actions</code> are reliably stored before the Execution Logic resumes.</li> </ul>"},{"location":"runtime/#session","title":"<code>Session</code>","text":"<ul> <li>Role: A data container holding the state and history for one specific conversation between a user and the application.</li> <li>Function: Stores the current <code>state</code> record, the list of all past <code>events</code> (<code>event history</code>), and references to associated artifacts. It's the primary record of the interaction, managed by the <code>SessionService</code>. (Defined in <code>sessions/Session.ts</code>).</li> </ul>"},{"location":"runtime/#invocation","title":"<code>Invocation</code>","text":"<ul> <li>Role: A conceptual term representing everything that happens in response to a single user query, from the moment the <code>Runner</code> receives it until the agent logic finishes yielding events for that query.</li> <li>Function: An invocation might involve multiple agent runs (if using agent transfer or agent tools), multiple LLM calls, tool executions, and callback executions, all tied together by a single <code>invocationId</code> within the <code>InvocationContext</code>.</li> </ul>"},{"location":"runtime/#how-it-works-a-simplified-invocation","title":"How It Works: A Simplified Invocation","text":"<p>Let's trace a simplified flow for a typical user query that involves an LLM agent calling a tool:</p> <p></p>"},{"location":"runtime/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":"<ol> <li>User Input: The User sends a query (e.g., \"What's the capital of France?\").</li> <li>Runner Starts: <code>Runner.runAsync</code> begins. It interacts with the <code>SessionService</code> to load the relevant <code>Session</code> and adds the user query as the first <code>Event</code> to the session history. An <code>InvocationContext</code> (<code>ctx</code>) is prepared.</li> <li>Agent Execution: The <code>Runner</code> calls <code>agent.invoke(ctx)</code> on the designated root agent (e.g., an <code>LlmAgent</code>).</li> <li>LLM Call (Example): The <code>Agent_Llm</code> determines it needs information, perhaps by calling a tool. It prepares a request for the <code>LLM</code>. Let's assume the LLM decides to call <code>MyTool</code>.</li> <li>Yield FunctionCall Event: The <code>Agent_Llm</code> receives the <code>functionCall</code> response from the LLM, wraps it in an <code>Event</code> with appropriate content, and <code>yield</code>s this event.</li> <li>Agent Pauses: The <code>Agent_Llm</code>'s execution pauses after the <code>yield</code> statement (in the async generator).</li> <li>Runner Processes: The <code>Runner</code> receives the FunctionCall event. It passes it to the <code>SessionService</code> to record it in the history. The <code>Runner</code> then yields the event upstream to the <code>User</code> (or application).</li> <li>Agent Resumes: The <code>Runner</code> signals that the event is processed by continuing with the async generator iteration, and <code>Agent_Llm</code> resumes execution.</li> <li>Tool Execution: The <code>Agent_Llm</code>'s internal flow now proceeds to execute the requested <code>MyTool</code>.</li> <li>Tool Returns Result: <code>MyTool</code> executes and returns its result (e.g., <code>{ result: 'Paris' }</code>).</li> <li>Yield FunctionResponse Event: The agent (<code>Agent_Llm</code>) wraps the tool result into an <code>Event</code> containing a function response. This event might also contain <code>actions</code> if the tool modified state (<code>stateDelta</code>) or saved artifacts (<code>artifactDelta</code>). The agent <code>yield</code>s this event.</li> <li>Agent Pauses: <code>Agent_Llm</code> pauses again.</li> <li>Runner Processes: <code>Runner</code> receives the FunctionResponse event. It passes it to <code>SessionService</code> which applies any <code>stateDelta</code>/<code>artifactDelta</code> and adds the event to history. <code>Runner</code> yields the event upstream.</li> <li>Agent Resumes: <code>Agent_Llm</code> resumes, now knowing the tool result and any state changes are committed.</li> <li>Final LLM Call (Example): <code>Agent_Llm</code> sends the tool result back to the <code>LLM</code> to generate a natural language response.</li> <li>Yield Final Text Event: <code>Agent_Llm</code> receives the final text from the <code>LLM</code>, wraps it in an <code>Event</code> with text content, and <code>yield</code>s it.</li> <li>Agent Pauses: <code>Agent_Llm</code> pauses.</li> <li>Runner Processes: <code>Runner</code> receives the final text event, passes it to <code>SessionService</code> for history, and yields it upstream to the <code>User</code>. This is likely marked as <code>turnComplete: true</code>.</li> <li>Agent Resumes &amp; Finishes: <code>Agent_Llm</code> resumes. Having completed its task for this invocation, its async generator finishes.</li> <li>Runner Completes: The <code>Runner</code> sees the agent's generator is exhausted and finishes its loop for this invocation.</li> </ol> <p>This async generator pattern ensures that state changes are consistently applied and that the execution logic always operates on the most recently committed state after yielding an event.</p>"},{"location":"runtime/#important-runtime-behaviors","title":"Important Runtime Behaviors","text":"<p>Understanding a few key aspects of how the ADK Runtime handles state, streaming, and asynchronous operations is crucial for building predictable and efficient agents.</p>"},{"location":"runtime/#state-updates-commitment-timing","title":"State Updates &amp; Commitment Timing","text":"<ul> <li> <p>The Rule: When your code (in an agent, tool, or callback) modifies the session state (e.g., <code>context.session.state['my_key'] = 'new_value'</code>), this change is initially recorded locally within the current <code>InvocationContext</code>. The change is only guaranteed to be persisted (saved by the <code>SessionService</code>) after the <code>Event</code> carrying the corresponding <code>stateDelta</code> in its <code>actions</code> has been yielded by your code and subsequently processed by the <code>Runner</code>.</p> </li> <li> <p>Implication: Code that runs after resuming from the next iteration of the async generator can reliably assume that the state changes signaled in the previously yielded event have been committed.</p> </li> </ul> <pre><code>// Inside agent logic (conceptual)\n\n// 1. Modify state\nctx.session.state['status'] = 'processing';\nconst event1: Event = {\n  author: this.name,\n  invocationId: ctx.invocationId,\n  actions: { stateDelta: { 'status': 'processing' } },\n  // Other event properties...\n};\n\n// 2. Yield event with the delta\nyield event1;\n// --- PAUSE --- Runner processes event1, SessionService commits 'status' = 'processing' ---\n\n// 3. Resume execution on next iterator iteration\n// Now it's safe to rely on the committed state\nconst currentStatus = ctx.session.state['status']; // Guaranteed to be 'processing'\nconsole.log(`Status after resuming: ${currentStatus}`);\n</code></pre>"},{"location":"runtime/#dirty-reads-of-session-state","title":"\"Dirty Reads\" of Session State","text":"<ul> <li>Definition: While commitment happens after the event is processed, code running later within the same invocation, but before the state-changing event is actually yielded and processed, can often see the local, uncommitted changes. This is sometimes called a \"dirty read\".</li> <li>Example:</li> </ul> <pre><code>// Code in beforeAgentCallback\ncallbackContext.session.state['field_1'] = 'value_1';\n// State is locally set to 'value_1', but not yet committed by Runner\n\n// ... agent runs ...\n\n// Code in a tool called later *within the same invocation*\n// Readable (dirty read), but 'value_1' isn't guaranteed persistent yet\nconst val = toolContext.session.state['field_1']; // 'val' will likely be 'value_1' here\nconsole.log(`Dirty read value in tool: ${val}`);\n\n// Assume the event carrying the stateDelta={'field_1': 'value_1'}\n// is yielded *after* this tool runs and is processed by the Runner\n</code></pre> <ul> <li>Implications:</li> <li>Benefit: Allows different parts of your logic within a single complex step (e.g., multiple callbacks or tool calls before the next LLM turn) to coordinate using state without waiting for a full yield/commit cycle.</li> <li>Caveat: Relying heavily on dirty reads for critical logic can be risky. If the invocation fails before the event carrying the <code>stateDelta</code> is yielded and processed by the <code>Runner</code>, the uncommitted state change will be lost. For critical state transitions, ensure they are associated with an event that gets successfully processed.</li> </ul>"},{"location":"runtime/#streaming-vs-non-streaming-output-partialtrue","title":"Streaming vs. Non-Streaming Output (<code>partial=true</code>)","text":"<p>This primarily relates to how responses from the LLM are handled, especially when using streaming generation APIs.</p> <ul> <li>Streaming: The LLM generates its response token-by-token or in small chunks.</li> <li>The framework (often within LLM handling code) yields multiple <code>Event</code> objects for a single conceptual response. Most of these events will have <code>partial=true</code>.</li> <li>The <code>Runner</code>, upon receiving an event with <code>partial=true</code>, typically forwards it immediately upstream (for UI display) but skips processing its <code>actions</code> (like <code>stateDelta</code>).</li> <li>Eventually, the framework yields a final event for that response, marked as non-partial (<code>partial=false</code> or implicitly via <code>turnComplete=true</code>).</li> <li>The <code>Runner</code> fully processes only this final event, committing any associated <code>stateDelta</code> or <code>artifactDelta</code>.</li> <li>Non-Streaming: The LLM generates the entire response at once. The framework yields a single event marked as non-partial, which the <code>Runner</code> processes fully.</li> <li>Why it Matters: Ensures that state changes are applied atomically and only once based on the complete response from the LLM, while still allowing the UI to display text progressively as it's generated.</li> </ul>"},{"location":"runtime/#async-is-primary-runasync","title":"Async is Primary (<code>runAsync</code>)","text":"<ul> <li>Core Design: The ADK Runtime is fundamentally built on TypeScript's asynchronous capabilities using Promises and AsyncGenerators to handle concurrent operations (like waiting for LLM responses or tool executions) efficiently without blocking.</li> <li>Main Entry Point: <code>Runner.runAsync</code> is the primary method for executing agent invocations. All core runnable components (Agents, specific flows) use <code>async</code> functions and generators internally.</li> <li>Synchronous Convenience (<code>run</code>): While <code>run</code> exists, in TypeScript it's also asynchronous and mainly serves as a wrapper around <code>runAsync</code>.</li> <li>Developer Experience: You should generally design your application logic (e.g., web servers using ADK) using async/await patterns.</li> <li>Sync/Async Callbacks/Tools: The framework can handle both async and sync functions provided as tools or callbacks. Long-running synchronous tools or callbacks, especially those performing blocking I/O, should be avoided as they can block the entire event loop. Always prefer async implementations when possible.</li> </ul> <p>Understanding these behaviors helps you write more robust ADK applications and debug issues related to state consistency, streaming updates, and asynchronous execution.</p>"},{"location":"sessions/","title":"Introduction to Conversational Context: Session, State, and Memory","text":""},{"location":"sessions/#why-context-matters","title":"Why Context Matters","text":"<p>Meaningful, multi-turn conversations require agents to understand context. Just like humans, they need to recall what's been said and done to maintain continuity and avoid repetition. The Agent Development Kit (ADK) provides structured ways to manage this context through <code>Session</code>, <code>State</code>, and <code>Memory</code>.</p>"},{"location":"sessions/#core-concepts","title":"Core Concepts","text":"<p>Think of interacting with your agent as having distinct conversation threads, potentially drawing upon long-term knowledge.</p> <ol> <li> <p><code>Session</code>: The Current Conversation Thread  </p> <ul> <li>Represents a single, ongoing interaction between a user and your agent system.  </li> <li>Contains the chronological sequence of messages and actions (<code>Events</code>) for that specific interaction.  </li> <li>A <code>Session</code> can also hold temporary data (<code>State</code>) relevant only during this conversation.</li> </ul> </li> <li> <p><code>State</code> (<code>session.state</code>): Data Within the Current Conversation  </p> <ul> <li>Data stored within a specific <code>Session</code>.  </li> <li>Used to manage information relevant only to the current, active conversation thread (e.g., items in a shopping cart during this chat, user preferences mentioned in this session).</li> </ul> </li> <li> <p><code>Memory</code>: Searchable, Cross-Session Information  </p> <ul> <li>Represents a store of information that might span multiple past sessions or include external data sources.  </li> <li>It acts as a knowledge base the agent can search to recall information or context beyond the immediate conversation.</li> </ul> </li> </ol>"},{"location":"sessions/#managing-context-services","title":"Managing Context: Services","text":"<p>ADK provides services to manage these concepts:</p> <ol> <li> <p><code>SessionService</code>: Manages Conversation Threads (<code>Session</code> objects)  </p> <ul> <li>Handles the lifecycle: creating, retrieving, updating (appending <code>Events</code>, modifying <code>State</code>), and deleting individual <code>Session</code> threads.  </li> <li>Ensures the agent has the right history and state for the current turn.</li> </ul> </li> <li> <p><code>MemoryService</code>: Manages the Long-Term Knowledge Store (<code>Memory</code>)  </p> <ul> <li>Handles ingesting information (often from completed <code>Session</code>s) into the long-term store.  </li> <li>Provides methods to search this stored knowledge based on queries.</li> <li>Offers key-value storage capabilities for app/user-specific data.</li> </ul> </li> </ol> <p>Implementations: ADK offers different implementations for both <code>SessionService</code> and <code>MemoryService</code>, allowing you to choose the storage backend that best fits your application's needs:</p> <ol> <li>In-memory implementations (<code>InMemorySessionService</code> and <code>InMemoryMemoryService</code>) are provided for quick testing and development.</li> <li> <p>Important: All data stored using these in-memory options is lost when your application restarts.</p> </li> <li> <p>Persistent implementations:</p> </li> <li><code>DatabaseSessionService</code>: Uses SQLite or other database engines for persistent session storage.</li> <li><code>VertexAiSessionService</code>: Leverages Google Cloud for scalable, managed session storage.</li> <li><code>VertexAiRagMemoryService</code>: Uses Google Cloud's RAG capabilities for semantic long-term memory.</li> </ol> <p>In Summary:</p> <ul> <li><code>Session</code> &amp; <code>State</code>: Focus on the here and now \u2013 the history and temporary data of the single, active conversation. Managed primarily by <code>SessionService</code>.  </li> <li>Memory: Focuses on the past and external information \u2013 a searchable archive potentially spanning across conversations. Managed by <code>MemoryService</code>.</li> </ul>"},{"location":"sessions/#whats-next","title":"What's Next?","text":"<p>In the following sections, we'll dive deeper into each of these components:</p> <ul> <li><code>Session</code>: Understanding its structure and <code>Events</code>.  </li> <li><code>State</code>: How to effectively read, write, and manage session-specific data.  </li> <li><code>SessionService</code>: Choosing the right storage backend for your sessions.  </li> <li><code>MemoryService</code>: Exploring options for storing and retrieving broader context.</li> </ul> <p>Understanding these concepts is fundamental to building agents that can engage in complex, stateful, and context-aware conversations.</p>"},{"location":"sessions/memory/","title":"Memory: Long-Term Knowledge with <code>MemoryService</code>","text":"<p>We've seen how <code>Session</code> tracks the history (<code>events</code>) and temporary data (<code>state</code>) for a single, ongoing conversation. But what if an agent needs to recall information from past conversations or access external knowledge bases? This is where the concept of Long-Term Knowledge and the <code>MemoryService</code> come into play.</p> <p>Think of it this way:</p> <ul> <li><code>Session</code> / <code>State</code>: Like your short-term memory during one specific chat.  </li> <li>Long-Term Knowledge (<code>MemoryService</code>): Like a searchable archive or knowledge library the agent can consult, potentially containing information from many past chats or other sources.</li> </ul>"},{"location":"sessions/memory/#the-memoryservice-role","title":"The <code>MemoryService</code> Role","text":"<p>The <code>BaseMemoryService</code> defines the interface for managing this searchable, long-term knowledge store. Its primary responsibilities are:</p> <ol> <li>Ingesting Information (<code>addSessionToMemory</code>): Taking the contents of a (usually completed) <code>Session</code> and adding relevant information to the long-term knowledge store.  </li> <li>Searching Information (<code>searchMemory</code>): Allowing an agent (typically via a <code>Tool</code>) to query the knowledge store and retrieve relevant snippets or context based on a search query.</li> <li>Key-Value Store (<code>store/retrieve/delete</code>): Providing simple persistent storage for arbitrary data associated with app/user pairs.</li> </ol>"},{"location":"sessions/memory/#memoryservice-implementations","title":"<code>MemoryService</code> Implementations","text":"<p>ADK provides different ways to implement this long-term knowledge store:</p> <ol> <li> <p><code>InMemoryMemoryService</code> </p> <ul> <li>How it works: Stores session information in the application's memory and performs basic keyword matching for searches.  </li> <li>Persistence: None. All stored knowledge is lost if the application restarts. </li> <li>Requires: Nothing extra.  </li> <li>Best for: Prototyping, simple testing, scenarios where only basic keyword recall is needed and persistence isn't required.</li> </ul> <pre><code>import { InMemoryMemoryService } from 'adk-typescript/memory';\nconst memoryService = new InMemoryMemoryService();\n</code></pre> </li> <li> <p><code>VertexAiRagMemoryService</code> </p> <ul> <li>How it works: Leverages Google Cloud's Vertex AI RAG (Retrieval-Augmented Generation) service. It ingests session data into a specified RAG Corpus and uses powerful semantic search capabilities for retrieval.  </li> <li>Persistence: Yes. The knowledge is stored persistently within the configured Vertex AI RAG Corpus.  </li> <li>Requires: A Google Cloud project, appropriate permissions, necessary SDKs, and a pre-configured Vertex AI RAG Corpus resource name/ID.  </li> <li>Best for: Production applications needing scalable, persistent, and semantically relevant knowledge retrieval, especially when deployed on Google Cloud.</li> </ul> <pre><code>import { VertexAiRagMemoryService } from 'adk-typescript/memory';\n\n// Configure the RAG memory service\nconst memoryService = new VertexAiRagMemoryService({\n  project: \"your-gcp-project-id\",\n  location: \"us-central1\",\n  ragCorpus: \"your-rag-corpus-id\",\n  // Optional parameters\n  similarityTopK: 5, // Limit search results to top 5 matches\n  vectorDistanceThreshold: 0.8 // Only return results with similarity above this threshold\n});\n</code></pre> <p>Note: To use this service, you'll need to install the required dependencies:</p> <pre><code>npm install @google-cloud/vertexai google-auth-library axios form-data\n</code></pre> <p>This implementation uses the Vertex AI RAG API to store conversation content in a RAG corpus and perform semantic searches. The RAG corpus must be pre-created in your Google Cloud project.</p> </li> </ol>"},{"location":"sessions/memory/#how-memory-works-in-practice","title":"How Memory Works in Practice","text":"<p>The typical workflow involves these steps:</p> <ol> <li>Session Interaction: A user interacts with an agent via a <code>Session</code>, managed by a <code>SessionService</code>. Events are added, and state might be updated.  </li> <li>Ingestion into Memory: At some point (often when a session is considered complete or has yielded significant information), your application calls <code>memoryService.addSessionToMemory(session)</code>. This extracts relevant information from the session's events and adds it to the long-term knowledge store (in-memory dictionary or RAG Corpus).  </li> <li>Later Query: In a different (or the same) session, the user might ask a question requiring past context (e.g., \"What did we discuss about project X last week?\").  </li> <li>Agent Uses Memory Tool: An agent equipped with a memory-retrieval tool (like the built-in <code>loadMemory</code> tool) recognizes the need for past context. It calls the tool, providing a search query (e.g., \"discussion project X last week\").  </li> <li>Search Execution: The tool internally calls <code>memoryService.searchMemory(appName, userId, query)</code>.  </li> <li>Results Returned: The <code>MemoryService</code> searches its store (using keyword matching or semantic search) and returns relevant snippets as a <code>SearchMemoryResponse</code> containing a list of <code>MemoryResult</code> objects (each potentially holding events from a relevant past session).  </li> <li>Agent Uses Results: The tool returns these results to the agent, usually as part of the context or function response. The agent can then use this retrieved information to formulate its final answer to the user.</li> </ol>"},{"location":"sessions/memory/#example-adding-and-searching-memory","title":"Example: Adding and Searching Memory","text":"<p>This example demonstrates the basic flow using the <code>InMemory</code> services for simplicity.</p> <pre><code>import { InMemorySessionService, SessionInterface } from 'adk-typescript/sessions';\nimport { InMemoryMemoryService } from 'adk-typescript/memory';\nimport { Session } from 'adk-typescript/sessions';\nimport { Content, Part } from 'adk-typescript/sessions';\nimport { loadMemoryTool } from 'adk-typescript/tools';\nimport { runners } from 'adk-typescript';\nimport { LlmAgent } from 'adk-typescript/agents';\n\n// --- Constants ---\nconst APP_NAME = \"memory_example_app\";\nconst USER_ID = \"mem_user\";\nconst MODEL = \"gemini-pro\"; // Use an appropriate model\n\n// --- Initialize Services ---\nconst sessionService = new InMemorySessionService();\nconst memoryService = new InMemoryMemoryService();\n\n// --- Agent 1: Simple agent to capture information ---\nconst infoCaptureAgent = new LlmAgent({\n  model: MODEL,\n  name: \"InfoCaptureAgent\",\n  instruction: \"Acknowledge the user's statement.\"\n});\n\n// --- Agent 2: Agent that can use memory ---\nconst memoryRecallAgent = new LlmAgent({\n  model: MODEL,\n  name: \"MemoryRecallAgent\",\n  instruction: \"Answer the user's question. Use the 'load_memory' tool if the answer might be in past conversations.\",\n  tools: [loadMemoryTool] // Give the agent the ability to load memory\n});\n\n// --- Create a runner ---\nconst runner = new runners.Runner({\n  agent: infoCaptureAgent, // Start with info capture agent\n  appName: APP_NAME,\n  sessionService: sessionService,\n  memoryService: memoryService // Provide memory service to the runner\n});\n\n// --- SCENARIO: First capture information, then recall it ---\n\nasync function runScenario() {\n  // --- Turn 1: Capture some information in a session ---\n  console.log(\"--- Turn 1: Capturing Information ---\");\n  const SESSION1_ID = \"session_info\";\n\n  // Create session and prepare user message\n  const session1 = sessionService.createSession({\n    appName: APP_NAME, \n    userId: USER_ID, \n    sessionId: SESSION1_ID\n  });\n\n  // User's message\n  const userMessage1: Content = {\n    role: \"user\",\n    parts: [{ text: \"My favorite project is Project Alpha.\" }]\n  };\n\n  // Process the user message with the info capture agent\n  let finalResponseText1 = \"\";\n  for await (const event of runner.run({\n    userId: USER_ID,\n    sessionId: SESSION1_ID,\n    newMessage: userMessage1\n  })) {\n    if (event.turnComplete &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts.length &gt; 0) {\n      finalResponseText1 = event.content.parts[0].text || \"\";\n    }\n  }\n  console.log(`Agent 1 Response: ${finalResponseText1}`);\n\n  // Get the completed session\n  const completedSession1 = await sessionService.getSession({\n    appName: APP_NAME,\n    userId: USER_ID,\n    sessionId: SESSION1_ID\n  });\n\n  // Add session to memory\n  console.log(\"\\n--- Adding Session 1 to Memory ---\");\n  if (completedSession1) {\n    await memoryService.addSessionToMemory(completedSession1 as SessionInterface);\n    console.log(\"Session added to memory.\");\n  }\n\n  // --- Turn 2: In a new session, ask a question requiring memory ---\n  console.log(\"\\n--- Turn 2: Recalling Information ---\");\n  const SESSION2_ID = \"session_recall\";\n\n  // Create a new session\n  const session2 = sessionService.createSession({\n    appName: APP_NAME,\n    userId: USER_ID,\n    sessionId: SESSION2_ID\n  });\n\n  // Update runner to use the memory recall agent\n  runner.agent = memoryRecallAgent;\n\n  // User's question\n  const userMessage2: Content = {\n    role: \"user\",\n    parts: [{ text: \"What is my favorite project?\" }]\n  };\n\n  // Process the user question with the memory recall agent\n  console.log(\"Running MemoryRecallAgent...\");\n  let finalResponseText2 = \"\";\n\n  for await (const event of runner.run({\n    userId: USER_ID,\n    sessionId: SESSION2_ID,\n      newMessage: userMessage2\n  })) {\n    // Log the event type\n    console.log(`  Event: ${event.author} - ${\n      event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text ? 'Text' : \n      event.getFunctionCalls().length &gt; 0 ? 'FuncCall' : \n      event.getFunctionResponses().length &gt; 0 ? 'FuncResp' : 'Other'\n    }`);\n\n    // If this is the final response, capture it\n    if (event.turnComplete &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts.length &gt; 0) {\n      finalResponseText2 = event.content.parts[0].text || \"\";\n      console.log(`Agent 2 Final Response: ${finalResponseText2}`);\n    }\n  }\n}\n\n// Run the scenario\nrunScenario().catch(console.error);\n\n/**\n * Expected Event Sequence for Turn 2:\n * 1. User sends \"What is my favorite project?\"\n * 2. Agent (LLM) decides to call `load_memory` tool with a query like \"favorite project\".\n * 3. Runner executes the `load_memory` tool, which calls `memoryService.searchMemory`.\n * 4. `InMemoryMemoryService` finds the relevant text (\"My favorite project is Project Alpha.\") from session1.\n * 5. Tool returns this text in a function response event.\n * 6. Agent (LLM) receives the function response, processes the retrieved text.\n * 7. Agent generates the final answer (e.g., \"Your favorite project is Project Alpha.\").\n */\n</code></pre>"},{"location":"sessions/memory/#memory-service-interface","title":"Memory Service Interface","text":"<p>In TypeScript, the <code>BaseMemoryService</code> interface is defined as:</p> <pre><code>export interface BaseMemoryService {\n  /**\n   * Adds a session to the memory service.\n   * @param session The session to add\n   */\n  addSessionToMemory(session: Session): Promise&lt;void&gt;;\n\n  /**\n   * Searches for memories that match the query.\n   * @param appName The application name\n   * @param userId The user ID\n   * @param query The query to search for\n   */\n  searchMemory(appName: string, userId: string, query: string): Promise&lt;SearchMemoryResponse&gt;;\n\n  /**\n   * Stores a key-value pair.\n   * @param appName The application name\n   * @param userId The user ID\n   * @param key The key\n   * @param value The value\n   */\n  store(appName: string, userId: string, key: string, value: any): Promise&lt;void&gt;;\n\n  /**\n   * Retrieves a value by key.\n   * @param appName The application name\n   * @param userId The user ID\n   * @param key The key\n   */\n  retrieve(appName: string, userId: string, key: string): Promise&lt;any | undefined&gt;;\n\n  /**\n   * Deletes a key-value pair.\n   * @param appName The application name\n   * @param userId The user ID\n   * @param key The key\n   */\n  delete(appName: string, userId: string, key: string): Promise&lt;void&gt;;\n}\n</code></pre> <p>All memory service implementations in the ADK follow this interface, ensuring a consistent API regardless of the backend technology.</p>"},{"location":"sessions/session/","title":"Session: Tracking Individual Conversations","text":"<p>Following our Introduction, let's dive into the <code>Session</code>. Think back to the idea of a \"conversation thread.\" Just like you wouldn't start every text message from scratch, agents need context from the ongoing interaction. <code>Session</code> is the ADK object designed specifically to track and manage these individual conversation threads.</p>"},{"location":"sessions/session/#the-session-object","title":"The <code>Session</code> Object","text":"<p>When a user starts interacting with your agent, the <code>SessionService</code> creates a <code>Session</code> object. This object acts as the container holding everything related to that one specific chat thread. Here are its key properties:</p> <ul> <li>Identification (<code>id</code>, <code>appName</code>, <code>userId</code>): Unique labels for the conversation.  <ul> <li><code>id</code>: A unique identifier for this specific conversation thread, essential for retrieving it later.  </li> <li><code>appName</code>: Identifies which agent application this conversation belongs to.  </li> <li><code>userId</code>: Links the conversation to a particular user.  </li> </ul> </li> <li>History (<code>events</code>): A chronological sequence of all interactions (<code>Event</code> objects \u2013 user messages, agent responses, tool actions) that have occurred within this specific thread.  </li> <li>Session Data (<code>state</code>): A place to store temporary data relevant only to this specific, ongoing conversation. This acts as a scratchpad for the agent during the interaction. We will cover how to use and manage <code>state</code> in detail in the next section.  </li> <li>Activity Tracking (<code>lastUpdateTime</code>): A timestamp indicating the last time an event was added to this conversation thread.</li> </ul>"},{"location":"sessions/session/#example-examining-session-properties","title":"Example: Examining Session Properties","text":"<pre><code>import { InMemorySessionService } from 'adk-typescript/sessions';\nimport { Session } from 'adk-typescript/sessions';\n\n// Create a simple session to examine its properties\nconst tempService = new InMemorySessionService();\nconst exampleSession: Session = await tempService.createSession({\n    appName: \"my_app\",\n    userId: \"example_user\",\n    state: {\"initial_key\": \"initial_value\"} // State can be initialized\n});\n\nconsole.log(\"--- Examining Session Properties ---\");\nconsole.log(`ID (id):                ${exampleSession.id}`);\nconsole.log(`Application Name (appName): ${exampleSession.appName}`);\nconsole.log(`User ID (userId):         ${exampleSession.userId}`);\nconsole.log(`State (state):           ${JSON.stringify(exampleSession.state)}`); // Note: Only shows initial state here\nconsole.log(`Events (events):         ${exampleSession.events.length}`); // Initially empty\nconsole.log(\"---------------------------------\");\n\n// Clean up (optional for this example)\ntempService.deleteSession({\n    appName: exampleSession.appName,\n    userId: exampleSession.userId,\n    sessionId: exampleSession.id\n});\n</code></pre> <p>(Note: The state shown above is only the initial state. State updates happen via events, as discussed in the State section.)</p>"},{"location":"sessions/session/#managing-sessions-with-a-sessionservice","title":"Managing Sessions with a <code>SessionService</code>","text":"<p>You don't typically create or manage <code>Session</code> objects directly. Instead, you use a <code>SessionService</code>. This service acts as the central manager responsible for the entire lifecycle of your conversation sessions.</p> <p>Its core responsibilities include:</p> <ul> <li>Starting New Conversations: Creating fresh <code>Session</code> objects when a user begins an interaction.  </li> <li>Resuming Existing Conversations: Retrieving a specific <code>Session</code> (using its ID) so the agent can continue where it left off.  </li> <li>Saving Progress: Appending new interactions (<code>Event</code> objects) to a session's history. This is also the mechanism through which session <code>state</code> gets updated (more in the State section).  </li> <li>Listing Conversations: Finding the active session threads for a particular user and application.  </li> <li>Cleaning Up: Deleting <code>Session</code> objects and their associated data when conversations are finished or no longer needed.</li> </ul>"},{"location":"sessions/session/#sessionservice-implementations","title":"<code>SessionService</code> Implementations","text":"<p>ADK provides different <code>SessionService</code> implementations, allowing you to choose the storage backend that best suits your needs:</p> <ol> <li> <p><code>InMemorySessionService</code> </p> <ul> <li>How it works: Stores all session data directly in the application's memory.  </li> <li>Persistence: None. All conversation data is lost if the application restarts. </li> <li>Requires: Nothing extra.  </li> <li>Best for: Quick tests, local development, examples, and scenarios where long-term persistence isn't required.</li> </ul> <pre><code>import { InMemorySessionService } from 'adk-typescript/sessions';\nconst sessionService = new InMemorySessionService();\n</code></pre> </li> <li> <p><code>DatabaseSessionService</code> </p> <ul> <li>How it works: Connects to a relational database (e.g., SQLite) to store session data persistently in tables.  </li> <li>Persistence: Yes. Data survives application restarts.  </li> <li>Requires: A configured database connection URL and TypeORM dependencies.  </li> <li>Best for: Applications needing reliable, persistent storage that you manage yourself.</li> </ul> <pre><code>import { DatabaseSessionService } from 'adk-typescript/sessions';\n\n// Example using a local SQLite file:\nconst dbUrl = \"sqlite:///./my_agent_data.db\";\nconst sessionService = new DatabaseSessionService(dbUrl);\n</code></pre> </li> <li> <p><code>VertexAiSessionService</code> </p> <ul> <li>How it works: Uses Google Cloud's Vertex AI infrastructure via API calls for session management.  </li> <li>Persistence: Yes. Data is managed reliably and scalably by Google Cloud.  </li> <li>Requires: A Google Cloud project, appropriate permissions, necessary SDKs, and the Reasoning Engine resource name/ID.  </li> <li>Best for: Scalable production applications deployed on Google Cloud, especially when integrating with other Vertex AI features.</li> </ul> <pre><code>import { VertexAiSessionService } from 'adk-typescript/sessions';\n\nconst PROJECT_ID = \"your-gcp-project-id\";\nconst LOCATION = \"us-central1\";\n// The appName used with this service should be the Reasoning Engine ID or name\nconst REASONING_ENGINE_APP_NAME = \"projects/your-gcp-project-id/locations/us-central1/reasoningEngines/your-engine-id\";\n\nconst sessionService = new VertexAiSessionService({\n  project: PROJECT_ID,\n  location: LOCATION\n});\n// Use REASONING_ENGINE_APP_NAME when calling service methods, e.g.:\n// sessionService.createSession({ appName: REASONING_ENGINE_APP_NAME, ... })\n</code></pre> </li> </ol> <p>Choosing the right <code>SessionService</code> is key to defining how your agent's conversation history and temporary data are stored and persist.</p>"},{"location":"sessions/session/#the-session-lifecycle","title":"The Session Lifecycle","text":"<p>Here's a simplified flow of how <code>Session</code> and <code>SessionService</code> work together during a conversation turn:</p> <ol> <li>Start or Resume: A user sends a message. Your application's <code>Runner</code> uses the <code>SessionService</code> to either <code>createSession</code> (for a new chat) or <code>getSession</code> (to retrieve an existing one).  </li> <li>Context Provided: The <code>Runner</code> gets the appropriate <code>Session</code> object from the service, providing the agent with access to its <code>state</code> and <code>events</code>.  </li> <li>Agent Processing: The agent uses the current user message, its instructions, and potentially the session <code>state</code> and <code>events</code> history to decide on a response.  </li> <li>Response &amp; State Update: The agent generates a response (and potentially flags data to be updated in the <code>state</code>). The <code>Runner</code> packages this as an <code>Event</code>.  </li> <li>Save Interaction: The <code>Runner</code> calls <code>sessionService.appendEvent(...)</code> with the <code>Session</code> and the new <code>Event</code>. The service adds the <code>Event</code> to the history and updates the session's <code>state</code> in storage based on information within the event.</li> <li>Ready for Next: The agent's response goes to the user. The updated <code>Session</code> is now stored by the <code>SessionService</code>, ready for the next turn (which restarts the cycle at step 1, usually with <code>getSession</code>).  </li> <li>End Conversation: When the conversation is over, ideally your application calls <code>sessionService.deleteSession(...)</code> to clean up the stored session data.</li> </ol> <p>This cycle highlights how the <code>SessionService</code> ensures conversational continuity by managing the history and state associated with each <code>Session</code> object.</p>"},{"location":"sessions/session/#session-interface","title":"Session Interface","text":"<p>In TypeScript, the Session is defined by the following interface:</p> <pre><code>interface Session {\n  id: string;\n  appName: string;\n  userId: string;\n  state: Record&lt;string, any&gt;;\n  events: Event[];\n}\n</code></pre> <p>All <code>SessionService</code> implementations in the ADK work with this common interface, ensuring consistency across different storage backends.</p>"},{"location":"sessions/state/","title":"State: The Session's Scratchpad","text":"<p>Within each <code>Session</code> (our conversation thread), the <code>state</code> attribute acts like the agent's dedicated scratchpad for that specific interaction. While <code>session.events</code> holds the full history, <code>session.state</code> is where the agent stores and updates dynamic details needed during the conversation.</p>"},{"location":"sessions/state/#what-is-sessionstate","title":"What is <code>session.state</code>?","text":"<p>Conceptually, <code>session.state</code> is an instance of the <code>State</code> class which behaves like a record holding key-value pairs. It's designed for information the agent needs to recall or track to make the current conversation effective:</p> <ul> <li>Personalize Interaction: Remember user preferences mentioned earlier (e.g., <code>'user_preference_theme': 'dark'</code>).  </li> <li>Track Task Progress: Keep tabs on steps in a multi-turn process (e.g., <code>'booking_step': 'confirm_payment'</code>).  </li> <li>Accumulate Information: Build lists or summaries (e.g., <code>'shopping_cart_items': ['book', 'pen']</code>).  </li> <li>Make Informed Decisions: Store flags or values influencing the next response (e.g., <code>'user_is_authenticated': true</code>).</li> </ul>"},{"location":"sessions/state/#key-characteristics-of-state","title":"Key Characteristics of <code>State</code>","text":"<ol> <li> <p>Structure: Serializable Key-Value Pairs </p> <ul> <li>Data is stored as <code>key: value</code>.  </li> <li>Keys: Always strings (<code>string</code>). Use clear names (e.g., <code>'departure_city'</code>, <code>'user:language_preference'</code>).  </li> <li>Values: Must be serializable. This means they can be easily saved and loaded by the <code>SessionService</code>. Stick to basic TypeScript types like strings, numbers, booleans, and simple arrays or objects containing only these basic types.</li> <li>\u26a0\ufe0f Avoid Complex Objects: Do not store non-serializable objects (custom class instances, functions, connections, etc.) directly in the state. Store simple identifiers if needed, and retrieve the complex object elsewhere.</li> </ul> </li> <li> <p>Mutability: It Changes </p> <ul> <li>The contents of the <code>state</code> are expected to change as the conversation evolves.</li> </ul> </li> <li> <p>Persistence: Depends on <code>SessionService</code> </p> <ul> <li>Whether state survives application restarts depends on your chosen service:  </li> <li><code>InMemorySessionService</code>: Not Persistent. State is lost on restart.  </li> <li><code>DatabaseSessionService</code> / <code>VertexAiSessionService</code>: Persistent. State is saved reliably.</li> </ul> </li> </ol>"},{"location":"sessions/state/#organizing-state-with-prefixes-scope-matters","title":"Organizing State with Prefixes: Scope Matters","text":"<p>Prefixes on state keys define their scope and persistence behavior, especially with persistent services:</p> <ul> <li> <p>No Prefix (Session State): </p> <ul> <li>Scope: Specific to the current session (<code>id</code>).  </li> <li>Persistence: Only persists if the <code>SessionService</code> is persistent (<code>Database</code>, <code>VertexAI</code>).  </li> <li>Use Cases: Tracking progress within the current task (e.g., <code>'current_booking_step'</code>), temporary flags for this interaction (e.g., <code>'needs_clarification'</code>).  </li> <li>Example: <code>session.state['current_intent'] = 'book_flight'</code> or <code>session.state.set('current_intent', 'book_flight')</code></li> </ul> </li> <li> <p><code>user:</code> Prefix (User State): </p> <ul> <li>Scope: Tied to the <code>userId</code>, shared across all sessions for that user (within the same <code>appName</code>).  </li> <li>Persistence: Persistent with persistent service implementations. (Stored by <code>InMemory</code> but lost on restart).  </li> <li>Use Cases: User preferences (e.g., <code>'user:theme'</code>), profile details (e.g., <code>'user:name'</code>).  </li> <li>Example: <code>session.state['user:preferred_language'] = 'fr'</code> or <code>session.state.set('user:preferred_language', 'fr')</code></li> </ul> </li> <li> <p><code>app:</code> Prefix (App State): </p> <ul> <li>Scope: Tied to the <code>appName</code>, shared across all users and sessions for that application.  </li> <li>Persistence: Persistent with persistent service implementations. (Stored by <code>InMemory</code> but lost on restart).  </li> <li>Use Cases: Global settings (e.g., <code>'app:api_endpoint'</code>), shared templates.  </li> <li>Example: <code>session.state['app:global_discount_code'] = 'SAVE10'</code> or <code>session.state.set('app:global_discount_code', 'SAVE10')</code></li> </ul> </li> <li> <p><code>temp:</code> Prefix (Temporary Session State): </p> <ul> <li>Scope: Specific to the current session processing turn.  </li> <li>Persistence: Never Persistent. Guaranteed to be discarded, even with persistent services.  </li> <li>Use Cases: Intermediate results needed only immediately, data you explicitly don't want stored.  </li> <li>Example: <code>session.state['temp:raw_api_response'] = {...}</code> or <code>session.state.set('temp:raw_api_response', {...})</code></li> </ul> </li> </ul> <p>How the Agent Sees It: Your agent code interacts with the combined state through the single <code>session.state</code> object. The <code>SessionService</code> handles fetching/merging state from the correct underlying storage based on prefixes.</p>"},{"location":"sessions/state/#accessing-state-data","title":"Accessing State Data","text":"<p>The <code>State</code> class provides multiple ways to access and modify state data:</p> <ol> <li> <p>Direct Property Access: <pre><code>// Get a value\nconst theme = session.state['user:theme'];\n\n// Set a value\nsession.state['current_step'] = 'confirmation';\n</code></pre></p> </li> <li> <p>Method-based Access: <pre><code>// Get a value\nconst theme = session.state.get('user:theme');\n\n// Set a value\nsession.state.set('current_step', 'confirmation');\n\n// Check if a key exists\nif (session.state.has('user:preferences')) {\n  // Do something with the preferences\n}\n\n// Delete a key\nsession.state.delete('temp:calculation_result');\n\n// Get all state as a plain object\nconst allState = session.state.getAll();\n\n// Update multiple values at once\nsession.state.update({\n  'step': 'payment',\n  'user:last_action': 'checkout',\n  'temp:validation_results': { valid: true }\n});\n</code></pre></p> </li> </ol> <p>The method-based approach is more explicit and provides additional functionality like <code>has()</code>, <code>delete()</code>, and <code>update()</code>.</p>"},{"location":"sessions/state/#how-state-is-updated-recommended-methods","title":"How State is Updated: Recommended Methods","text":"<p>State should always be updated as part of adding an <code>Event</code> to the session history using <code>sessionService.appendEvent()</code>. This ensures changes are tracked, persistence works correctly, and updates are thread-safe.</p> <p>1. The Easy Way: <code>outputKey</code> (for Agent Text Responses)</p> <p>This is the simplest method for saving an agent's final text response directly into the state. When defining your <code>LlmAgent</code>, specify the <code>outputKey</code>:</p> <pre><code>import { LlmAgent } from 'adk-typescript/agents';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { Runner } from 'adk-typescript/runners';\nimport { Content, Part } from 'adk-typescript/models';\n\n// Define agent with outputKey\nconst greetingAgent = new LlmAgent({\n  name: \"Greeter\",\n  model: \"gemini-2.0-flash\", // Use a valid model\n  instruction: \"Generate a short, friendly greeting.\",\n  outputKey: \"last_greeting\" // Save response to state['last_greeting']\n});\n\n// --- Setup Runner and Session ---\nconst appName = \"state_app\";\nconst userId = \"user1\";\nconst sessionId = \"session1\";\nconst sessionService = new InMemorySessionService();\nconst runner = new Runner({\n  agent: greetingAgent,\n  appName: appName,\n  sessionService: sessionService\n});\n\nconst session = await sessionService.createSession({\n  appName: appName,\n  userId: userId,\n  sessionId: sessionId\n});\nconsole.log(`Initial state: ${JSON.stringify(session.state.getAll())}`);\n\n// --- Run the Agent ---\n// Runner handles calling appendEvent, which uses the outputKey\n// to automatically create the stateDelta.\nconst userMessage = new Content({\n  role: 'user',\n  parts: [new Part({ text: \"Hello\" })]\n});\n\nfor await (const event of runner.run({\n  userId: userId,\n  sessionId: sessionId,\n  newMessage: userMessage\n})) {\n  if (event.isFinalResponse()) {\n    console.log(\"Agent responded.\"); // Response text is also in event.content\n  }\n}\n\n// --- Check Updated State ---\nconst updatedSession = await sessionService.getSession({\n  appName: appName,\n  userId: userId,\n  sessionId: sessionId\n});\nconsole.log(`State after agent run: ${JSON.stringify(updatedSession?.state.getAll())}`);\n// Expected output might include: {'last_greeting': 'Hello there! How can I help you today?'}\n</code></pre> <p>Behind the scenes, the <code>Runner</code> uses the <code>outputKey</code> to create the necessary <code>EventActions</code> with a <code>stateDelta</code> and calls <code>appendEvent</code>.</p> <p>2. The Standard Way: <code>EventActions.stateDelta</code> (for Complex Updates)</p> <p>For more complex scenarios (updating multiple keys, non-string values, specific scopes like <code>user:</code> or <code>app:</code>, or updates not tied directly to the agent's final text), you manually construct the <code>stateDelta</code> within <code>EventActions</code>.</p> <pre><code>import { Event, EventActions } from 'adk-typescript/events';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { StatePrefix } from 'adk-typescript/sessions';\n\n// --- Setup ---\nconst sessionService = new InMemorySessionService();\nconst appName = \"state_app_manual\";\nconst userId = \"user2\";\nconst sessionId = \"session2\";\n\n// Create a session with initial state\nconst session = await sessionService.createSession({\n  appName,\n  userId,\n  sessionId,\n  state: { 'user:login_count': 0, 'task_status': 'idle' }\n});\nconsole.log(`Initial state: ${JSON.stringify(session.state.getAll())}`);\n\n// --- Define State Changes ---\nconst currentTime = Date.now() / 1000; // Convert to seconds for timestamp consistency\nconst stateChanges: Record&lt;string, any&gt; = {\n  'task_status': 'active',              // Update session state\n  'user:login_count': (session.state.get('user:login_count') || 0) + 1, // Update user state\n  'user:last_login_ts': currentTime,    // Add user state\n  'temp:validation_needed': true        // Add temporary state (will be discarded)\n};\n\n// --- Create Event with Actions ---\nconst actionsWithUpdate = new EventActions({ stateDelta: stateChanges });\n// This event might represent an internal system action, not just an agent response\nconst systemEvent = new Event({\n  invocationId: 'inv_login_update',\n  author: 'system', // Or 'agent', 'tool' etc.\n  actions: actionsWithUpdate,\n  timestamp: currentTime,\n  content: {\n    role: 'system',\n    parts: [{ text: 'System login update processed' }]\n  }\n});\n\n// --- Append the Event (This updates the state) ---\nawait sessionService.appendEvent({ session, event: systemEvent });\nconsole.log('`appendEvent` called with explicit state delta.');\n\n// --- Check Updated State ---\nconst updatedSession = await sessionService.getSession({\n  appName,\n  userId,\n  sessionId\n});\nconsole.log(`State after event: ${JSON.stringify(updatedSession?.state.getAll())}`);\n// Expected: {'user:login_count': 1, 'task_status': 'active', 'user:last_login_ts': &lt;timestamp&gt;}\n// Note: 'temp:validation_needed' is NOT present in persistent storage.\n</code></pre> <p>3. Via <code>CallbackContext</code> or <code>ToolContext</code> (Recommended for Callbacks and Tools)</p> <p>Modifying state within agent callbacks (e.g., <code>beforeModelCallback</code>, <code>afterModelCallback</code>) or tool functions is best done using the <code>state</code> attribute of the <code>CallbackContext</code> or <code>ToolContext</code> provided to your function.</p> <ul> <li><code>callbackContext.state.set('my_key', my_value)</code></li> <li><code>toolContext.state.set('my_key', my_value)</code></li> </ul> <p>These context objects are specifically designed to manage state changes within their respective execution scopes. When you modify <code>context.state</code>, the ADK framework ensures that these changes are automatically captured and correctly routed into the <code>EventActions.stateDelta</code> for the event being generated by the callback or tool. This delta is then processed by the <code>SessionService</code> when the event is appended, ensuring proper persistence and tracking.</p> <p>This method abstracts away the manual creation of <code>EventActions</code> and <code>stateDelta</code> for most common state update scenarios within callbacks and tools, making your code cleaner and less error-prone.</p> <p>For more comprehensive details on context objects, refer to the Context documentation.</p> <pre><code>// In an agent callback or tool function\nimport { CallbackContext } from 'adk-typescript/agents'; // or ToolContext from 'adk-typescript/tools'\n\nfunction myCallbackOrToolFunction(\n  context: CallbackContext, // Or ToolContext\n  // ... other parameters ...\n): void {\n  // Update existing state\n  const count = context.state.get(\"user_action_count\", 0);\n  context.state.set(\"user_action_count\", count + 1);\n\n  // Add new state\n  context.state.set(\"temp:last_operation_status\", \"success\");\n\n  // State changes are automatically part of the event's stateDelta\n  // ... rest of callback/tool logic ...\n}\n</code></pre> <p>What <code>appendEvent</code> Does:</p> <ul> <li>Adds the <code>Event</code> to <code>session.events</code>.  </li> <li>Reads the <code>stateDelta</code> from the event's <code>actions</code>.  </li> <li>Applies these changes to the state managed by the <code>SessionService</code>, correctly handling prefixes and persistence based on the service type.  </li> <li>Updates the session's <code>lastUpdateTime</code>.  </li> <li>Ensures thread-safety for concurrent updates.</li> </ul>"},{"location":"sessions/state/#a-warning-about-direct-state-modification","title":"\u26a0\ufe0f A Warning About Direct State Modification","text":"<p>Avoid directly modifying the <code>session.state</code> object on a <code>Session</code> object that was obtained directly from the <code>SessionService</code> (e.g., via <code>sessionService.getSession()</code> or <code>sessionService.createSession()</code>) outside of the managed lifecycle of an agent invocation (i.e., not through a <code>CallbackContext</code> or <code>ToolContext</code>). For example, code like <code>retrievedSession = await sessionService.getSession(...); retrievedSession.state.set('key', value)</code> is problematic.</p> <p>State modifications within callbacks or tools using <code>CallbackContext.state</code> or <code>ToolContext.state</code> are the correct way to ensure changes are tracked, as these context objects handle the necessary integration with the event system.</p> <p>Why direct modification (outside of contexts) is strongly discouraged:</p> <ol> <li>Bypasses Event History: The change isn't recorded as an <code>Event</code>, losing auditability.</li> <li>Breaks Persistence: Changes made this way will likely NOT be saved by <code>DatabaseSessionService</code> or <code>VertexAiSessionService</code>. They rely on <code>appendEvent</code> to trigger saving.</li> <li>Not Thread-Safe: Can lead to race conditions and lost updates.</li> <li>Ignores Timestamps/Logic: Doesn't update <code>lastUpdateTime</code> or trigger related event logic.</li> </ol> <p>Recommendation: Stick to updating state via <code>outputKey</code>, <code>EventActions.stateDelta</code> (when manually creating events), or by modifying the <code>state</code> property of <code>CallbackContext</code> or <code>ToolContext</code> objects when within their respective scopes. These methods ensure reliable, trackable, and persistent state management. Use direct access to <code>session.state</code> (from a <code>SessionService</code>-retrieved session) only for reading state.</p>"},{"location":"sessions/state/#best-practices-for-state-design-recap","title":"Best Practices for State Design Recap","text":"<ul> <li>Minimalism: Store only essential, dynamic data.  </li> <li>Serialization: Use basic, serializable types.  </li> <li>Descriptive Keys &amp; Prefixes: Use clear names and appropriate prefixes (<code>user:</code>, <code>app:</code>, <code>temp:</code>, or none).  </li> <li>Shallow Structures: Avoid deep nesting where possible.  </li> <li>Standard Update Flow: Rely on <code>appendEvent</code>.</li> </ul>"},{"location":"sessions/state/#access-constants-for-prefixes","title":"Access Constants for Prefixes","text":"<p>TypeScript provides constants for the standard prefixes in the <code>StatePrefix</code> class:</p> <pre><code>import { StatePrefix } from 'adk-typescript/sessions';\n\n// Use constants for prefixes\nconst appSettings = `${StatePrefix.APP_PREFIX}feature_flags`;\nconst userPreference = `${StatePrefix.USER_PREFIX}theme`;\nconst tempData = `${StatePrefix.TEMP_PREFIX}calculation_result`;\n</code></pre> <p>This helps avoid typos and ensures consistent prefix usage throughout your application.</p>"},{"location":"tools/","title":"Tools","text":""},{"location":"tools/#what-is-a-tool","title":"What is a Tool?","text":"<p>In the context of ADK, a Tool represents a specific capability provided to an AI agent, enabling it to perform actions and interact with the world beyond its core text generation and reasoning abilities. What distinguishes capable agents from basic language models is often their effective use of tools.</p> <p>Technically, a tool is typically a modular code component\u2014like a Python function, a class method, or even another specialized agent\u2014designed to execute a distinct, predefined task. These tasks often involve interacting with external systems or data.</p> <p></p>"},{"location":"tools/#key-characteristics","title":"Key Characteristics","text":"<p>Action-Oriented: Tools perform specific actions, such as:</p> <ul> <li>Querying databases</li> <li>Making API requests (e.g., fetching weather data, booking systems)</li> <li>Searching the web</li> <li>Executing code snippets</li> <li>Retrieving information from documents (RAG)</li> <li>Interacting with other software or services</li> </ul> <p>Extends Agent capabilities: They empower agents to access real-time information, affect external systems, and overcome the knowledge limitations inherent in their training data.</p> <p>Execute predefined logic: Crucially, tools execute specific, developer-defined logic. They do not possess their own independent reasoning capabilities like the agent's core Large Language Model (LLM). The LLM reasons about which tool to use, when, and with what inputs, but the tool itself just executes its designated function.</p>"},{"location":"tools/#how-agents-use-tools","title":"How Agents Use Tools","text":"<p>Agents leverage tools dynamically through mechanisms often involving function calling. The process generally follows these steps:</p> <ol> <li>Reasoning: The agent's LLM analyzes its system instruction, conversation history, and user request.</li> <li>Selection: Based on the analysis, the LLM decides on which tool, if any, to execute, based on the tools available to the agent and the docstrings that describes each tool.</li> <li>Invocation: The LLM generates the required arguments (inputs) for the selected tool and triggers its execution.</li> <li>Observation: The agent receives the output (result) returned by the tool.</li> <li>Finalization: The agent incorporates the tool's output into its ongoing reasoning process to formulate the next response, decide the subsequent step, or determine if the goal has been achieved.</li> </ol> <p>Think of the tools as a specialized toolkit that the agent's intelligent core (the LLM) can access and utilize as needed to accomplish complex tasks.</p>"},{"location":"tools/#tool-types-in-adk","title":"Tool Types in ADK","text":"<p>ADK offers flexibility by supporting several types of tools:</p> <ol> <li>Function Tools: Tools created by you, tailored to your specific application's needs.<ul> <li>Functions/Methods: Define standard synchronous functions or methods in your code (e.g., Python def).</li> <li>Agents-as-Tools: Use another, potentially specialized, agent as a tool for a parent agent.</li> <li>Long Running Function Tools: Support for tools that perform asynchronous operations or take significant time to complete.</li> </ul> </li> <li>Built-in Tools: Ready-to-use tools provided by the framework for common tasks.         Examples: Google Search, Code Execution, Retrieval-Augmented Generation (RAG).</li> <li>Third-Party Tools: Integrate tools seamlessly from popular external libraries.         Examples: LangChain Tools, CrewAI Tools.</li> </ol> <p>Navigate to the respective documentation pages linked above for detailed information and examples for each tool type.</p>"},{"location":"tools/#referencing-tool-in-agents-instructions","title":"Referencing Tool in Agent's Instructions","text":"<p>Within an agent's instructions, you can directly reference a tool by using its function name. If the tool's function name and docstring are sufficiently descriptive, your instructions can primarily focus on when the Large Language Model (LLM) should utilize the tool. This promotes clarity and helps the model understand the intended use of each tool.</p> <p>It is crucial to clearly instruct the agent on how to handle different return values that a tool might produce. For example, if a tool returns an error message, your instructions should specify whether the agent should retry the operation, give up on the task, or request additional information from the user.</p> <p>Furthermore, ADK supports the sequential use of tools, where the output of one tool can serve as the input for another. When implementing such workflows, it's important to describe the intended sequence of tool usage within the agent's instructions to guide the model through the necessary steps.</p>"},{"location":"tools/#example","title":"Example","text":"<p>The following example showcases how an agent can use tools by referencing their function names in its instructions. It also demonstrates how to guide the agent to handle different return values from tools, such as success or error messages, and how to orchestrate the sequential use of multiple tools to accomplish a task.</p> <pre><code>import { LlmAgent as Agent } from 'adk-typescript/agents';\nimport { runners } from 'adk-typescript';\nimport { Content } from 'adk-typescript/types';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\n\n// Constants for the app\nconst APP_NAME = \"weather_sentiment_agent\";\nconst USER_ID = \"user1234\";\nconst SESSION_ID = \"1234\";\nconst MODEL_ID = \"gemini-2.0-flash\";\n\n// Configure logging (simplified version for TypeScript)\nconst logger = {\n  info: (message: string, ...args: any[]) =&gt; console.info(message, ...args),\n  error: (message: string, ...args: any[]) =&gt; console.error(message, ...args)\n};\n\n// Tool 1: Get Weather Report\nfunction getWeatherReport(city: string): Record&lt;string, string | Record&lt;string, string&gt;&gt; {\n  /**\n   * Retrieves the current weather report for a specified city.\n   * \n   * @param city The name of the city to get weather for\n   * @returns A dictionary with status and either a report or error message\n   */\n  if (city.toLowerCase() === \"london\") {\n    return { \n      \"status\": \"success\", \n      \"report\": \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a chance of rain.\" \n    };\n  } else if (city.toLowerCase() === \"paris\") {\n    return { \n      \"status\": \"success\", \n      \"report\": \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\" \n    };\n  } else {\n    return { \n      \"status\": \"error\", \n      \"error_message\": `Weather information for '${city}' is not available.` \n    };\n  }\n}\n\n\n// Tool 2: Analyze Sentiment\nfunction analyzeSentiment(text: string): Record&lt;string, string | number&gt; {\n  /**\n   * Analyzes the sentiment of the given text.\n   * \n   * @param text The text to analyze\n   * @returns A dictionary with sentiment type and confidence score\n   */\n  if (text.toLowerCase().includes(\"good\") || text.toLowerCase().includes(\"sunny\")) {\n    return { \"sentiment\": \"positive\", \"confidence\": 0.8 };\n  } else if (text.toLowerCase().includes(\"rain\") || text.toLowerCase().includes(\"bad\")) {\n    return { \"sentiment\": \"negative\", \"confidence\": 0.7 };\n  } else {\n    return { \"sentiment\": \"neutral\", \"confidence\": 0.6 };\n  }\n}\n\n\n// Create the agent with both tools\nconst weatherSentimentAgent = new Agent({\n  name: \"weather_sentiment_agent\",\n  model: MODEL_ID,\n  instruction: `You are a helpful assistant that provides weather information and analyzes the sentiment of user feedback.\n**If the user asks about the weather in a specific city, use the 'get_weather_report' tool to retrieve the weather details.**\n**If the 'get_weather_report' tool returns a 'success' status, provide the weather report to the user.**\n**If the 'get_weather_report' tool returns an 'error' status, inform the user that the weather information for the specified city is not available and ask if they have another city in mind.**\n**After providing a weather report, if the user gives feedback on the weather (e.g., 'That's good' or 'I don't like rain'), use the 'analyze_sentiment' tool to understand their sentiment.** Then, briefly acknowledge their sentiment.\nYou can handle these tasks sequentially if needed.`,\n  tools: [getWeatherReport, analyzeSentiment]\n});\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nconst session = sessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: weatherSentimentAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nfunction callAgent(query: string): void {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  (async () =&gt; {\n    try {\n      const events = runner.run({\n        userId: USER_ID, \n        sessionId: SESSION_ID, \n        newMessage: content\n      });\n\n      for await (const event of events) {\n        if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n          const finalResponse = event.content.parts[0].text;\n          console.log(\"Agent Response: \", finalResponse);\n        }\n      }\n    } catch (error) {\n      console.error(\"Error running agent:\", error);\n    }\n  })();\n}\n\n// Execute with a sample query\nif (require.main === module) {\n  callAgent(\"weather in london?\");\n}\n\n// Export for external use\nexport const agent = weatherSentimentAgent;\nexport function runWeatherSentimentDemo(query: string): void {\n  callAgent(query);\n} \n</code></pre>"},{"location":"tools/#tool-context","title":"Tool Context","text":"<p>For more advanced scenarios, ADK allows you to access additional contextual information within your tool function by including the special parameter <code>tool_context: ToolContext</code>. By including this in the function signature, ADK will automatically provide an instance of the ToolContext class when your tool is called during agent execution.</p> <p>The ToolContext provides access to several key pieces of information and control levers:</p> <ul> <li> <p><code>state: State</code>: Read and modify the current session's state. Changes made here are tracked and persisted.</p> </li> <li> <p><code>actions: EventActions</code>: Influence the agent's subsequent actions after the tool runs (e.g., skip summarization, transfer to another agent).</p> </li> <li> <p><code>function_call_id: str</code>: The unique identifier assigned by the framework to this specific invocation of the tool. Useful for tracking and correlating with authentication responses. This can also be helpful when multiple tools are called within a single model response.</p> </li> <li> <p><code>function_call_event_id: str</code>: This attribute provides the unique identifier of the event that triggered the current tool call. This can be useful for tracking and logging purposes.</p> </li> <li> <p><code>auth_response: Any</code>: Contains the authentication response/credentials if an authentication flow was completed before this tool call.</p> </li> <li> <p>Access to Services: Methods to interact with configured services like Artifacts and Memory.</p> </li> </ul>"},{"location":"tools/#state-management","title":"State Management","text":"<p>The <code>tool_context.state</code> attribute provides direct read and write access to the state associated with the current session. It behaves like a dictionary but ensures that any modifications are tracked as deltas and persisted by the session service. This enables tools to maintain and share information across different interactions and agent steps.</p> <ul> <li> <p>Reading State: Use standard dictionary access (<code>tool_context.state['my_key']</code>) or the <code>.get()</code> method (<code>tool_context.state.get('my_key', default_value)</code>).</p> </li> <li> <p>Writing State: Assign values directly (<code>tool_context.state['new_key'] = 'new_value'</code>). These changes are recorded in the state_delta of the resulting event.</p> </li> <li> <p>State Prefixes: Remember the standard state prefixes:</p> <ul> <li> <p><code>app:*</code>: Shared across all users of the application.</p> </li> <li> <p><code>user:*</code>: Specific to the current user across all their sessions.</p> </li> <li> <p>(No prefix): Specific to the current session.</p> </li> <li> <p><code>temp:*</code>: Temporary, not persisted across invocations (useful for passing data within a single run call but generally less useful inside a tool context which operates between LLM calls).</p> </li> </ul> </li> </ul> <pre><code>/**\n * TypeScript port of the user_preference.py example from the Python ADK library\n * \n * This example demonstrates how to use ToolContext to update user-specific preferences\n * in the session state when a tool is invoked.\n * \n * NOTE: This is a template file that demonstrates how to use the ADK TypeScript library.\n * You'll see TypeScript errors in your IDE until you install the actual 'adk-typescript' package.\n * The structure and patterns shown here match how you would use the library in a real project.\n */\n\nimport { ToolContext, FunctionTool } from 'adk-typescript/tools';\n\n/**\n * Updates a user-specific preference in the session state.\n * \n * @param preference The preference name to update\n * @param value The value to set for the preference\n * @param toolContext The context for the tool execution, providing access to state\n * @returns A status object indicating success and which preference was updated\n */\nfunction updateUserPreference(\n  preference: string, \n  value: string, \n  toolContext: ToolContext\n): Record&lt;string, string&gt; {\n  const userPrefsKey = \"user:preferences\";\n\n  // Get current preferences or initialize if none exist\n  const preferences = toolContext.state.get(userPrefsKey, {});\n\n  // Update the specific preference\n  preferences[preference] = value;\n\n  // Write the updated dictionary back to the state\n  toolContext.state[userPrefsKey] = preferences;\n\n  console.log(`Tool: Updated user preference '${preference}' to '${value}'`);\n\n  return { \n    \"status\": \"success\", \n    \"updated_preference\": preference \n  };\n}\n\n\n// Export for use in an Agent\nexport const userPreferenceTool = updateUserPreference;\n\n/**\n * Usage example in an Agent:\n * \n * ```typescript\n * import { Agent } from 'adk-typescript';\n * import { userPreferenceTool } from './user-preference';\n * \n * const myAgent = new Agent(\"preference_agent\", {\n *   model: \"gemini-2.0-flash\",\n *   instruction: \"You can update user preferences when asked.\",\n *   tools: [userPreferenceTool]\n * });\n * ```\n * \n * When the LLM calls updateUserPreference(preference='theme', value='dark', ...):\n * - The toolContext.state will be updated with {'user:preferences': {'theme': 'dark'}}\n * - The change will be part of the resulting tool response event's actions.state_delta\n */ \n</code></pre>"},{"location":"tools/#controlling-agent-flow","title":"Controlling Agent Flow","text":"<p>The <code>tool_context.actions</code> attribute holds an EventActions object. Modifying attributes on this object allows your tool to influence what the agent or framework does after the tool finishes execution.</p> <ul> <li> <p><code>skip_summarization: bool</code>: (Default: False) If set to True, instructs the ADK to bypass the LLM call that typically summarizes the tool's output. This is useful if your tool's return value is already a user-ready message.</p> </li> <li> <p><code>transfer_to_agent: str</code>: Set this to the name of another agent. The framework will halt the current agent's execution and transfer control of the conversation to the specified agent. This allows tools to dynamically hand off tasks to more specialized agents.</p> </li> <li> <p><code>escalate: bool</code>: (Default: False) Setting this to True signals that the current agent cannot handle the request and should pass control up to its parent agent (if in a hierarchy). In a LoopAgent, setting escalate=True in a sub-agent's tool will terminate the loop.</p> </li> </ul>"},{"location":"tools/#example_1","title":"Example","text":"<pre><code>import { LlmAgent as Agent } from 'adk-typescript/agents';\nimport { runners } from 'adk-typescript';\nimport { Content } from 'adk-typescript/types';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { ToolContext } from 'adk-typescript/tools';\n\n// Constants for the app\nconst APP_NAME = \"customer_support_agent\";\nconst USER_ID = \"user1234\";\nconst SESSION_ID = \"1234\";\n\n// Configure logging (simplified version for TypeScript)\nconst logger = {\n  info: (message: string, ...args: any[]) =&gt; console.info(message, ...args),\n  error: (message: string, ...args: any[]) =&gt; console.error(message, ...args)\n};\n\n/**\n * Checks if a query requires escalation and transfers to another agent if needed.\n * \n * @param query The user's query to check for urgency\n * @param toolContext The context for the tool execution\n * @returns A message indicating if transfer occurred\n */\nfunction checkAndTransfer(query: string, toolContext: ToolContext): string {\n  if (query.toLowerCase().includes(\"urgent\")) {\n    console.log(\"Tool: Detected urgency, transferring to the support agent.\");\n    toolContext.actions.transferToAgent = \"support_agent\";\n    return \"Transferring to the support agent...\";\n  } else {\n    return `Processed query: '${query}'. No further action needed.`;\n  }\n}\n\n\n// Create the main agent\nconst mainAgent = new Agent({\n  name: \"main_agent\",\n  model: \"gemini-2.0-flash\",\n  instruction: \"You are the first point of contact for customer support of an analytics tool. Answer general queries. If the user indicates urgency, use the 'check_and_transfer' tool.\",\n  tools: [checkAndTransfer]\n});\n\n// Create the support agent\nconst supportAgent = new Agent({\n  name: \"support_agent\",\n  model: \"gemini-2.0-flash\",\n  instruction: \"You are the dedicated support agent. Mentioned you are a support handler and please help the user with their urgent issue.\"\n});\n\n// Add the support agent as a sub-agent of the main agent\nmainAgent.subAgents = [supportAgent];\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nconst session = sessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: mainAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nfunction callAgent(query: string): void {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  (async () =&gt; {\n    try {\n      const events = runner.run({\n        userId: USER_ID, \n        sessionId: SESSION_ID, \n        newMessage: content\n      });\n\n      for await (const event of events) {\n        if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n          const finalResponse = event.content.parts[0].text;\n          console.log(\"Agent Response: \", finalResponse);\n        }\n      }\n    } catch (error) {\n      console.error(\"Error running agent:\", error);\n    }\n  })();\n}\n\n// Execute with a sample query\nif (require.main === module) {\n  callAgent(\"this is urgent, i cant login\");\n}\n\n// Export for external use\nexport const agent = mainAgent;\nexport function runCustomerSupportDemo(query: string): void {\n  callAgent(query);\n} \n</code></pre>"},{"location":"tools/#explanation","title":"Explanation","text":"<ul> <li>We define two agents: <code>main_agent</code> and <code>support_agent</code>. The <code>main_agent</code> is designed to be the initial point of contact.</li> <li>The <code>check_and_transfer</code> tool, when called by <code>main_agent</code>, examines the user's query.</li> <li>If the query contains the word \"urgent\", the tool accesses the <code>tool_context</code>, specifically <code>tool_context.actions</code>, and sets the transfer_to_agent attribute to <code>support_agent</code>.</li> <li>This action signals to the framework to transfer the control of the conversation to the agent named <code>support_agent</code>.</li> <li>When the <code>main_agent</code> processes the urgent query, the <code>check_and_transfer</code> tool triggers the transfer. The subsequent response would ideally come from the <code>support_agent</code>.</li> <li>For a normal query without urgency, the tool simply processes it without triggering a transfer.</li> </ul> <p>This example illustrates how a tool, through EventActions in its ToolContext, can dynamically influence the flow of the conversation by transferring control to another specialized agent.</p>"},{"location":"tools/#authentication","title":"Authentication","text":"<p>ToolContext provides mechanisms for tools interacting with authenticated APIs. If your tool needs to handle authentication, you might use the following:</p> <ul> <li> <p><code>auth_response</code>: Contains credentials (e.g., a token) if authentication was already handled by the framework before your tool was called (common with RestApiTool and OpenAPI security schemes).</p> </li> <li> <p><code>request_credential(auth_config: dict)</code>: Call this method if your tool determines authentication is needed but credentials aren't available. This signals the framework to start an authentication flow based on the provided auth_config.</p> </li> <li> <p><code>get_auth_response()</code>: Call this in a subsequent invocation (after request_credential was successfully handled) to retrieve the credentials the user provided.</p> </li> </ul> <p>For detailed explanations of authentication flows, configuration, and examples, please refer to the dedicated Tool Authentication documentation page.</p>"},{"location":"tools/#context-aware-data-access-methods","title":"Context-Aware Data Access Methods","text":"<p>These methods provide convenient ways for your tool to interact with persistent data associated with the session or user, managed by configured services.</p> <ul> <li> <p><code>list_artifacts()</code>: Returns a list of filenames (or keys) for all artifacts currently stored for the session via the artifact_service. Artifacts are typically files (images, documents, etc.) uploaded by the user or generated by tools/agents.</p> </li> <li> <p><code>load_artifact(filename: str)</code>: Retrieves a specific artifact by its filename from the artifact_service. You can optionally specify a version; if omitted, the latest version is returned. Returns a <code>google.genai.types.Part</code> object containing the artifact data and mime type, or None if not found.</p> </li> <li> <p><code>save_artifact(filename: str, artifact: types.Part)</code>: Saves a new version of an artifact to the artifact_service. Returns the new version number (starting from 0).</p> </li> <li> <p><code>search_memory(query: str)</code>: Queries the user's long-term memory using the configured <code>memory_service</code>. This is useful for retrieving relevant information from past interactions or stored knowledge. The structure of the SearchMemoryResponse depends on the specific memory service implementation but typically contains relevant text snippets or conversation excerpts.</p> </li> </ul>"},{"location":"tools/#example_2","title":"Example","text":"<pre><code>import { LlmAgent as Agent } from 'adk-typescript/agents';\nimport { runners } from 'adk-typescript';\nimport { Content, Part } from 'adk-typescript/types';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { ToolContext } from 'adk-typescript/tools';\nimport { FunctionTool } from 'adk-typescript/tools';\n\n/**\n * Analyzes a document using context from memory.\n * \n * @param params Object containing documentName and analysisQuery\n * @param toolContext The context for the tool execution with access to artifacts and memory\n * @returns A status object with analysis results information\n */\nasync function processDocument(\n  params: Record&lt;string, any&gt;,\n  toolContext: ToolContext\n): Promise&lt;Record&lt;string, string | number&gt;&gt; {\n  const documentName = params.documentName as string;\n  const analysisQuery = params.analysisQuery as string;\n\n  // 1. Load the artifact\n  console.log(`Tool: Attempting to load artifact: ${documentName}`);\n  const documentPart = await toolContext.loadArtifact(documentName);\n\n  if (!documentPart) {\n    return { \n      \"status\": \"error\", \n      \"message\": `Document '${documentName}' not found.` \n    };\n  }\n\n  // Assuming it's text for simplicity\n  const documentText = documentPart.text || \"\";\n  console.log(`Tool: Loaded document '${documentName}' (${documentText.length} chars).`);\n\n  // 2. Search memory for related context\n  console.log(`Tool: Searching memory for context related to: '${analysisQuery}'`);\n  const memoryResponse = await toolContext.searchMemory(`Context for analyzing document about ${analysisQuery}`);\n\n  // Simplified extraction from memory response\n  const memoryContext = memoryResponse.memories\n    ? memoryResponse.memories\n        .filter(m =&gt; m.content &amp;&amp; m.content.parts &amp;&amp; m.content.parts.length &gt; 0)\n        .map(m =&gt; m.content.parts[0].text || \"\")\n        .join(\"\\n\")\n    : \"\";\n\n  console.log(`Tool: Found memory context: ${memoryContext.substring(0, 100)}...`);\n\n  // 3. Perform analysis (placeholder)\n  const analysisResult = `Analysis of '${documentName}' regarding '${analysisQuery}' using memory context: [Placeholder Analysis Result]`;\n  console.log(\"Tool: Performed analysis.\");\n\n  // 4. Save the analysis result as a new artifact\n  const analysisPart: Part = { text: analysisResult };\n  const newArtifactName = `analysis_${documentName}`;\n  const version = await toolContext.saveArtifact(newArtifactName, analysisPart);\n  console.log(`Tool: Saved analysis result as '${newArtifactName}' version ${version}.`);\n\n  return { \n    \"status\": \"success\", \n    \"analysis_artifact\": newArtifactName, \n    \"version\": version \n  };\n}\n\n// Create the function tool\nconst docAnalysisTool = new FunctionTool(processDocument);\n\n// Export for use in an Agent\nexport const documentAnalysisTool = docAnalysisTool;\n\n/**\n * Usage example in an Agent:\n * \n * ```typescript\n * import { Agent } from 'adk-typescript/agents';\n * import { documentAnalysisTool } from './doc-analysis';\n * \n * const myAgent = new Agent(\"analysis_agent\", {\n *   model: \"gemini-2.0-flash\",\n *   instruction: \"You can analyze documents when asked.\",\n *   tools: [documentAnalysisTool]\n * });\n * ```\n * \n * Notes:\n * - Assume artifact 'report.txt' was previously saved.\n * - Assume memory service is configured and has relevant past data.\n * - The agent must be configured with appropriate artifact and memory services.\n */ \n</code></pre> <p>By leveraging the ToolContext, developers can create more sophisticated and context-aware custom tools that seamlessly integrate with ADK's architecture and enhance the overall capabilities of their agents.</p>"},{"location":"tools/#defining-effective-tool-functions","title":"Defining Effective Tool Functions","text":"<p>When using a standard Python function as an ADK Tool, how you define it significantly impacts the agent's ability to use it correctly. The agent's Large Language Model (LLM) relies heavily on the function's name, parameters (arguments), type hints, and docstring to understand its purpose and generate the correct call.</p> <p>Here are key guidelines for defining effective tool functions:</p> <ul> <li> <p>Function Name:</p> <ul> <li>Use descriptive, verb-noun based names that clearly indicate the action (e.g., <code>get_weather</code>, <code>search_documents</code>, <code>schedule_meeting</code>).</li> <li>Avoid generic names like <code>run</code>, <code>process</code>, <code>handle_data</code>, or overly ambiguous names like <code>do_stuff</code>. Even with a good description, a name like <code>do_stuff</code> might confuse the model about when to use the tool versus, for example, <code>cancel_flight</code>.</li> <li>The LLM uses the function name as a primary identifier during tool selection.</li> </ul> </li> <li> <p>Parameters (Arguments):</p> <ul> <li>Your function can have any number of parameters.</li> <li>Use clear and descriptive names (e.g., <code>city</code> instead of <code>c</code>, <code>search_query</code> instead of <code>q</code>).</li> <li>Provide type hints for all parameters (e.g., <code>city: str</code>, <code>user_id: int</code>, <code>items: list[str]</code>). This is essential for ADK to generate the correct schema for the LLM.</li> <li>Ensure all parameter types are JSON serializable. Standard Python types like <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>list</code>, <code>dict</code>, and their combinations are generally safe. Avoid complex custom class instances as direct parameters unless they have a clear JSON representation.</li> <li>Do not set default values for parameters. E.g., <code>def my_func(param1: str = \"default\")</code>. Default values are not reliably supported or used by the underlying models during function call generation. All necessary information should be derived by the LLM from the context or explicitly requested if missing.</li> </ul> </li> <li> <p>Return Type:</p> <ul> <li>The function's return value must be a dictionary (<code>dict</code>).</li> <li>If your function returns a non-dictionary type (e.g., a string, number, list), the ADK framework will automatically wrap it into a dictionary like <code>{'result': your_original_return_value}</code> before passing the result back to the model.</li> <li>Design the dictionary keys and values to be descriptive and easily understood by the LLM. Remember, the model reads this output to decide its next step.</li> <li>Include meaningful keys. For example, instead of returning just an error code like <code>500</code>, return <code>{'status': 'error', 'error_message': 'Database connection failed'}</code>.</li> <li>It's a highly recommended practice to include a <code>status</code> key (e.g., <code>'success'</code>, <code>'error'</code>, <code>'pending'</code>, <code>'ambiguous'</code>) to clearly indicate the outcome of the tool execution for the model.</li> </ul> </li> <li> <p>Docstring:</p> <ul> <li>This is critical. The docstring is the primary source of descriptive information for the LLM.</li> <li>Clearly state what the tool does. Be specific about its purpose and limitations.</li> <li>Explain when the tool should be used. Provide context or example scenarios to guide the LLM's decision-making.</li> <li>Describe each parameter clearly. Explain what information the LLM needs to provide for that argument.</li> <li>Describe the structure and meaning of the expected <code>dict</code> return value, especially the different <code>status</code> values and associated data keys.</li> </ul> <p>Example of a good definition:</p> <pre><code>function lookup_order_status(order_id: string) -&gt; dict {\n  /** Fetches the current status of a customer's order using its ID.\n\n  Use this tool ONLY when a user explicitly asks for the status of\n  a specific order and provides the order ID. Do not use it for\n  general inquiries.\n\n  Args:\n      order_id: The unique identifier of the order to look up.\n\n  Returns:\n      A dictionary containing the order status.\n      Possible statuses: 'shipped', 'processing', 'pending', 'error'.\n      Example success: {'status': 'shipped', 'tracking_number': '1Z9...'}\n      Example error: {'status': 'error', 'error_message': 'Order ID not found.'}\n  */\n  // ... function implementation to fetch status ...\n  if (status = fetch_status_from_backend(order_id)) {\n       return {\"status\": status.state, \"tracking_number\": status.tracking} // Example structure\n  } else {\n       return {\"status\": \"error\", \"error_message\": `Order ID ${order_id} not found.`}\n  }\n}\n</code></pre> </li> <li> <p>Simplicity and Focus:</p> <ul> <li>Keep Tools Focused: Each tool should ideally perform one well-defined task.</li> <li>Fewer Parameters are Better: Models generally handle tools with fewer, clearly defined parameters more reliably than those with many optional or complex ones.</li> <li>Use Simple Data Types: Prefer basic types (<code>str</code>, <code>int</code>, <code>bool</code>, <code>float</code>, <code>List[str]</code>, etc.) over complex custom classes or deeply nested structures as parameters when possible.</li> <li>Decompose Complex Tasks: Break down functions that perform multiple distinct logical steps into smaller, more focused tools. For instance, instead of a single <code>update_user_profile(profile: ProfileObject)</code> tool, consider separate tools like <code>update_user_name(name: str)</code>, <code>update_user_address(address: str)</code>, <code>update_user_preferences(preferences: list[str])</code>, etc. This makes it easier for the LLM to select and use the correct capability.</li> </ul> </li> </ul> <p>By adhering to these guidelines, you provide the LLM with the clarity and structure it needs to effectively utilize your custom function tools, leading to more capable and reliable agent behavior.</p>"},{"location":"tools/authentication/","title":"Authenticating with Tools","text":""},{"location":"tools/authentication/#core-concepts","title":"Core Concepts","text":"<p>Many tools need to access protected resources (like user data in Google Calendar, Salesforce records, etc.) and require authentication. ADK provides a system to handle various authentication methods securely.</p> <p>The key components involved are:</p> <ol> <li><code>AuthScheme</code>: Defines how an API expects authentication credentials (e.g., as an API Key in a header, an OAuth 2.0 Bearer token). ADK supports the same types of authentication schemes as OpenAPI 3.0. To know more about what each type of credential is, refer to OpenAPI doc: Authentication. ADK uses classes like <code>ApiKeyAuthScheme</code>, <code>BearerAuthScheme</code>, and interfaces like <code>OpenIdConnectWithConfig</code>.  </li> <li><code>AuthCredential</code>: Holds the initial information needed to start the authentication process (e.g., your application's OAuth Client ID/Secret, an API key value). It includes an <code>authType</code> property (like <code>API_KEY</code>, <code>OAUTH2</code>, <code>SERVICE_ACCOUNT</code>) specifying the credential type.</li> </ol> <p>The general flow involves providing these details when configuring a tool. ADK then attempts to automatically exchange the initial credential for a usable one (like an access token) before the tool makes an API call. For flows requiring user interaction (like OAuth consent), a specific interactive process involving the Agent Client application is triggered.</p>"},{"location":"tools/authentication/#supported-initial-credential-types","title":"Supported Initial Credential Types","text":"<ul> <li>API_KEY: For simple key/value authentication. Usually requires no exchange.  </li> <li>HTTP: Can represent Basic Auth (not recommended/supported for exchange) or already obtained Bearer tokens. If it's a Bearer token, no exchange is needed.  </li> <li>OAUTH2: For standard OAuth 2.0 flows. Requires configuration (client ID, secret, scopes) and often triggers the interactive flow for user consent.  </li> <li>OPEN_ID_CONNECT: For authentication based on OpenID Connect. Similar to OAuth2, often requires configuration and user interaction.  </li> <li>SERVICE_ACCOUNT: For Google Cloud Service Account credentials (JSON key or Application Default Credentials). Typically exchanged for a Bearer token.</li> </ul>"},{"location":"tools/authentication/#configuring-authentication-on-tools","title":"Configuring Authentication on Tools","text":"<p>You set up authentication when defining your tool:</p> <ul> <li> <p>RestApiTool / OpenAPIToolset: Pass <code>authScheme</code> and <code>authCredential</code> during initialization</p> </li> <li> <p>GoogleApiToolSet Tools: ADK has built-in 1st party tools like Google Calendar, BigQuery etc. Use the toolset's specific configuration method.</p> </li> <li> <p>APIHubToolset / ApplicationIntegrationToolset: Pass <code>authScheme</code> and <code>authCredential</code> during initialization, if the API managed in API Hub / provided by Application Integration requires authentication.</p> </li> </ul> <p>WARNING</p> <p>Storing sensitive credentials like access tokens and especially refresh tokens directly in the session state might pose security risks depending on your session storage backend (<code>SessionService</code>) and overall application security posture.</p> <ul> <li><code>InMemorySessionService</code>: Suitable for testing and development, but data is lost when the process ends. Less risk as it's transient.</li> <li>Database/Persistent Storage: Strongly consider encrypting the token data before storing it in the database using a robust encryption library and managing encryption keys securely (e.g., using a key management service).</li> <li>Secure Secret Stores: For production environments, storing sensitive credentials in a dedicated secret manager (like Google Cloud Secret Manager or HashiCorp Vault) is the most recommended approach. Your tool could potentially store only short-lived access tokens or secure references (not the refresh token itself) in the session state, fetching the necessary secrets from the secure store when needed.</li> </ul>"},{"location":"tools/authentication/#journey-1-building-agentic-applications-with-authenticated-tools","title":"Journey 1: Building Agentic Applications with Authenticated Tools","text":"<p>This section focuses on using pre-existing tools (like those from <code>RestApiTool/ OpenAPIToolset</code>, <code>APIHubToolset</code>, <code>GoogleApiToolSet</code>) that require authentication within your agentic application. Your main responsibility is configuring the tools and handling the client-side part of interactive authentication flows (if required by the tool).</p>"},{"location":"tools/authentication/#1-configuring-tools-with-authentication","title":"1. Configuring Tools with Authentication","text":"<p>When adding an authenticated tool to your agent, you need to provide its required <code>AuthScheme</code> and your application's initial <code>AuthCredential</code>.</p> <p>A. Using OpenAPI-based Toolsets (<code>OpenAPIToolset</code>, <code>APIHubToolset</code>, etc.)</p> <p>Pass the scheme and credential during toolset initialization. The toolset applies them to all generated tools. Here are few ways to create tools with authentication in ADK.</p> API KeyOAuth2Service AccountOpenID Connect <p>Create a tool requiring an API Key.</p> <pre><code>import { APIHubToolset } from 'adk-typescript';\n\n// Creating an API Key auth scheme\nconst authScheme = {\n  type: 'apiKey',\n  name: 'apikey',\n  in: 'query'\n};\n\n// Creating the credential with the actual API key\nconst authCredential = {\n  authType: 'API_KEY',\n  apiKey: {\n    apiKey: 'YOUR_API_KEY_STRING'\n  }\n};\n\n// Create the toolset with authentication\nconst sampleApiToolset = new APIHubToolset({\n  name: 'sample-api-requiring-api-key',\n  description: 'A tool using an API protected by API Key',\n  apihubResourceName: '...',\n  authScheme: authScheme,\n  authCredential: authCredential\n});\n</code></pre> <p>Create a tool requiring OAuth2.</p> <pre><code>import { \n  OpenAPIToolset, \n  AuthCredential, \n  AuthCredentialTypes, \n  OAuth2Auth \n} from 'adk-typescript';\n\n// Define the OAuth2 auth scheme with flow configuration\nconst authScheme = {\n  type: 'oauth2',\n  flows: {\n    authorizationCode: {\n      authorizationUrl: 'https://accounts.google.com/o/oauth2/auth',\n      tokenUrl: 'https://oauth2.googleapis.com/token',\n      scopes: {\n        'https://www.googleapis.com/auth/calendar': 'calendar scope'\n      }\n    }\n  }\n};\n\n// Define the initial OAuth2 credentials (client ID and secret)\nconst authCredential = {\n  authType: AuthCredentialTypes.OAUTH2,\n  oauth2: {\n    clientId: 'YOUR_OAUTH_CLIENT_ID',\n    clientSecret: 'YOUR_OAUTH_CLIENT_SECRET'\n  }\n};\n\n// Create the OpenAPI toolset with OAuth2 authentication\nconst calendarApiToolset = new OpenAPIToolset({\n  specStr: googleCalendarOpenApiSpecStr, // Fill this with an OpenAPI spec\n  specStrType: 'yaml',\n  authScheme: authScheme,\n  authCredential: authCredential\n});\n</code></pre> <p>Create a tool requiring Google Service Account.</p> <pre><code>import { \n  OpenAPIToolset, \n  AuthCredential, \n  AuthCredentialTypes \n} from 'adk-typescript';\n\n// Parse the service account JSON key file\nconst serviceAccountCred = JSON.parse(serviceAccountJsonStr);\n\n// Define the auth scheme for service account authentication\nconst authScheme = {\n  type: 'http',\n  scheme: 'bearer'\n};\n\n// Configure the service account credential\nconst authCredential = {\n  authType: AuthCredentialTypes.SERVICE_ACCOUNT,\n  serviceAccount: {\n    credentials: serviceAccountCred,\n    scopes: ['https://www.googleapis.com/auth/cloud-platform']\n  }\n};\n\n// Create the OpenAPI toolset with service account authentication\nconst sampleToolset = new OpenAPIToolset({\n  specStr: serviceAccountOpenApiSpecStr, // Fill this with an OpenAPI spec\n  specStrType: 'json',\n  authScheme: authScheme,\n  authCredential: authCredential\n});\n</code></pre> <p>Create a tool requiring OpenID Connect.</p> <pre><code>import { \n  OpenAPIToolset, \n  OpenIdConnectWithConfig,\n  AuthCredential, \n  AuthCredentialTypes \n} from 'adk-typescript';\n\n// Define the OpenID Connect auth scheme\nconst authScheme = {\n  type: 'openIdConnect',\n  authorization_endpoint: 'https://your-endpoint.okta.com/oauth2/v1/authorize',\n  token_endpoint: 'https://your-endpoint.okta.com/oauth2/v1/token',\n  scopes: ['openid', 'email', 'profile']\n};\n\n// Configure the OAuth2 credentials for OpenID Connect\nconst authCredential = {\n  authType: AuthCredentialTypes.OPEN_ID_CONNECT,\n  oauth2: {\n    clientId: 'YOUR_CLIENT_ID',\n    clientSecret: 'YOUR_CLIENT_SECRET'\n  }\n};\n\n// Create the OpenAPI toolset with OpenID Connect authentication\nconst userinfoToolset = new OpenAPIToolset({\n  specStr: oidcSpecContent, // Fill with an actual OpenAPI spec\n  specStrType: 'yaml',\n  authScheme: authScheme,\n  authCredential: authCredential\n});\n</code></pre> <p>B. Using Google API Toolsets (e.g., <code>calendar_tool_set</code>)</p> <p>These toolsets often have dedicated configuration methods.</p> <p>Tip: For how to create a Google OAuth Client ID &amp; Secret, see this guide: Get your Google API Client ID</p> <pre><code>// Example: Configuring Google Calendar Tools\nimport { GoogleApiToolSet } from 'adk-typescript';\n\nconst clientId = 'YOUR_GOOGLE_OAUTH_CLIENT_ID.apps.googleusercontent.com';\nconst clientSecret = 'YOUR_GOOGLE_OAUTH_CLIENT_SECRET';\n\n// Initialize calendar tools with OAuth2 authentication\nconst calendarTools = GoogleApiToolSet.calendarTools({\n  authConfig: {\n    clientId: clientId,\n    clientSecret: clientSecret\n  }\n});\n\n// Add the tools to your agent\n// agent = new LlmAgent(..., tools: calendarTools.getTools());\n</code></pre> <p>The sequence diagram of auth request flow (where tools are requesting auth credentials) looks like below:</p> <p> </p>"},{"location":"tools/authentication/#2-handling-the-interactive-oauthoidc-flow-client-side","title":"2. Handling the Interactive OAuth/OIDC Flow (Client-Side)","text":"<p>If a tool requires user login/consent (typically OAuth 2.0 or OIDC), the ADK framework pauses execution and signals your Agent Client application. There are two cases:</p> <ul> <li>Agent Client application runs the agent directly (via <code>runner.run()</code> or <code>runner.runAsync()</code>) in the same process. e.g. UI backend, CLI app, or Spark job etc.</li> <li>Agent Client application interacts with ADK's Express server via <code>/run</code> or <code>/run_sse</code> endpoint. While ADK's Express server could be setup on the same server or different server as Agent Client application</li> </ul> <p>The second case is a special case of first case, because <code>/run</code> or <code>/run_sse</code> endpoint also invokes <code>runner.runAsync()</code>. The only differences are:</p> <ul> <li>Whether to call a TypeScript function to run the agent (first case) or call a service endpoint to run the agent (second case).</li> <li>Whether the result events are in-memory objects (first case) or serialized JSON string in HTTP response (second case).</li> </ul> <p>Below sections focus on the first case and you should be able to map it to the second case very straightforward. We will also describe some differences to handle for the second case if necessary.</p> <p>Here's the step-by-step process for your client application:</p> <p>Step 1: Run Agent &amp; Detect Auth Request</p> <ul> <li>Initiate the agent interaction using <code>runner.runAsync()</code>.</li> <li>Iterate through the yielded events.</li> <li>Look for a specific event that contains a function call with a special name: <code>adk_request_credential</code>. This event signals that user interaction is needed. You can use helper functions to identify this event and extract necessary information.</li> </ul> <pre><code>import { Runner, Session, Event, Content, isPendingAuthEvent } from 'adk-typescript';\n\n// runner = new Runner(...);\n// session = await sessionService.createSession(...);\n// content = new Content(...); // User's initial query\n\nconsole.log(\"\\nRunning agent...\");\nconst eventsAsync = runner.runAsync({\n  sessionId: session.id,\n  userId: 'user',\n  newMessage: content\n});\n\nlet authRequestFunctionCallId: string | undefined;\nlet authConfig: any | undefined;\n\n// Iterate through events asynchronously\nfor await (const event of eventsAsync) {\n  // Check if this is an auth request event\n  if (isPendingAuthEvent(event)) {\n    console.log(\"--&gt; Authentication required by agent.\");\n\n    // Get the function call from the event (implementation depends on your event structure)\n    const functionCall = event.content?.parts?.[0]?.functionCall;\n\n    if (!functionCall || !functionCall.id) {\n      throw new Error('Cannot get function call ID from auth request event');\n    }\n\n    // Store the ID needed to respond later\n    authRequestFunctionCallId = functionCall.id;\n\n    // Get the AuthConfig from the function call arguments\n    authConfig = functionCall.args?.auth_config;\n\n    break; // Stop processing events, need user interaction\n  }\n}\n\nif (!authRequestFunctionCallId) {\n  console.log(\"\\nAuth not required or agent finished.\");\n  // return or handle final response\n}\n</code></pre> <p>Step 2: Redirect User for Authorization</p> <ul> <li>Get the authorization URL (<code>auth_uri</code>) from the <code>authConfig</code> extracted in the previous step.</li> <li>Crucially, append your application's redirect_uri as a query parameter to this <code>auth_uri</code>. This <code>redirect_uri</code> must be pre-registered with your OAuth provider (e.g., Google Cloud Console, Okta admin panel).</li> <li>Direct the user to this complete URL (e.g., open it in their browser).</li> </ul> <pre><code>// (Continuing after detecting auth needed)\n\nif (authRequestFunctionCallId &amp;&amp; authConfig) {\n  // Get the base authorization URL from the AuthConfig\n  const baseAuthUri = authConfig.exchanged_auth_credential?.oauth2?.auth_uri;\n\n  if (baseAuthUri) {\n    const redirectUri = 'http://localhost:8000/callback'; // MUST match your OAuth client app config\n\n    // Append redirect_uri (use URLSearchParams in production for proper encoding)\n    const authRequestUri = baseAuthUri + `&amp;redirect_uri=${encodeURIComponent(redirectUri)}`;\n\n    console.log(`\\nPlease open this URL in your browser to authorize the application:\\n${authRequestUri}`);\n\n    // In a web app, you would redirect the user to this URL:\n    // window.location.href = authRequestUri;\n\n    // Note: The auth provider will ask the user to log in and authorize your application\n    // Then redirect back to your redirect_uri with an authorization code\n  } else {\n    console.error(\"ERROR: Auth URI not found in authConfig.\");\n    // Handle error\n  }\n}\n</code></pre> <p>Step 3. Handle the Redirect Callback (Client):</p> <ul> <li>Your application must have a mechanism (e.g., a web server route at the <code>redirect_uri</code>) to receive the user after they authorize the application with the provider.</li> <li>The provider redirects the user to your <code>redirect_uri</code> and appends an <code>authorization_code</code> (and potentially <code>state</code>, <code>scope</code>) as query parameters to the URL.</li> <li>Capture the full callback URL from this incoming request.</li> <li>(This step happens outside the main agent execution loop, in your web server or equivalent callback handler.)</li> </ul> <p>Here's an example using Express:</p> <pre><code>import express from 'express';\n\nconst app = express();\nconst port = 8000;\n\n// This route handles the OAuth callback\napp.get('/callback', (req, res) =&gt; {\n  // Get the full URL including query parameters (authorization code)\n  const fullCallbackUrl = `${req.protocol}://${req.get('host')}${req.originalUrl}`;\n\n  // Display for manual copy-paste in CLI apps\n  res.send(`\n    &lt;html&gt;\n      &lt;body&gt;\n        &lt;h1&gt;Authorization Successful&lt;/h1&gt;\n        &lt;p&gt;Please copy this URL and paste it back in your application:&lt;/p&gt;\n        &lt;textarea rows=\"3\" cols=\"100\" onclick=\"this.select()\"&gt;${fullCallbackUrl}&lt;/textarea&gt;\n      &lt;/body&gt;\n    &lt;/html&gt;\n  `);\n\n  // In a web app, you might store the URL in a session or database\n  // and redirect back to your main application automatically\n});\n\napp.listen(port, () =&gt; {\n  console.log(`Auth callback server listening on port ${port}`);\n});\n</code></pre> <p>Step 4. Send Authentication Result Back to ADK (Client):</p> <ul> <li>Once you have the full callback URL (containing the authorization code), retrieve the <code>authRequestFunctionCallId</code> and the <code>authConfig</code> object saved in Client Step 1.</li> <li>Set the captured callback URL into the <code>exchanged_auth_credential.oauth2.auth_response_uri</code> field. Also ensure <code>exchanged_auth_credential.oauth2.redirect_uri</code> contains the redirect URI you used.</li> <li>Create a <code>Content</code> object containing a <code>Part</code> with a <code>FunctionResponse</code>.</li> <li>Set <code>name</code> to <code>\"adk_request_credential\"</code>. (Note: This is a special name for ADK to proceed with authentication. Do not use other names.)</li> <li>Set <code>id</code> to the <code>authRequestFunctionCallId</code> you saved.</li> <li>Set <code>response</code> to the serialized (e.g., <code>.stringify()</code> or <code>.toJSON()</code>) updated <code>authConfig</code> object.</li> <li>Call <code>runner.runAsync()</code> again for the same session, passing this <code>FunctionResponse</code> content as the <code>newMessage</code>.</li> </ul> <pre><code>import { Content, Part, FunctionResponse, getUserInput } from 'adk-typescript';\n\n// (Continuing after user has authorized and been redirected)\n\n// Get the callback URL - in a CLI app, prompt the user to paste it\n// In a web app, you might retrieve it from a session or temporary storage\nasync function handleAuthCallback() {\n  // Simulate getting the callback URL (e.g., from user paste or web handler)\n  const authResponseUri = await getUserInput('Paste the full callback URL here:\\n&gt; ');\n\n  if (!authResponseUri || authResponseUri.trim() === '') {\n    console.log(\"Callback URL not provided. Aborting.\");\n    return;\n  }\n\n  // Update the received AuthConfig with the callback details\n  authConfig.exchanged_auth_credential.oauth2.auth_response_uri = authResponseUri.trim();\n  // Also include the redirect_uri used, as the token exchange might need it\n  authConfig.exchanged_auth_credential.oauth2.redirect_uri = redirectUri;\n\n  // Construct the FunctionResponse Content object\n  const authContent = new Content({\n    role: 'user', // Role must be 'user' when sending a FunctionResponse\n    parts: [\n      new Part({\n        functionResponse: new FunctionResponse({\n          id: authRequestFunctionCallId,       // Link to the original request\n          name: 'adk_request_credential',      // Special framework function name\n          response: JSON.stringify(authConfig) // Send back the *updated* AuthConfig\n        })\n      })\n    ]\n  });\n\n  // --- Resume Execution ---\n  console.log(\"\\nSubmitting authentication details back to the agent...\");\n  const eventsAsyncAfterAuth = runner.runAsync({\n    sessionId: session.id,\n    userId: 'user',\n    newMessage: authContent // Send the FunctionResponse back\n  });\n\n  // --- Process Final Agent Output ---\n  console.log(\"\\n--- Agent Response after Authentication ---\");\n  for await (const event of eventsAsyncAfterAuth) {\n    // Process events normally, expecting the tool call to succeed now\n    console.log(event); // Print the full event for inspection\n  }\n}\n\n// Call the function to handle the callback\nhandleAuthCallback();\n</code></pre> <p>Step 5: ADK Handles Token Exchange &amp; Tool Retry and gets Tool result</p> <ul> <li>ADK receives the <code>FunctionResponse</code> for <code>adk_request_credential</code>.</li> <li>It uses the information in the updated <code>authConfig</code> (including the callback URL containing the code) to perform the OAuth token exchange with the provider's token endpoint, obtaining the access token (and possibly refresh token).</li> <li>ADK internally makes these tokens available by setting them in the session state).</li> <li>ADK automatically retries the original tool call (the one that initially failed due to missing auth).</li> <li>This time, the tool finds the valid tokens (via <code>toolContext.getAuthResponse()</code>) and successfully executes the authenticated API call.</li> <li>The agent receives the actual result from the tool and generates its final response to the user.</li> </ul> <p>The sequence diagram of auth response flow (where Agent Client sends back the auth response and ADK retries tool calling) looks like below:</p> <p></p>"},{"location":"tools/authentication/#journey-2-building-custom-tools-functiontool-requiring-authentication","title":"Journey 2: Building Custom Tools (<code>FunctionTool</code>) Requiring Authentication","text":"<p>This section focuses on implementing the authentication logic inside your custom TypeScript function when creating a new ADK Tool. We will implement a <code>FunctionTool</code> as an example.</p>"},{"location":"tools/authentication/#prerequisites","title":"Prerequisites","text":"<p>Your function signature must include <code>toolContext: ToolContext</code>. ADK automatically injects this object, providing access to state and auth mechanisms.</p> <pre><code>import { FunctionTool, ToolContext } from 'adk-typescript';\n\nfunction myAuthenticatedToolFunction(\n  param1: string, \n  ..., \n  toolContext: ToolContext\n): Record&lt;string, any&gt; {\n  // ... your logic ...\n}\n\nconst myTool = new FunctionTool({\n  func: myAuthenticatedToolFunction\n});\n</code></pre>"},{"location":"tools/authentication/#authentication-logic-within-the-tool-function","title":"Authentication Logic within the Tool Function","text":"<p>Implement the following steps inside your function:</p> <p>Step 1: Check for Cached &amp; Valid Credentials:</p> <p>Inside your tool function, first check if valid credentials (e.g., access/refresh tokens) are already stored from a previous run in this session. Credentials for the current sessions should be stored in <code>toolContext.state</code> (a dictionary of state). Check existence of existing credentials using <code>toolContext.state.get(credentialName)</code>.</p> <pre><code>// Inside your tool function\nconst TOKEN_CACHE_KEY = \"my_tool_tokens\"; // Choose a unique key\nconst SCOPES = [\"scope1\", \"scope2\"]; // Define required scopes\n\nlet creds = null;\nconst cachedTokenInfo = toolContext.state.get(TOKEN_CACHE_KEY);\n\nif (cachedTokenInfo) {\n  try {\n    // This example uses a hypothetical OAuth library - adapt to your OAuth library\n    creds = Credentials.fromAuthInfo(cachedTokenInfo, SCOPES);\n\n    if (!creds.valid &amp;&amp; creds.expired &amp;&amp; creds.refreshToken) {\n      // Token expired but can be refreshed\n      await creds.refresh();\n      // Update cache with refreshed tokens\n      toolContext.state.set(TOKEN_CACHE_KEY, creds.toJSON());\n    } else if (!creds.valid) {\n      // Invalid token that can't be refreshed\n      creds = null;\n      toolContext.state.set(TOKEN_CACHE_KEY, null);\n    }\n  } catch (error) {\n    console.error(\"Error loading/refreshing cached creds:\", error);\n    creds = null;\n    toolContext.state.set(TOKEN_CACHE_KEY, null);\n  }\n}\n\nif (creds &amp;&amp; creds.valid) {\n  // Skip to Step 5: Make Authenticated API Call\n  // ...\n} else {\n  // Proceed to Step 2...\n  // ...\n}\n</code></pre> <p>Step 2: Check for Auth Response from Client</p> <ul> <li>If Step 1 didn't yield valid credentials, check if the client just completed the interactive flow by calling <code>exchangedCredential = toolContext.getAuthResponse()</code>.</li> <li>This returns the updated <code>exchangedCredential</code> object sent back by the client (containing the callback URL in <code>auth_response_uri</code>).</li> </ul> <pre><code>// Use authScheme and authCredential configured in the tool\n// exchangedCredential: AuthCredential | null\n\nconst exchangedCredential = toolContext.getAuthResponse({\n  authScheme: authScheme,\n  rawAuthCredential: authCredential\n});\n\n// If exchangedCredential is not null, then there is already an exchanged credential from the auth response\nif (exchangedCredential) {\n  // ADK exchanged the access token already for us\n  const accessToken = exchangedCredential.oauth2?.accessToken;\n  const refreshToken = exchangedCredential.oauth2?.refreshToken;\n\n  // Create credentials object using your OAuth library\n  creds = new Credentials({\n    token: accessToken,\n    refreshToken: refreshToken,\n    tokenUri: authScheme.flows?.authorizationCode?.tokenUrl,\n    clientId: authCredential.oauth2?.clientId,\n    clientSecret: authCredential.oauth2?.clientSecret,\n    scopes: Object.keys(authScheme.flows?.authorizationCode?.scopes || {})\n  });\n\n  // Cache the token in session state and proceed to Step 5\n  // ...\n}\n</code></pre> <p>Step 3: Initiate Authentication Request</p> <p>If no valid credentials (Step 1) and no auth response (Step 2) are found, the tool needs to start the OAuth flow. Define the AuthScheme and initial AuthCredential and call <code>toolContext.requestCredential()</code>. Return a response indicating authorization is needed.</p> <pre><code>// Use the authScheme and authCredential configured for the tool\n\ntoolContext.requestCredential({\n  authScheme: authScheme,\n  rawAuthCredential: authCredential\n});\n\n// By calling requestCredential, ADK detects a pending authentication event.\n// It pauses execution and asks the end user to login.\nreturn {\n  pending: true, \n  message: 'Awaiting user authentication.'\n};\n</code></pre> <p>Step 4: Exchange Authorization Code for Tokens</p> <p>ADK automatically generates an OAuth authorization URL and presents it to your Agent Client application. Your Agent Client application should follow the same process described in Journey 1 to redirect the user to the authorization URL (with <code>redirect_uri</code> appended). Once a user completes the login flow following the authorization URL and ADK extracts the authentication callback URL from the Agent Client application, it automatically parses the auth code and generates an auth token. At the next Tool call, <code>toolContext.getAuthResponse</code> in Step 2 will contain a valid credential to use in subsequent API calls.</p> <p>Step 5: Cache Obtained Credentials</p> <p>After successfully obtaining the token from ADK (Step 2) or if the token is still valid (Step 1), immediately store the new <code>Credentials</code> object in <code>toolContext.state</code> (serialized, e.g., as JSON) using your cache key.</p> <pre><code>// Inside your tool function, after obtaining 'creds' (either refreshed or newly exchanged)\n// Cache the new/refreshed tokens\ntoolContext.state.set(TOKEN_CACHE_KEY, creds.toJSON());\nconsole.log(`DEBUG: Cached/updated tokens under key: ${TOKEN_CACHE_KEY}`);\n// Proceed to Step 6 (Make API Call)\n</code></pre> <p>Step 6: Make Authenticated API Call</p> <ul> <li>Once you have a valid <code>Credentials</code> object (<code>creds</code> from Step 1 or Step 4), use it to make the actual call to the protected API using the appropriate client library (e.g., Google APIs, Axios, etc.). Pass the necessary authorization headers or credentials.</li> <li>Include error handling, especially for 401/403 responses, which might mean the token expired or was revoked between calls. If you get such an error, consider clearing the cached token (<code>toolContext.state.delete(...)</code>) and potentially returning the <code>auth_required</code> status again to force re-authentication.</li> </ul> <pre><code>// Inside your tool function, using the valid 'creds' object\n// Ensure creds is valid before proceeding\nif (!creds || !creds.valid) {\n  return { \n    status: \"error\", \n    error_message: \"Cannot proceed without valid credentials.\" \n  };\n}\n\ntry {\n  // Example using an API client library\n  const service = new CalendarService(creds);\n  const apiResult = await service.events.list({ /* params */ });\n  // Proceed to Step 7\n} catch (error) {\n  // Handle API errors (e.g., check for 401/403, maybe clear cache and re-request auth)\n  console.error(\"API call failed:\", error);\n\n  // If it's an auth error, clear cached credentials\n  if (error.status === 401 || error.status === 403) {\n    toolContext.state.delete(TOKEN_CACHE_KEY);\n    // Consider re-initiating auth flow\n  }\n\n  return { \n    status: \"error\", \n    error_message: `API call failed: ${error.message}` \n  };\n}\n</code></pre> <p>Step 7: Return Tool Result</p> <ul> <li>After a successful API call, process the result into a format that is useful for the LLM.</li> <li>Include a status along with the data.</li> </ul> <pre><code>// Inside your tool function, after successful API call\nconst processedResult = [...]; // Process apiResult for the LLM\nreturn { \n  status: \"success\", \n  data: processedResult \n};\n</code></pre> Full Code Tools and AgentAgent CLIHelperSpec tools_and_agent.ts<pre><code>import * as fs from 'fs';\nimport * as path from 'path';\n\nimport { OpenIdConnectWithConfig } from 'adk-typescript/auth';\nimport { AuthCredential, AuthCredentialTypes, OAuth2Auth } from 'adk-typescript/auth';\nimport { OpenAPIToolset } from 'adk-typescript/tools';\nimport { LlmAgent } from 'adk-typescript/agents';\n\n// --- Authentication Configuration ---\n// This section configures how the agent will handle authentication using OpenID Connect (OIDC),\n// often layered on top of OAuth 2.0.\n\n// Define the Authentication Scheme using OpenID Connect.\n// This object tells the ADK *how* to perform the OIDC/OAuth2 flow.\n// It requires details specific to your Identity Provider (IDP), like Google OAuth, Okta, Auth0, etc.\n// Note: Replace the example Okta URLs and credentials with your actual IDP details.\n// All following fields are required, and available from your IDP.\nconst authScheme = new OpenIdConnectWithConfig({\n  // The URL of the IDP's authorization endpoint where the user is redirected to log in.\n  authorizationEndpoint: \"https://your-endpoint.okta.com/oauth2/v1/authorize\",\n  // The URL of the IDP's token endpoint where the authorization code is exchanged for tokens.\n  tokenEndpoint: \"https://your-token-endpoint.okta.com/oauth2/v1/token\",\n  // The scopes (permissions) your application requests from the IDP.\n  // 'openid' is standard for OIDC. 'profile' and 'email' request user profile info.\n  scopes: ['openid', 'profile', \"email\"]\n});\n\n// Define the Authentication Credentials for your specific application.\n// This object holds the client identifier and secret that your application uses\n// to identify itself to the IDP during the OAuth2 flow.\n// !! SECURITY WARNING: Avoid hardcoding secrets in production code. !!\n// !! Use environment variables or a secret management system instead. !!\nconst authCredential = new AuthCredential({\n  authType: AuthCredentialTypes.OPEN_ID_CONNECT,\n  oauth2: new OAuth2Auth({\n    clientId: \"CLIENT_ID\",\n    clientSecret: \"CIENT_SECRET\"\n  })\n});\n\n// --- Toolset Configuration from OpenAPI Specification ---\n// This section defines a sample set of tools the agent can use, configured with Authentication\n// from steps above.\n// This sample set of tools use endpoints protected by Okta and requires an OpenID Connect flow\n// to acquire end user credentials.\n\n// Helper function to read the specification file\nfunction readSpecFile(): string {\n  const specFilePath = path.join(__dirname, 'spec.yaml');\n  return fs.readFileSync(specFilePath, 'utf8');\n}\n\nconst specContent = readSpecFile();\n\nconst userinfoToolset = new OpenAPIToolset({\n  specStr: specContent,\n  specStrType: 'yaml',\n  // ** Crucially, associate the authentication scheme and credentials with these tools. **\n  // This tells the ADK that the tools require the defined OIDC/OAuth2 flow.\n  authScheme: authScheme,\n  authCredential: authCredential\n});\n\n// --- Agent Configuration ---\n// Configure and create the main LLM Agent.\nconst rootAgent = new LlmAgent({\n  name: \"enterprise_assistant\",\n  model: 'gemini-2.0-flash',\n  instruction: 'Help user integrate with multiple enterprise systems, including retrieving user information which may require authentication.',\n  tools: await userinfoToolset.getTools()\n});\n\n// --- Ready for Use ---\n// The `rootAgent` is now configured with tools protected by OIDC/OAuth2 authentication.\n// When the agent attempts to use one of these tools, the ADK framework will automatically\n// trigger the authentication flow defined by `authScheme` and `authCredential`\n// if valid credentials are not already available in the session.\n// The subsequent interaction flow would guide the user through the login process and handle\n// token exchanging, and automatically attach the exchanged token to the endpoint defined in\n// the tool.\n\n// Export the agent for use in other modules\nexport const agent = rootAgent; \n</code></pre> agent_cli.ts<pre><code>import dotenv from 'dotenv';\nimport { runners } from 'adk-typescript';\nimport { Content, Part } from 'adk-typescript/types';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { InMemoryArtifactService } from 'adk-typescript/artifacts';\nimport { AuthConfig } from 'adk-typescript/auth';\n\nimport { \n  isPendingAuthEvent, \n  getFunctionCallId, \n  getFunctionCallAuthConfig,\n  getUserInput \n} from './helpers';\n\nimport { agent } from './ToolsAndAgent';\n\n// Load environment variables from .env file\ndotenv.config();\n\n/**\n * Interface for Function Response in ADK\n */\ninterface FunctionResponse {\n  id: string;\n  name: string;\n  response: any;\n}\n\n/**\n * Main asynchronous function orchestrating the agent interaction and authentication flow.\n */\nasync function asyncMain(): Promise&lt;void&gt; {\n  // --- Step 1: Service Initialization ---\n  // Use in-memory services for session and artifact storage (suitable for demos/testing).\n  const sessionService = new InMemorySessionService();\n  const artifactsService = new InMemoryArtifactService();\n\n  // Create a new user session to maintain conversation state.\n  const session = sessionService.createSession({\n    state: {},  // Optional state dictionary for session-specific data\n    appName: 'my_app', // Application identifier\n    userId: 'user' // User identifier\n  });\n\n  // --- Step 2: Initial User Query ---\n  // Define the user's initial request.\n  const query = 'Show me my user info';\n  console.log(`user: ${query}`);\n\n  // Format the query into the Content structure expected by the ADK Runner.\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Initialize the ADK Runner\n  const runner = new runners.Runner({\n    appName: 'my_app',\n    agent: agent,\n    artifactService: artifactsService,\n    sessionService: sessionService\n  });\n\n  // --- Step 3: Send Query and Handle Potential Auth Request ---\n  console.log(\"\\nRunning agent with initial query...\");\n\n  // Variables to store details if an authentication request occurs.\n  let authRequestEventId: string | null = null;\n  let authConfig: AuthConfig | null = null;\n\n  try {\n    const session = await sessionService.createSession({\n      state: {},  // Optional state dictionary for session-specific data\n      appName: 'my_app', // Application identifier\n      userId: 'user' // User identifier\n    });\n    const events = runner.run({\n      sessionId: session.id,\n      userId: 'user',\n      newMessage: content\n    });\n\n    // Iterate through the events generated by the first run.\n    for await (const event of events) {\n      // Check if this event is the specific 'adk_request_credential' function call.\n      if (isPendingAuthEvent(event)) {\n        console.log(\"--&gt; Authentication required by agent.\");\n        authRequestEventId = getFunctionCallId(event);\n        authConfig = getFunctionCallAuthConfig(event);\n        // Once the auth request is found and processed, exit this loop.\n        // We need to pause execution here to get user input for authentication.\n        break;\n      }\n    }\n\n    // If no authentication request was detected after processing all events, exit.\n    if (!authRequestEventId || !authConfig) {\n      console.log(\"\\nAuthentication not required for this query or processing finished.\");\n      return; // Exit the main function\n    }\n\n    // --- Step 4: Manual Authentication Step (Simulated OAuth 2.0 Flow) ---\n    // This section simulates the user interaction part of an OAuth 2.0 flow.\n    // In a real web application, this would involve browser redirects.\n\n    // Define the Redirect URI. This *must* match one of the URIs registered\n    // with the OAuth provider for your application. The provider sends the user\n    // back here after they approve the request.\n    const redirectUri = 'http://localhost:8000/dev-ui'; // Example for local development\n\n    // Construct the Authorization URL that the user must visit.\n    // This typically includes the provider's authorization endpoint URL,\n    // client ID, requested scopes, response type (e.g., 'code'), and the redirect URI.\n    // Here, we retrieve the base authorization URI from the AuthConfig provided by ADK\n    // and append the redirect_uri.\n    // NOTE: A robust implementation would use urlencode and potentially add state, scope, etc.\n    const authRequestUri = (\n      authConfig.exchangedAuthCredential?.oauth2?.auth_uri +\n      `&amp;redirect_uri=${redirectUri}` // Simple concatenation; ensure correct query param format\n    );\n\n    console.log(\"\\n--- User Action Required ---\");\n    // Prompt the user to visit the authorization URL, log in, grant permissions,\n    // and then paste the *full* URL they are redirected back to (which contains the auth code).\n    const authResponseUri = await getUserInput(\n      `1. Please open this URL in your browser to log in:\\n   ${authRequestUri}\\n\\n` +\n      `2. After successful login and authorization, your browser will be redirected.\\n` +\n      `   Copy the *entire* URL from the browser's address bar.\\n\\n` +\n      `3. Paste the copied URL here and press Enter:\\n\\n&gt; `\n    );\n\n    // --- Step 5: Prepare Authentication Response for the Agent ---\n    // Update the AuthConfig object with the information gathered from the user.\n    // The ADK framework needs the full response URI (containing the code)\n    // and the original redirect URI to complete the OAuth token exchange process internally.\n    if (authConfig.exchangedAuthCredential?.oauth2) {\n      authConfig.exchangedAuthCredential.oauth2.auth_response_uri = authResponseUri;\n      authConfig.exchangedAuthCredential.oauth2.redirect_uri = redirectUri;\n    }\n\n    // Construct a FunctionResponse Content object to send back to the agent/runner.\n    // This response explicitly targets the 'adk_request_credential' function call\n    // identified earlier by its ID.\n    const authContent: Content = {\n      role: 'user',\n      parts: [\n        {\n          functionResponse: {\n            // Crucially, link this response to the original request using the saved ID.\n            id: authRequestEventId,\n            // The special name of the function call we are responding to.\n            name: 'adk_request_credential',\n            // The payload containing all necessary authentication details.\n            response: authConfig\n          } as FunctionResponse\n        } as Part\n      ]\n    };\n\n    // --- Step 6: Resume Execution with Authentication ---\n    console.log(\"\\nSubmitting authentication details back to the agent...\");\n    // Run the agent again, this time providing the `authContent` (FunctionResponse).\n    // The ADK Runner intercepts this, processes the 'adk_request_credential' response\n    // (performs token exchange, stores credentials), and then allows the agent\n    // to retry the original tool call that required authentication, now succeeding with\n    // a valid access token embedded.\n    const authEvents = runner.run({\n      sessionId: session.id,\n      userId: 'user',\n      newMessage: authContent // Provide the prepared auth response\n    });\n\n    // Process and print the final events from the agent after authentication is complete.\n    // This stream now contain the actual result from the tool (e.g., the user info).\n    console.log(\"\\n--- Agent Response after Authentication ---\");\n    for await (const event of authEvents) {\n      console.log(event);\n    }\n  } catch (error) {\n    console.error(`Error in main function: ${error}`);\n  }\n}\n\n// Execute the main function if this module is run directly\nif (require.main === module) {\n  asyncMain().catch(error =&gt; {\n    console.error(`Unhandled error in main: ${error}`);\n  });\n}\n\n// Export for external use\nexport { asyncMain as runAuthenticatedDemo }; \n</code></pre> helpers.ts<pre><code>\n</code></pre> <pre><code>openapi: 3.0.1\ninfo:\n  title: Okta User Info API\n  version: 1.0.0\n  description: |-\n    API to retrieve user profile information based on a valid Okta OIDC Access Token.\n    Authentication is handled via OpenID Connect with Okta.\n  contact:\n    name: API Support\n    email: support@example.com # Replace with actual contact if available\nservers:\n- url: &lt;substitute with your server name&gt;\n  description: Production Environment\npaths:\n  /okta-jwt-user-api:\n    get:\n      summary: Get Authenticated User Info\n      description: |-\n        Fetches profile details for the user\n      operationId: getUserInfo\n      tags:\n      - User Profile\n      security:\n      - okta_oidc:\n          - openid\n          - email\n          - profile\n      responses:\n        '200':\n          description: Successfully retrieved user information.\n          content:\n            application/json:\n              schema:\n                type: object\n                properties:\n                  sub:\n                    type: string\n                    description: Subject identifier for the user.\n                    example: \"abcdefg\"\n                  name:\n                    type: string\n                    description: Full name of the user.\n                    example: \"Example LastName\"\n                  locale:\n                    type: string\n                    description: User's locale, e.g., en-US or en_US.\n                    example: \"en_US\"\n                  email:\n                    type: string\n                    format: email\n                    description: User's primary email address.\n                    example: \"username@example.com\"\n                  preferred_username:\n                    type: string\n                    description: Preferred username of the user (often the email).\n                    example: \"username@example.com\"\n                  given_name:\n                    type: string\n                    description: Given name (first name) of the user.\n                    example: \"Example\"\n                  family_name:\n                    type: string\n                    description: Family name (last name) of the user.\n                    example: \"LastName\"\n                  zoneinfo:\n                    type: string\n                    description: User's timezone, e.g., America/Los_Angeles.\n                    example: \"America/Los_Angeles\"\n                  updated_at:\n                    type: integer\n                    format: int64 # Using int64 for Unix timestamp\n                    description: Timestamp when the user's profile was last updated (Unix epoch time).\n                    example: 1743617719\n                  email_verified:\n                    type: boolean\n                    description: Indicates if the user's email address has been verified.\n                    example: true\n                required:\n                - sub\n                - name\n                - locale\n                - email\n                - preferred_username\n                - given_name\n                - family_name\n                - zoneinfo\n                - updated_at\n                - email_verified\n        '401':\n          description: Unauthorized. The provided Bearer token is missing, invalid, or expired.\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Error'\n        '403':\n          description: Forbidden. The provided token does not have the required scopes or permissions to access this resource.\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Error'\ncomponents:\n  securitySchemes:\n    okta_oidc:\n      type: openIdConnect\n      description: Authentication via Okta using OpenID Connect. Requires a Bearer Access Token.\n      openIdConnectUrl: https://your-endpoint.okta.com/.well-known/openid-configuration\n  schemas:\n    Error:\n      type: object\n      properties:\n        code:\n          type: string\n          description: An error code.\n        message:\n          type: string\n          description: A human-readable error message.\n      required:\n        - code\n        - message\n</code></pre>"},{"location":"tools/built-in-tools/","title":"Built-in tools","text":"<p>These built-in tools provide ready-to-use functionality such as Google Search or code executors that provide agents with common capabilities. For instance, an agent that needs to retrieve information from the web can directly use the googleSearch tool without any additional setup.</p>"},{"location":"tools/built-in-tools/#how-to-use","title":"How to Use","text":"<ol> <li>Import: Import the desired tool from the <code>adk-typescript</code> library.</li> <li>Configure: Initialize the tool, providing required parameters if any.</li> <li>Register: Add the initialized tool to the tools list of your Agent.</li> </ol> <p>Once added to an agent, the agent can decide to use the tool based on the user prompt and its instructions. The framework handles the execution of the tool when the agent calls it.</p>"},{"location":"tools/built-in-tools/#available-built-in-tools","title":"Available Built-in tools","text":""},{"location":"tools/built-in-tools/#google-search","title":"Google Search","text":"<p>The <code>googleSearch</code> tool allows the agent to perform web searches using Google Search. It is compatible with Gemini 2 models, and you can add this tool to the agent's tools list.</p> <pre><code>import { \n  Agent, \n  googleSearch, \n  Runner, \n  InMemorySessionService \n} from 'adk-typescript';\n\n// Create an agent with Google Search capability\nconst agent = new Agent({\n  name: \"search_agent\",\n  model: \"gemini-2.0-flash\",\n  description: \"I can search the web for information.\",\n  instruction: \"Use googleSearch to find information when asked.\",\n  tools: [googleSearch] // Add the built-in Google Search tool\n});\n\n// Set up session service and runner\nconst sessionService = new InMemorySessionService();\n\nasync function main() {\n  // Create a new session\n  const session = await sessionService.createSession({ \n    appName: \"search_example\",\n    userId: \"user123\" \n  });\n\n  // Create runner\n  const runner = new Runner({\n    appName: \"search_example\",\n    agent: agent,\n    sessionService: sessionService\n  });\n\n  // Function to run a search query\n  async function runQuery(query: string) {\n    console.log(`\\nUser Query: ${query}\\n`);\n\n    // Create a content object for the query\n    const content = {\n      role: \"user\",\n      parts: [{ text: query }]\n    };\n\n    // Run the agent\n    for await (const event of runner.runAsync({\n      sessionId: session.id,\n      userId: \"user123\",\n      newMessage: content\n    })) {\n      if (event.content) {\n        console.log(\"Agent Response:\", event.content.parts[0]?.text || \"No text response\");\n      }\n    }\n  }\n\n  // Example search query\n  await runQuery(\"What were the major technology announcements from Google I/O 2023?\");\n}\n\nmain().catch(console.error);\n</code></pre>"},{"location":"tools/built-in-tools/#code-execution","title":"Code Execution","text":"<p>The <code>builtInCodeExecution</code> tool enables the agent to execute code, specifically when using Gemini 2 models. This allows the model to perform tasks like calculations, data manipulation, or running small scripts.</p> <pre><code>import { \n  Agent, \n  builtInCodeExecution, \n  Runner, \n  InMemorySessionService \n} from 'adk-typescript';\n\n// Create an agent with Code Execution capability\nconst agent = new Agent({\n  name: \"code_executor_agent\",\n  model: \"gemini-2.0-flash\",\n  description: \"I can execute code to solve problems.\",\n  instruction: \"Use code execution to perform calculations and data manipulation tasks.\",\n  tools: [builtInCodeExecution] // Add the built-in Code Execution tool\n});\n\n// Set up session service and runner\nconst sessionService = new InMemorySessionService();\n\nasync function main() {\n  // Create a new session\n  const session = await sessionService.createSession({ \n    appName: \"code_execution_example\",\n    userId: \"user123\" \n  });\n\n  // Create runner\n  const runner = new Runner({\n    appName: \"code_execution_example\",\n    agent: agent,\n    sessionService: sessionService\n  });\n\n  // Function to run a query\n  async function runQuery(query: string) {\n    console.log(`\\nUser Query: ${query}\\n`);\n\n    // Create a content object for the query\n    const content = {\n      role: \"user\",\n      parts: [{ text: query }]\n    };\n\n    // Run the agent\n    for await (const event of runner.runAsync({\n      sessionId: session.id,\n      userId: \"user123\",\n      newMessage: content\n    })) {\n      if (event.content) {\n        console.log(\"Agent Response:\", event.content.parts[0]?.text || \"No text response\");\n      }\n    }\n  }\n\n  // Example queries that benefit from code execution\n  await runQuery(\"Calculate the fibonacci sequence up to the 20th number.\");\n  await runQuery(\"What's the square root of 144 divided by the cube root of 27?\");\n}\n\nmain().catch(console.error);\n</code></pre>"},{"location":"tools/built-in-tools/#vertex-ai-search","title":"Vertex AI Search","text":"<p>The <code>vertexAiSearchTool</code> uses Google Cloud's Vertex AI Search, enabling the agent to search across your private, configured data stores (e.g., internal documents, company policies, knowledge bases). This built-in tool requires you to provide the specific data store ID during configuration.</p> <pre><code>import { \n  Agent, \n  vertexAiSearchTool, \n  Runner, \n  InMemorySessionService \n} from 'adk-typescript';\n\n// Configure Vertex AI Search with your data store ID\nconst myVertexSearch = vertexAiSearchTool('YOUR_DATA_STORE_ID');\n\n// Create an agent with Vertex AI Search capability\nconst agent = new Agent({\n  name: \"company_knowledge_agent\",\n  model: \"gemini-2.0-flash\",\n  description: \"I can search through company documents and policies.\",\n  instruction: \"Use Vertex AI Search to find information in internal documents when asked.\",\n  tools: [myVertexSearch] // Add the configured Vertex AI Search tool\n});\n\n// Set up session service and runner\nconst sessionService = new InMemorySessionService();\n\nasync function main() {\n  // Create a new session\n  const session = await sessionService.createSession({ \n    appName: \"vertex_search_example\",\n    userId: \"user123\" \n  });\n\n  // Create runner\n  const runner = new Runner({\n    appName: \"vertex_search_example\",\n    agent: agent,\n    sessionService: sessionService\n  });\n\n  // Function to run a search query\n  async function runQuery(query: string) {\n    console.log(`\\nUser Query: ${query}\\n`);\n\n    // Create a content object for the query\n    const content = {\n      role: \"user\",\n      parts: [{ text: query }]\n    };\n\n    // Run the agent\n    for await (const event of runner.runAsync({\n      sessionId: session.id,\n      userId: \"user123\",\n      newMessage: content\n    })) {\n      if (event.content) {\n        console.log(\"Agent Response:\", event.content.parts[0]?.text || \"No text response\");\n      }\n    }\n  }\n\n  // Example internal knowledge query\n  await runQuery(\"What is our company's policy on remote work?\");\n}\n\nmain().catch(console.error);\n</code></pre>"},{"location":"tools/built-in-tools/#use-built-in-tools-with-other-tools","title":"Use Built-in tools with other tools","text":"<p>The following code sample demonstrates how to use multiple built-in tools or how to use built-in tools with other tools by using multiple agents:</p> <pre><code>import { \n  Agent, \n  AgentTool, \n  googleSearch, \n  builtInCodeExecution \n} from 'adk-typescript';\n\n// Create a specialized search agent\nconst searchAgent = new Agent({\n  model: 'gemini-2.0-flash',\n  name: 'SearchAgent',\n  instruction: `\n    You're a specialist in Google Search\n  `,\n  tools: [googleSearch],\n});\n\n// Create a specialized coding agent\nconst codingAgent = new Agent({\n  model: 'gemini-2.0-flash',\n  name: 'CodeAgent',\n  instruction: `\n    You're a specialist in Code Execution\n  `,\n  tools: [builtInCodeExecution],\n});\n\n// Create a root agent that can delegate to the specialized agents\nconst rootAgent = new Agent({\n  name: \"RootAgent\",\n  model: \"gemini-2.0-flash\",\n  description: \"Root Agent\",\n  tools: [\n    new AgentTool({ agent: searchAgent }), \n    new AgentTool({ agent: codingAgent })\n  ],\n});\n</code></pre>"},{"location":"tools/built-in-tools/#limitations","title":"Limitations","text":"<p>Warning</p> <p>Currently, for each root agent or single agent, only one built-in tool is supported.</p> <p>For example, the following approach that uses two or more built-in tools within  a root agent (or a single agent) is not currently supported:</p> <pre><code>// NOT SUPPORTED\nconst rootAgent = new Agent({\n  name: \"RootAgent\",\n  model: \"gemini-2.0-flash\",\n  description: \"Root Agent\",\n  tools: [builtInCodeExecution, customFunction],\n});\n</code></pre> <p>Warning</p> <p>Built-in tools cannot be used within a sub-agent.</p> <p>For example, the following approach that uses built-in tools within sub-agents is not currently supported:</p> <pre><code>// NOT SUPPORTED\nconst searchAgent = new Agent({\n  model: 'gemini-2.0-flash',\n  name: 'SearchAgent',\n  instruction: `\n    You're a specialist in Google Search\n  `,\n  tools: [googleSearch],\n});\n\nconst codingAgent = new Agent({\n  model: 'gemini-2.0-flash',\n  name: 'CodeAgent',\n  instruction: `\n    You're a specialist in Code Execution\n  `,\n  tools: [builtInCodeExecution],\n});\n\nconst rootAgent = new Agent({\n  name: \"RootAgent\",\n  model: \"gemini-2.0-flash\",\n  description: \"Root Agent\",\n  subAgents: [\n    searchAgent,\n    codingAgent\n  ],\n});\n</code></pre>"},{"location":"tools/function-tools/","title":"Function tools","text":""},{"location":"tools/function-tools/#what-are-function-tools","title":"What are function tools?","text":"<p>When out-of-the-box tools don't fully meet specific requirements, developers can create custom function tools. This allows for tailored functionality, such as connecting to proprietary databases or implementing unique algorithms.</p> <p>For example, a function tool, \"myfinancetool\", might be a function that calculates a specific financial metric. ADK also supports long running functions, so if that calculation takes a while, the agent can continue working on other tasks.</p> <p>ADK offers several ways to create functions tools, each suited to different levels of complexity and control:</p> <ol> <li>Function Tool</li> <li>Long Running Function Tool</li> <li>Agents-as-a-Tool</li> </ol>"},{"location":"tools/function-tools/#1-function-tool","title":"1. Function Tool","text":"<p>Transforming a function into a tool is a straightforward way to integrate custom logic into your agents. This approach offers flexibility and quick integration.</p>"},{"location":"tools/function-tools/#parameters","title":"Parameters","text":"<p>Define your function parameters using standard JSON-serializable types (e.g., string, number, array, object). It's important to avoid setting default values for parameters, as the language model (LLM) does not currently support interpreting them.</p>"},{"location":"tools/function-tools/#return-type","title":"Return Type","text":"<p>The preferred return type for a TypeScript Function Tool is an object. This allows you to structure the response with key-value pairs, providing context and clarity to the LLM. If your function returns a type other than an object, the framework automatically wraps it into an object with a single key named \"result\".</p> <p>Strive to make your return values as descriptive as possible. For example, instead of returning a numeric error code, return an object with an \"errorMessage\" key containing a human-readable explanation. Remember that the LLM, not a piece of code, needs to understand the result. As a best practice, include a \"status\" key in your return object to indicate the overall outcome (e.g., \"success\", \"error\", \"pending\"), providing the LLM with a clear signal about the operation's state.</p>"},{"location":"tools/function-tools/#jsdoc-comments","title":"JSDoc Comments","text":"<p>The JSDoc comments of your function serve as the tool's description and are sent to the LLM. Therefore, a well-written and comprehensive JSDoc comment is crucial for the LLM to understand how to use the tool effectively. Clearly explain the purpose of the function, the meaning of its parameters, and the expected return values.</p> Example <p>This tool is a TypeScript function which obtains the stock price of a given stock ticker/symbol.</p> <p>Note: You need to install the Yahoo Finance library before using this tool: <code>npm install yahoo-finance2</code></p> <pre><code>import { LlmAgent as Agent } from 'adk-typescript/agents';\nimport { runners } from 'adk-typescript';\nimport { Content } from 'adk-typescript/types';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { FunctionTool } from 'adk-typescript/tools';\n\n// Constants for the app\nconst APP_NAME = \"stock_app\";\nconst USER_ID = \"1234\";\nconst SESSION_ID = \"session1234\";\n\n// Configure logging (simplified version for TypeScript)\nconst logger = {\n  info: (message: string, ...args: any[]) =&gt; console.info(message, ...args),\n  error: (message: string, ...args: any[]) =&gt; console.error(message, ...args)\n};\n\n/**\n * Retrieves the current stock price for a given symbol.\n * This is a simulated version of the Python yfinance function.\n * \n * @param symbol The stock symbol (e.g., \"AAPL\", \"GOOG\").\n * @returns The current stock price, or null if an error occurs.\n */\nfunction getStockPrice(symbol: string): number | null {\n  try {\n    // Simulated stock prices\n    const stockPrices: Record&lt;string, number&gt; = {\n      \"AAPL\": 187.32,\n      \"GOOG\": 141.18,\n      \"MSFT\": 378.85,\n      \"AMZN\": 175.47,\n      \"META\": 471.05,\n      \"TSLA\": 177.86,\n      \"NVDA\": 824.98\n    };\n\n    // In a real implementation, this would make an API call\n    // to a financial data provider or use a library like yfinance\n    const price = stockPrices[symbol.toUpperCase()];\n\n    if (price !== undefined) {\n      console.log(`Retrieved stock price for ${symbol}: $${price}`);\n      return price;\n    } else {\n      console.log(`Could not find stock price for ${symbol}`);\n      return null;\n    }\n  } catch (error) {\n    console.error(`Error retrieving stock price for ${symbol}:`, error);\n    return null;\n  }\n}\n\n// Create the agent with the function tool\nconst stockPriceAgent = new Agent({\n  name: \"stock_agent\",\n  model: \"gemini-2.0-flash\",\n  instruction: `You are an agent who retrieves stock prices. If a ticker symbol is provided, fetch the current price. If only a company name is given, first perform a Google search to find the correct ticker symbol before retrieving the stock price. If the provided ticker symbol is invalid or data cannot be retrieved, inform the user that the stock price could not be found.`,\n  description: `This agent specializes in retrieving real-time stock prices. Given a stock ticker symbol (e.g., AAPL, GOOG, MSFT) or the stock name, use the tools and reliable data sources to provide the most up-to-date price.`,\n  tools: [getStockPrice] // Add the function directly - it will be wrapped as a FunctionTool\n});\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nconst session = sessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: stockPriceAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nfunction callAgent(query: string): void {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  (async () =&gt; {\n    try {\n      const events = runner.run({\n        userId: USER_ID, \n        sessionId: SESSION_ID, \n        newMessage: content\n      });\n\n      for await (const event of events) {\n        if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n          const finalResponse = event.content.parts[0].text;\n          console.log(\"Agent Response: \", finalResponse);\n        }\n      }\n    } catch (error) {\n      console.error(\"Error running agent:\", error);\n    }\n  })();\n}\n\n// Execute with a sample query\ncallAgent(\"stock price of GOOG\");\n\n// Export for external use\nexport const agent = stockPriceAgent;\nexport function runStockPriceDemo(query: string): void {\n  callAgent(query);\n} \n</code></pre> <p>The return value from this tool will be wrapped into an object if it's not already one:</p> <pre><code>{\"result\": \"$123.45\"}\n</code></pre>"},{"location":"tools/function-tools/#best-practices","title":"Best Practices","text":"<p>While you have considerable flexibility in defining your function, remember that simplicity enhances usability for the LLM. Consider these guidelines:</p> <ul> <li>Fewer Parameters are Better: Minimize the number of parameters to reduce complexity.  </li> <li>Simple Data Types: Favor primitive data types like <code>string</code> and <code>number</code> over custom classes whenever possible.  </li> <li>Meaningful Names: The function's name and parameter names significantly influence how the LLM interprets and utilizes the tool. Choose names that clearly reflect the function's purpose and the meaning of its inputs. Avoid generic names like <code>doStuff()</code>.  </li> </ul>"},{"location":"tools/function-tools/#2-long-running-function-tool","title":"2. Long Running Function Tool","text":"<p>Designed for tasks that require a significant amount of processing time without blocking the agent's execution. This tool is a specialized version of <code>FunctionTool</code>.</p> <p>When using a <code>LongRunningFunctionTool</code>, your TypeScript function can initiate the long-running operation and optionally return an intermediate result to keep the model and user informed about the progress. The agent can then continue with other tasks. An example is the human-in-the-loop scenario where the agent needs human approval before proceeding with a task.</p>"},{"location":"tools/function-tools/#how-it-works","title":"How it Works","text":"<p>You wrap a TypeScript async generator function (a function using <code>async function*</code> and <code>yield</code>) with <code>LongRunningFunctionTool</code>.</p> <ol> <li> <p>Initiation: When the LLM calls the tool, your generator function starts executing.</p> </li> <li> <p>Intermediate Updates (<code>yield</code>): Your function should yield intermediate JavaScript objects (typically objects) periodically to report progress. The ADK framework takes each yielded value and sends it back to the LLM packaged within a <code>FunctionResponse</code>. This allows the LLM to inform the user (e.g., status, percentage complete, messages).</p> </li> <li> <p>Completion (<code>return</code>): When the task is finished, the generator function uses <code>return</code> to provide the final JavaScript object result.</p> </li> <li> <p>Framework Handling: The ADK framework manages the execution. It sends each yielded value back as an intermediate <code>FunctionResponse</code>. When the generator completes, the framework sends the returned value as the content of the final <code>FunctionResponse</code>, signaling the end of the long-running operation to the LLM.</p> </li> </ol>"},{"location":"tools/function-tools/#creating-the-tool","title":"Creating the Tool","text":"<p>Define your generator function and wrap it using the <code>LongRunningFunctionTool</code> class:</p> <pre><code>import { LongRunningFunctionTool } from 'adk-typescript/tools';\n\n// Define your generator function (see example below)\nasync function* myLongTaskGenerator(...args: any[]): AsyncGenerator&lt;any, any, unknown&gt; {\n  // ... setup ...\n  yield { status: \"pending\", message: \"Starting task...\" }; // Framework sends this as FunctionResponse\n  // ... perform work incrementally ...\n  yield { status: \"pending\", progress: 50 };               // Framework sends this as FunctionResponse\n  // ... finish work ...\n  return { status: \"completed\", result: \"Final outcome\" }; // Framework sends this as final FunctionResponse\n}\n\n// Wrap the function\nconst myTool = new LongRunningFunctionTool({\n  func: myLongTaskGenerator\n});\n</code></pre>"},{"location":"tools/function-tools/#intermediate-updates","title":"Intermediate Updates","text":"<p>Yielding structured JavaScript objects is crucial for providing meaningful updates. Include keys like:</p> <ul> <li> <p>status: e.g., \"pending\", \"running\", \"waiting_for_input\"</p> </li> <li> <p>progress: e.g., percentage, steps completed</p> </li> <li> <p>message: Descriptive text for the user/LLM</p> </li> <li> <p>estimatedCompletionTime: If calculable</p> </li> </ul> <p>Each value you yield is packaged into a FunctionResponse by the framework and sent to the LLM.</p>"},{"location":"tools/function-tools/#final-result","title":"Final Result","text":"<p>The JavaScript object your generator function returns is considered the final result of the tool execution. The framework packages this value (even if it's null or undefined) into the content of the final <code>FunctionResponse</code> sent back to the LLM, indicating the tool execution is complete.</p> Example: File Processing Simulation <pre><code>import { LlmAgent as Agent } from 'adk-typescript/agents';\nimport { runners } from 'adk-typescript';\nimport { Content } from 'adk-typescript/types';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { LongRunningFunctionTool, ToolContext } from 'adk-typescript/tools';\n\n// Constants for the app\nconst APP_NAME = \"file_processor\";\nconst USER_ID = \"1234\";\nconst SESSION_ID = \"session1234\";\n\n// Configure logging (simplified version for TypeScript)\nconst logger = {\n  info: (message: string, ...args: any[]) =&gt; console.info(message, ...args),\n  error: (message: string, ...args: any[]) =&gt; console.error(message, ...args)\n};\n\n// 1. Define the generator function\nasync function* processLargeFile(\n  params: Record&lt;string, any&gt;, \n  context: ToolContext\n): AsyncGenerator&lt;Record&lt;string, string&gt;, Record&lt;string, string&gt;, void&gt; {\n  /**\n   * Simulates processing a large file, yielding progress updates.\n   * \n   * @param params.filePath Path to the file being processed.\n   * @returns A final status dictionary.\n   */\n  const filePath = params.filePath as string;\n  const totalSteps = 5;\n\n  // This object will be sent in the first FunctionResponse\n  yield { status: \"pending\", message: `Starting processing for ${filePath}...` };\n\n  for (let i = 0; i &lt; totalSteps; i++) {\n    // Simulate work for one step\n    await new Promise(resolve =&gt; setTimeout(resolve, 1000));\n\n    const progress = (i + 1) / totalSteps;\n    // Each yielded object is sent in a subsequent FunctionResponse\n    yield {\n      status: \"pending\",\n      progress: `${Math.floor(progress * 100)}%`,\n      estimated_completion_time: `~${totalSteps - (i + 1)} seconds remaining`\n    };\n  }\n\n  // This returned object will be sent in the final FunctionResponse\n  return { status: \"completed\", result: `Successfully processed file: ${filePath}` };\n}\n\n// 2. Wrap the function with LongRunningFunctionTool\nconst longRunningTool = new LongRunningFunctionTool({\n  name: 'process_large_file',\n  description: 'Processes a large file and provides progress updates.',\n  fn: processLargeFile,\n  functionDeclaration: {\n    name: 'process_large_file',\n    description: 'Processes a large file and provides progress updates.',\n    parameters: {\n      type: 'object',\n      properties: {\n        filePath: {\n          type: 'string',\n          description: 'The path to the file to process.',\n        },\n      },\n      required: ['filePath'],\n    },\n  },\n});\n\n// 3. Use the tool in an Agent\nconst fileProcessorAgent = new Agent({\n  name: \"file_processor_agent\",\n  // Use a model compatible with function calling\n  model: \"gemini-2.0-flash\",\n  instruction: `You are an agent that processes large files. When the user provides a file path, use the 'process_large_file' tool. Keep the user informed about the progress based on the tool's updates (which arrive as function responses). Only provide the final result when the tool indicates completion in its final function response.`,\n  tools: [longRunningTool]\n});\n\n// Create Session and Runner\nconst sessionService = new InMemorySessionService();\nconst session = sessionService.createSession({\n  appName: APP_NAME, \n  userId: USER_ID, \n  sessionId: SESSION_ID\n});\n\nconst runner = new runners.Runner({\n  agent: fileProcessorAgent, \n  appName: APP_NAME, \n  sessionService: sessionService\n});\n\n// Agent Interaction function\nfunction callAgent(query: string): void {\n  // Create content for the request\n  const content: Content = {\n    role: 'user',\n    parts: [{ text: query }]\n  };\n\n  // Run the agent and collect results\n  (async () =&gt; {\n    try {\n      const events = runner.run({\n        userId: USER_ID, \n        sessionId: SESSION_ID, \n        newMessage: content\n      });\n\n      for await (const event of events) {\n        if (event.isFinalResponse() &amp;&amp; event.content &amp;&amp; event.content.parts &amp;&amp; event.content.parts[0].text) {\n          const finalResponse = event.content.parts[0].text;\n          console.log(\"Agent Response: \", finalResponse);\n        }\n      }\n    } catch (error) {\n      console.error(\"Error running agent:\", error);\n    }\n  })();\n}\n\n// Execute with a sample query\ncallAgent(\"Please process the file at /path/to/example.txt\");\n\n// Export for external use\nexport const agent = fileProcessorAgent;\nexport function runFileProcessorDemo(filePath: string): void {\n  callAgent(`Please process the file at ${filePath}`);\n} \n</code></pre>"},{"location":"tools/function-tools/#key-aspects-of-this-example","title":"Key aspects of this example","text":"<ul> <li> <p>processLargeFile: This generator simulates a lengthy operation, yielding intermediate status/progress objects.</p> </li> <li> <p><code>LongRunningFunctionTool</code>: Wraps the generator; the framework handles sending yielded updates and the final return value as sequential FunctionResponses.</p> </li> <li> <p>Agent instruction: Directs the LLM to use the tool and understand the incoming FunctionResponse stream (progress vs. completion) for user updates.</p> </li> <li> <p>Final return: The function returns the final result object, which is sent in the concluding FunctionResponse to indicate completion.</p> </li> </ul>"},{"location":"tools/function-tools/#3-agent-as-a-tool","title":"3. Agent-as-a-Tool","text":"<p>This powerful feature allows you to leverage the capabilities of other agents within your system by calling them as tools. The Agent-as-a-Tool enables you to invoke another agent to perform a specific task, effectively delegating responsibility. This is conceptually similar to creating a TypeScript function that calls another agent and uses the agent's response as the function's return value.</p>"},{"location":"tools/function-tools/#key-difference-from-sub-agents","title":"Key difference from sub-agents","text":"<p>It's important to distinguish an Agent-as-a-Tool from a Sub-Agent.</p> <ul> <li> <p>Agent-as-a-Tool: When Agent A calls Agent B as a tool (using Agent-as-a-Tool), Agent B's answer is passed back to Agent A, which then summarizes the answer and generates a response to the user. Agent A retains control and continues to handle future user input.  </p> </li> <li> <p>Sub-agent: When Agent A calls Agent B as a sub-agent, the responsibility of answering the user is completely transferred to Agent B. Agent A is effectively out of the loop. All subsequent user input will be answered by Agent B.</p> </li> </ul>"},{"location":"tools/function-tools/#usage","title":"Usage","text":"<p>To use an agent as a tool, wrap the agent with the AgentTool class.</p> <pre><code>import { AgentTool } from 'adk-typescript/tools';\n\ntools: [new AgentTool({ agent: agentB })]\n</code></pre>"},{"location":"tools/function-tools/#customization","title":"Customization","text":"<p>The <code>AgentTool</code> class provides the following attributes for customizing its behavior:</p> <ul> <li>skipSummarization: boolean: If set to true, the framework will bypass the LLM-based summarization of the tool agent's response. This can be useful when the tool's response is already well-formatted and requires no further processing.</li> </ul> Example <pre><code>\n</code></pre>"},{"location":"tools/function-tools/#how-it-works_1","title":"How it works","text":"<ol> <li>When the <code>mainAgent</code> receives the long text, its instruction tells it to use the 'summarize' tool for long texts.  </li> <li>The framework recognizes 'summarize' as an <code>AgentTool</code> that wraps the <code>summaryAgent</code>.  </li> <li>Behind the scenes, the <code>mainAgent</code> will call the <code>summaryAgent</code> with the long text as input.  </li> <li>The <code>summaryAgent</code> will process the text according to its instruction and generate a summary.  </li> <li>The response from the <code>summaryAgent</code> is then passed back to the <code>mainAgent</code>. </li> <li>The <code>mainAgent</code> can then take the summary and formulate its final response to the user (e.g., \"Here's a summary of the text: ...\")</li> </ol>"},{"location":"tools/google-cloud-tools/","title":"Google Cloud Tools","text":"<p>Google Cloud tools make it easier to connect your agents to Google Cloud's products and services. With just a few lines of code you can use these tools to connect your agents with:</p> <ul> <li>Any custom APIs that developers host in Apigee.</li> <li>100s of prebuilt connectors to enterprise systems such as Salesforce,   Workday, and SAP.</li> <li>Automation workflows built using application integration.</li> <li>Databases such as Spanner, AlloyDB, Postgres and more using the MCP Toolbox for   databases.</li> </ul> <p></p>"},{"location":"tools/google-cloud-tools/#apigee-api-hub-tools","title":"Apigee API Hub Tools","text":"<p>ApiHubToolset lets you turn any documented API from Apigee API hub into a tool with a few lines of code. This section shows you the step by step instructions including setting up authentication for a secure connection to your APIs.</p> <p>Prerequisites</p> <ol> <li>Install ADK</li> <li>Install the    Google Cloud CLI.</li> <li>Apigee API hub     instance with documented (i.e. OpenAPI spec) APIs</li> <li>Set up your project structure and create required files</li> </ol> <pre><code>project_root_folder\n |\n `-- my_agent\n     |-- .env\n     |-- package.json\n     |-- tsconfig.json\n     |-- src\n         |-- index.ts\n         |-- agent.ts\n         `__ tools.ts\n</code></pre>"},{"location":"tools/google-cloud-tools/#create-an-api-hub-toolset","title":"Create an API Hub Toolset","text":"<p>Note: This tutorial includes an agent creation. If you already have an agent, you only need to follow a subset of these steps.</p> <ol> <li> <p>Get your access token, so that APIHubToolset can fetch spec from API Hub API.    In your terminal run the following command</p> <pre><code>gcloud auth print-access-token\n# Prints your access token like 'ya29....'\n</code></pre> </li> <li> <p>Ensure that the account used has the required permissions. You can use the    pre-defined role <code>roles/apihub.viewer</code> or assign the following permissions:</p> <ol> <li>apihub.specs.get (required)</li> <li>apihub.apis.get (optional)</li> <li>apihub.apis.list (optional)</li> <li>apihub.versions.get (optional)</li> <li>apihub.versions.list (optional)</li> <li>apihub.specs.list (optional)</li> </ol> </li> <li> <p>Create a tool with <code>APIHubToolset</code>. Add the below to <code>tools.ts</code></p> <p>If your API requires authentication, you must configure authentication for the tool. The following code sample demonstrates how to configure an API key. ADK supports token based auth (API Key, Bearer token), service account, and OpenID Connect. We will soon add support for various OAuth2 flows.</p> <pre><code>import { tokenToSchemeCredential, APIHubToolset } from 'adk-typescript';\n\n// Provide authentication for your APIs. Not required if your APIs don't required authentication.\nconst { authScheme, authCredential } = tokenToSchemeCredential(\n    \"apikey\", \"query\", \"apikey\", apikeyCredentialStr\n);\n\nconst sampleToolsetWithAuth = new APIHubToolset({\n    name: \"apihub-sample-tool\",\n    description: \"Sample Tool\",\n    accessToken: \"...\",  // Copy your access token generated in step 1\n    apihubResourceName: \"...\", // API Hub resource name\n    authScheme: authScheme,\n    authCredential: authCredential,\n});\n</code></pre> <p>For production deployment we recommend using a service account instead of an access token. In the code snippet above, use <code>serviceAccountJson: serviceAccountCredJsonStr</code> and provide your security account credentials instead of the token.</p> <p>For apihubResourceName, if you know the specific ID of the OpenAPI Spec being used for your API, use <code>`projects/my-project-id/locations/us-west1/apis/my-api-id/versions/version-id/specs/spec-id`</code>. If you would like the Toolset to automatically pull the first available spec from the API, use <code>`projects/my-project-id/locations/us-west1/apis/my-api-id`</code></p> </li> <li> <p>Create your agent file <code>agent.ts</code> and add the created tools    to your agent definition:</p> <pre><code>import { Agent } from 'adk-typescript';\nimport { sampleToolset } from './tools';\n\nexport const rootAgent = new Agent({\n    model: 'gemini-2.0-flash',\n    name: 'enterprise_assistant',\n    instruction: 'Help user, leverage the tools you have access to',\n    tools: sampleToolset.getTools(),\n});\n</code></pre> </li> <li> <p>Configure your <code>index.ts</code> to export your agent</p> <pre><code>export { rootAgent } from './agent';\n</code></pre> </li> <li> <p>Start the ADK Web UI and try your agent:</p> <pre><code># Make sure to run from your project_root_folder\nnpx adk-typescript web\n</code></pre> </li> </ol> <p>Then go to http://localhost:8000 to try your agent from the Web UI.</p>"},{"location":"tools/google-cloud-tools/#application-integration-tools","title":"Application Integration Tools","text":"<p>With ApplicationIntegrationToolset you can seamlessly give your agents a secure and governed access to enterprise applications using Integration Connector's 100+ pre-built connectors for systems like Salesforce, ServiceNow, JIRA, SAP, and more. Support for both on-prem and SaaS applications. In addition you can turn your existing Application Integration process automations into agentic workflows by providing application integration workflows as tools to your ADK agents.</p> <p>Prerequisites</p> <ol> <li>Install ADK</li> <li>An existing    Application Integration    workflow or    Integrations Connector    connection you want to use with your agent</li> <li>To use tool with default credentials: have Google Cloud CLI installed. See    installation guide.</li> </ol> <p>Run :</p> <pre><code>```shell\ngcloud config set project\ngcloud auth application-default login\ngcloud auth application-default set-quota-project &lt;project-id&gt;\n```\n</code></pre> <ol> <li> <p>Set up your project structure and create required files</p> <pre><code>project_root_folder\n|-- .env\n`-- my_agent\n    |-- package.json\n    |-- tsconfig.json\n    |-- src\n        |-- index.ts\n        |-- agent.ts\n        `__ tools.ts\n</code></pre> </li> </ol> <p>When running the agent, make sure to run <code>npx adk-typescript web</code> in project_root_folder</p>"},{"location":"tools/google-cloud-tools/#use-integration-connectors","title":"Use Integration Connectors","text":"<p>Connect your agent to enterprise applications using Integration Connectors.</p> <p>Prerequisites</p> <ol> <li>To use a connector from Integration Connectors, you need to provision    Application Integration in the same region as your connection by clicking on \"QUICK SETUP\" button.</li> </ol> <p></p> <ol> <li> <p>Go to Connection Tool    template from the template library and click on \"USE TEMPLATE\" button.</p> <p></p> </li> <li> <p>Fill the Integration Name as ExecuteConnection (It is mandatory to use this integration name only) and    select the region same as the connection region. Click on \"CREATE\".</p> </li> <li> <p>Publish the integration by using the \"PUBLISH\" button on the Application Integration Editor.</p> <p> </p> </li> </ol> <p>Steps:</p> <ol> <li> <p>Create a tool with <code>ApplicationIntegrationToolset</code></p> <pre><code>import { ApplicationIntegrationToolset } from 'adk-typescript';\n\nconst connectorTool = new ApplicationIntegrationToolset({\n    project: \"test-project\", // TODO: replace with GCP project of the connection\n    location: \"us-central1\", //TODO: replace with location of the connection\n    connection: \"test-connection\", //TODO: replace with connection name\n    entityOperations: {\n        \"Entity_One\": [\"LIST\",\"CREATE\"], \n        \"Entity_Two\": [] // empty array for actions means all operations on the entity are supported.\n    },\n    actions: [\"action1\"], //TODO: replace with actions\n    serviceAccountCredentials: '{...}', // optional\n    toolName: \"tool_prefix2\",\n    toolInstructions: \"...\"\n});\n</code></pre> <p>Note: -   You can provide service account to be used instead of using default     credentials. -   To find the list of supported entities and actions for a connection, use the connectors apis:     listActions or      listEntityTypes</p> </li> <li> <p>Add the tool to your agent. Update your <code>agent.ts</code> file</p> <pre><code>import { Agent } from 'adk-typescript';\nimport { connectorTool } from './tools';\n\nexport const rootAgent = new Agent({\n    model: 'gemini-2.0-flash',\n    name: 'connector_agent',\n    instruction: \"Help user, leverage the tools you have access to\",\n    tools: connectorTool.getTools(),\n});\n</code></pre> </li> <li> <p>Configure your <code>index.ts</code> to export your agent</p> <pre><code>export { rootAgent } from './agent';\n</code></pre> </li> <li> <p>Start the ADK Web UI and try your agent.</p> <pre><code># make sure to run from your project_root_folder\nnpx adk-typescript web\n</code></pre> </li> </ol> <p>Then go to http://localhost:8000, and choose    my_agent agent (same as the agent folder name)</p>"},{"location":"tools/google-cloud-tools/#use-app-integration-workflows","title":"Use App Integration Workflows","text":"<p>Use existing Application Integration workflow as a tool for your agent or create a new one.</p> <p>Steps:</p> <ol> <li> <p>Create a tool with <code>ApplicationIntegrationToolset</code></p> <pre><code>import { ApplicationIntegrationToolset } from 'adk-typescript';\n\nconst integrationTool = new ApplicationIntegrationToolset({\n    project: \"test-project\", // TODO: replace with GCP project of the connection\n    location: \"us-central1\", //TODO: replace with location of the connection\n    integration: \"test-integration\", //TODO: replace with integration name\n    trigger: \"api_trigger/test_trigger\",//TODO: replace with trigger id\n    serviceAccountCredentials: '{...}', //optional\n    toolName: \"tool_prefix1\",\n    toolInstructions: \"...\"\n});\n</code></pre> <p>Note: You can provide service account to be used instead of using default credentials</p> </li> <li> <p>Add the tool to your agent. Update your <code>agent.ts</code> file</p> <pre><code>import { Agent } from 'adk-typescript';\nimport { integrationTool, connectorTool } from './tools';\n\nexport const rootAgent = new Agent({\n    model: 'gemini-2.0-flash',\n    name: 'integration_agent',\n    instruction: \"Help user, leverage the tools you have access to\",\n    tools: integrationTool.getTools(),\n});\n</code></pre> </li> <li> <p>Configure your <code>index.ts</code> to export your agent</p> <pre><code>export { rootAgent } from './agent';\n</code></pre> </li> <li> <p>Start the ADK Web UI and try your agent.</p> <pre><code># make sure to run from your project_root_folder\nnpx adk-typescript web\n</code></pre> <p>Then go to http://localhost:8000, and choose my_agent agent (same as the agent folder name)</p> </li> </ol>"},{"location":"tools/google-cloud-tools/#toolbox-tools-for-databases","title":"Toolbox Tools for Databases","text":"<p>MCP Toolbox for Databases is an open source MCP server for databases. It was designed with enterprise-grade and production-quality in mind. It enables you to develop tools easier, faster, and more securely by handling the complexities such as connection pooling, authentication, and more.</p> <p>Google's Agent Development Kit (ADK) has built in support for Toolbox. For more information on getting started or configuring Toolbox, see the documentation.</p> <p></p>"},{"location":"tools/google-cloud-tools/#configure-and-deploy","title":"Configure and deploy","text":"<p>Toolbox is an open source server that you deploy and manage yourself. For more instructions on deploying and configuring, see the official Toolbox documentation:</p> <ul> <li>Installing the Server</li> <li>Configuring Toolbox</li> </ul>"},{"location":"tools/google-cloud-tools/#install-client-sdk","title":"Install client SDK","text":"<p>ADK relies on the Toolbox client SDK to use Toolbox. Install the package before getting started:</p> <pre><code>npm install toolbox-langchain langchain\n</code></pre>"},{"location":"tools/google-cloud-tools/#loading-toolbox-tools","title":"Loading Toolbox Tools","text":"<p>Once your Toolbox server is configured and up and running, you can load tools from your server using the ADK:</p> <pre><code>import { ToolboxTool, Agent } from 'adk-typescript';\n\nconst toolbox = new ToolboxTool(\"https://127.0.0.1:5000\");\n\n// Load a specific set of tools\nconst toolsetTools = toolbox.getToolset('my-toolset-name');\n// Or, load a single tool\nconst singleTool = toolbox.getTool('my-tool-name');\n\nconst rootAgent = new Agent({\n    model: 'gemini-2.0-flash',\n    name: 'database_agent',\n    instruction: 'Help user query and analyze database data using the provided tools',\n    tools: toolsetTools // Provide the list of tools to the Agent\n});\n</code></pre>"},{"location":"tools/google-cloud-tools/#advanced-toolbox-features","title":"Advanced Toolbox Features","text":"<p>Toolbox has a variety of features to make developing Gen AI tools for databases. For more information, read more about the following features:</p> <ul> <li>Authenticated Parameters: bind tool inputs to values from OIDC tokens automatically, making it easy to run sensitive queries without potentially leaking data</li> <li>Authorized Invocations:  restrict access to use a tool based on the users Auth token</li> <li>OpenTelemetry: get metrics and tracing from Toolbox with OpenTelemetry</li> </ul>"},{"location":"tools/mcp-tools/","title":"Model Context Protocol Tools","text":"<p>This guide walks you through two ways of integrating Model Context Protocol (MCP) with ADK.</p>"},{"location":"tools/mcp-tools/#what-is-model-context-protocol-mcp","title":"What is Model Context Protocol (MCP)?","text":"<p>The Model Context Protocol (MCP) is an open standard designed to standardize how Large Language Models (LLMs) like Gemini and Claude communicate with external applications, data sources, and tools. Think of it as a universal connection mechanism that simplifies how LLMs obtain context, execute actions, and interact with various systems.</p> <p>MCP follows a client-server architecture, defining how data (resources), interactive templates (prompts), and actionable functions (tools) are exposed by an MCP server and consumed by an MCP client (which could be an LLM host application or an AI agent).</p> <p>This guide covers two primary integration patterns:</p> <ol> <li>Using Existing MCP Servers within ADK: An ADK agent acts as an MCP client, leveraging tools provided by external MCP servers.  </li> <li>Exposing ADK Tools via an MCP Server: Building an MCP server that wraps ADK tools, making them accessible to any MCP client.</li> </ol>"},{"location":"tools/mcp-tools/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following set up:</p> <ul> <li>Set up ADK: Follow the standard ADK setup instructions in the quickstart.  </li> <li>Setup Node.js and npm: MCP requires Node.js version 18 or higher.</li> <li>Verify Installations: Confirm the required tools are in your PATH:</li> </ul> <pre><code># Both commands should print the path to the executables\nwhich npm\nwhich npx\n</code></pre>"},{"location":"tools/mcp-tools/#1-using-mcp-servers-with-adk-agents-adk-as-an-mcp-client","title":"1. Using MCP servers with ADK agents (ADK as an MCP client)","text":"<p>This section shows two examples of using MCP servers with ADK agents. This is the most common integration pattern. Your ADK agent needs to use functionality provided by an existing service that exposes itself as an MCP Server.</p>"},{"location":"tools/mcp-tools/#mcptoolset-class","title":"<code>MCPToolset</code> class","text":"<p>The examples use the <code>MCPToolset</code> class in ADK which acts as the bridge to the MCP server. Your ADK agent uses <code>MCPToolset</code> to:</p> <ol> <li>Connect: Establish a connection to an MCP server process. This can be a local server communicating over standard input/output (<code>StdioServerParameters</code>) or a remote server using Server-Sent Events (<code>SseServerParams</code>).  </li> <li>Discover: Query the MCP server for its available tools (<code>list_tools</code> MCP method).  </li> <li>Adapt: Convert the MCP tool schemas into ADK-compatible <code>BaseTool</code> instances.  </li> <li>Expose: Present these adapted tools to the ADK <code>Agent</code>.  </li> <li>Proxy Calls: When the <code>Agent</code> decides to use one of these tools, <code>MCPToolset</code> forwards the call (<code>call_tool</code> MCP method) to the MCP server and returns the result.  </li> <li>Manage Connection: Handle the lifecycle of the connection to the MCP server process, often requiring explicit cleanup.</li> </ol>"},{"location":"tools/mcp-tools/#example-1-file-system-mcp-server","title":"Example 1: File System MCP Server","text":"<p>This example demonstrates connecting to a local MCP server that provides file system operations.</p>"},{"location":"tools/mcp-tools/#step-1-attach-the-mcp-server-to-your-adk-agent-via-mcptoolset","title":"Step 1: Attach the MCP Server to your ADK agent via <code>MCPToolset</code>","text":"<p>Create <code>agent.ts</code> in <code>./adk_agent_samples/mcp_agent/</code> and use the following code snippet to define a function that initializes the <code>MCPToolset</code>.</p> <ul> <li>Important: Replace <code>\"/path/to/your/folder\"</code> with the absolute path to an actual folder on your system.</li> </ul> <pre><code>// ./adk_agent_samples/mcp_agent/agent.ts\nimport { \n  Agent, \n  MCPToolset, \n  StdioServerParameters,\n  SseServerParams,\n  Runner, \n  InMemorySessionService,\n  InMemoryArtifactService \n} from 'adk-typescript';\n\n// --- Step 1: Import Tools from MCP Server ---\nasync function getToolsAsync() {\n  /**\n   * Gets tools from the File System MCP Server.\n   */\n  console.log(\"Attempting to connect to MCP Filesystem server...\");\n\n  const toolset = new MCPToolset({\n    // Use StdioServerParameters for local process communication\n    connectionParams: {\n      command: 'npx', // Command to run the server\n      args: [\n        \"-y\",    // Arguments for the command\n        \"@modelcontextprotocol/server-filesystem\",\n        // TODO: IMPORTANT! Change the path below to an ABSOLUTE path on your system.\n        \"/path/to/your/folder\"\n      ],\n    }\n    // For remote servers, you would use SseServerParams instead:\n    // connectionParams: new SseServerParams({\n    //   url: \"http://remote-server:port/path\", \n    //   headers: {} \n    // })\n  });\n\n  const tools = await toolset.getTools();\n\n  console.log(\"MCP Toolset created successfully.\");\n  // MCP requires maintaining a connection to the local MCP Server.\n  // toolset manages the cleanup of this connection.\n  return { tools, toolset };\n}\n\n// --- Step 2: Agent Definition ---\nasync function getAgentAsync() {\n  /**\n   * Creates an ADK Agent equipped with tools from the MCP Server.\n   */\n  const { tools, toolset } = await getToolsAsync();\n  console.log(`Fetched ${tools.length} tools from MCP server.`);\n\n  const rootAgent = new Agent({\n    model: 'gemini-2.0-flash', // Adjust model name if needed based on availability\n    name: 'filesystem_assistant',\n    instruction: 'Help user interact with the local filesystem using available tools.',\n    tools: toolset, // Provide the MCP toolset to the ADK agent\n  });\n\n  return { rootAgent, toolset };\n}\n\n// --- Step 3: Main Execution Logic ---\nasync function main() {\n  const sessionService = new InMemorySessionService();\n  // Artifact service might not be needed for this example\n  const artifactsService = new InMemoryArtifactService();\n\n  const session = await sessionService.createSession({\n    appName: 'mcp_filesystem_app', \n    userId: 'user_fs'\n  });\n\n  // TODO: Change the query to be relevant to YOUR specified folder.\n  // e.g., \"list files in the 'documents' subfolder\" or \"read the file 'notes.txt'\"\n  const query = \"list files in the tests folder\";\n  console.log(`User Query: '${query}'`);\n\n  const content = {\n    role: 'user', \n    parts: [{ text: query }]\n  };\n\n  const { rootAgent, toolset } = await getAgentAsync();\n\n  const runner = new Runner({\n    appName: 'mcp_filesystem_app',\n    agent: rootAgent,\n    artifactService: artifactsService, // Optional\n    sessionService: sessionService,\n  });\n\n  console.log(\"Running agent...\");\n\n  try {\n    // Use for...await to iterate through the async generator\n    for await (const event of runner.runAsync({\n      sessionId: session.id, \n      userId: session.userId, \n      newMessage: content\n    })) {\n      console.log(`Event received: ${JSON.stringify(event)}`);\n    }\n  } finally {\n    // Crucial Cleanup: Ensure the MCP server process connection is closed.\n    console.log(\"Closing MCP server connection...\");\n    await toolset.close();\n    console.log(\"Cleanup complete.\");\n  }\n}\n\n// Run the main function\nmain().catch(error =&gt; {\n  console.error(`An error occurred: ${error}`);\n});\n</code></pre>"},{"location":"tools/mcp-tools/#step-2-observe-the-result","title":"Step 2: Observe the result","text":"<p>Run the script:</p> <pre><code>cd ./adk_agent_samples\nnpx ts-node ./mcp_agent/agent.ts\n</code></pre> <p>The following shows the expected output for the connection attempt, the MCP server starting (via npx), the ADK agent events (including the FunctionCall to list_directory and the FunctionResponse), and the final agent text response based on the file listing. Ensure the exitStack.close() runs at the end.</p> <pre><code>User Query: 'list files in the tests folder'\nAttempting to connect to MCP Filesystem server...\n# --&gt; npx process starts here, potentially logging to stderr/stdout\nSecure MCP Filesystem Server running on stdio\nAllowed directories: [\n  '/path/to/your/folder'\n]\n# &lt;-- npx process output ends\nMCP Toolset created successfully.\nFetched [N] tools from MCP server. # N = number of tools like list_directory, read_file etc.\nRunning agent...\nEvent received: {\"content\":{\"parts\":[{\"functionCall\":{\"id\":\"...\",\"args\":{\"path\":\"tests\"},\"name\":\"list_directory\"}}],\"role\":\"model\"}}\nEvent received: {\"content\":{\"parts\":[{\"functionResponse\":{\"id\":\"...\",\"name\":\"list_directory\",\"response\":{\"result\":{\"content\":[{\"text\":\"...\"}]}}}}],\"role\":\"user\"}}\nEvent received: {\"content\":{\"parts\":[{\"text\":\"...\"}],\"role\":\"model\"}}\nClosing MCP server connection...\nCleanup complete.\n</code></pre>"},{"location":"tools/mcp-tools/#example-2-google-maps-mcp-server","title":"Example 2: Google Maps MCP Server","text":"<p>This follows the same pattern but targets the Google Maps MCP server.</p>"},{"location":"tools/mcp-tools/#step-1-get-api-key-and-enable-apis","title":"Step 1: Get API Key and Enable APIs","text":"<p>Follow the directions at Use API keys to get a Google Maps API Key.</p> <p>Enable Directions API and Routes API in your Google Cloud project. For instructions, see Getting started with Google Maps Platform topic.</p>"},{"location":"tools/mcp-tools/#step-2-update-gettoolsasync","title":"Step 2: Update getToolsAsync","text":"<p>Modify getToolsAsync in agent.ts to connect to the Maps server, passing your API key via the env parameter of StdioServerParameters.</p> <pre><code>// agent.ts (modify getToolsAsync and other parts as needed)\nimport { \n  Agent, \n  MCPToolset, \n  StdioServerParameters,\n  SseServerParams,\n  Runner, \n  InMemorySessionService,\n  InMemoryArtifactService \n} from 'adk-typescript';\n\nasync function getToolsAsync() {\n  /** Gets tools from the Google Maps MCP Server. */\n  // IMPORTANT: Replace with your actual key\n  const googleMapsApiKey = \"YOUR_API_KEY_FROM_STEP_1\";\n  if (googleMapsApiKey.includes(\"YOUR_API_KEY\")) {\n    throw new Error(\"Please replace 'YOUR_API_KEY_FROM_STEP_1' with your actual Google Maps API key.\");\n  }\n\n  console.log(\"Attempting to connect to MCP Google Maps server...\");\n  const toolset = new MCPToolset({\n    connectionParams: {\n      command: 'npx',\n      args: [\n        \"-y\",\n        \"@modelcontextprotocol/server-google-maps\",\n      ],\n      // Pass the API key as an environment variable to the npx process\n      env: {\n        \"GOOGLE_MAPS_API_KEY\": googleMapsApiKey\n      }\n    }\n  });\n\n  const tools = await toolset.getTools();\n\n  console.log(\"MCP Toolset created successfully.\");\n  return { tools, toolset };\n}\n\n// --- Step 2: Agent Definition ---\nasync function getAgentAsync() {\n  /** Creates an ADK Agent equipped with tools from the MCP Server. */\n  const { tools, toolset } = await getToolsAsync();\n  console.log(`Fetched ${tools.length} tools from MCP server.`);\n\n  const rootAgent = new Agent({\n    model: 'gemini-2.0-flash', // Adjust if needed\n    name: 'maps_assistant',\n    instruction: 'Help user with mapping and directions using available tools.',\n    tools: toolset,\n  });\n\n  return { rootAgent, toolset };\n}\n\n// --- Step 3: Main Execution Logic (modify query) ---\nasync function main() {\n  const sessionService = new InMemorySessionService();\n  const artifactsService = new InMemoryArtifactService(); // Optional\n\n  const session = await sessionService.createSession({\n    appName: 'mcp_maps_app', \n    userId: 'user_maps'\n  });\n\n  // TODO: Use specific addresses for reliable results with this server\n  const query = \"What is the route from 1600 Amphitheatre Pkwy to 1165 Borregas Ave\";\n  console.log(`User Query: '${query}'`);\n\n  const content = {\n    role: 'user', \n    parts: [{ text: query }]\n  };\n\n  const { rootAgent, toolset } = await getAgentAsync();\n\n  const runner = new Runner({\n    appName: 'mcp_maps_app',\n    agent: rootAgent,\n    artifactService: artifactsService, // Optional\n    sessionService: sessionService,\n  });\n\n  console.log(\"Running agent...\");\n\n  try {\n    for await (const event of runner.runAsync({\n      sessionId: session.id, \n      userId: session.userId, \n      newMessage: content\n    })) {\n      console.log(`Event received: ${JSON.stringify(event)}`);\n    }\n  } finally {\n    console.log(\"Closing MCP server connection...\");\n    await toolset.close();\n    console.log(\"Cleanup complete.\");\n  }\n}\n\nmain().catch(error =&gt; {\n  console.error(`An error occurred: ${error}`);\n});\n</code></pre>"},{"location":"tools/mcp-tools/#step-3-observe-the-result","title":"Step 3: Observe the Result","text":"<p>Run the script:</p> <pre><code>cd ./adk_agent_samples\nnpx ts-node ./mcp_agent/agent.ts\n</code></pre> <p>A successful run will show events indicating the agent called the relevant Google Maps tool (likely related to directions or routes) and a final response containing the directions. An example is shown below.</p> <pre><code>User Query: 'What is the route from 1600 Amphitheatre Pkwy to 1165 Borregas Ave'\nAttempting to connect to MCP Google Maps server...\n# --&gt; npx process starts...\nMCP Toolset created successfully.\nFetched [N] tools from MCP server.\nRunning agent...\nEvent received: {\"content\":{\"parts\":[{\"functionCall\":{\"name\":\"get_directions\",...}}],\"role\":\"model\"}}\nEvent received: {\"content\":{\"parts\":[{\"functionResponse\":{\"name\":\"get_directions\",...}}],\"role\":\"user\"}}\nEvent received: {\"content\":{\"parts\":[{\"text\":\"Head north toward Amphitheatre Pkwy...\"}],\"role\":\"model\"}}\nClosing MCP server connection...\nCleanup complete.\n</code></pre>"},{"location":"tools/mcp-tools/#2-building-an-mcp-server-with-adk-tools-mcp-server-exposing-adk","title":"2. Building an MCP server with ADK tools (MCP server exposing ADK)","text":"<p>This pattern allows you to wrap ADK's tools and make them available to any standard MCP client application. The example in this section exposes the loadWebPage ADK tool through the MCP server.</p>"},{"location":"tools/mcp-tools/#summary-of-steps","title":"Summary of steps","text":"<p>You will create a standard TypeScript MCP server application using the model-context-protocol library. Within this server, you will:</p> <ol> <li>Instantiate the ADK tool(s) you want to expose (e.g., FunctionTool with loadWebPage).  </li> <li>Implement the MCP server's handlers to advertise the ADK tool(s), converting the ADK tool definition to the MCP schema using helper functions.  </li> <li>Implement the server to receive requests from MCP clients, identify if the request targets your wrapped ADK tool, execute the ADK tool's method, and format the result into an MCP-compliant response.</li> </ol>"},{"location":"tools/mcp-tools/#prerequisites_1","title":"Prerequisites","text":"<p>Install the MCP server library:</p> <pre><code>npm install @model-context-protocol/server @model-context-protocol/client adk-typescript\n</code></pre>"},{"location":"tools/mcp-tools/#step-1-create-the-mcp-server-script","title":"Step 1: Create the MCP Server Script","text":"<p>Create a new TypeScript file, e.g., <code>adk_mcp_server.ts</code>.</p>"},{"location":"tools/mcp-tools/#step-2-implement-the-server-logic","title":"Step 2: Implement the Server Logic","text":"<p>Add the following code, which sets up an MCP server exposing the ADK loadWebPage tool.</p> <pre><code>// adk_mcp_server.ts\nimport * as dotenv from 'dotenv';\nimport { Server, NotificationOptions } from '@model-context-protocol/server';\nimport { \n  Tool as McpTool, \n  TextContent\n} from '@model-context-protocol/client';\nimport { \n  FunctionTool, \n  loadWebPage \n} from 'adk-typescript';\n\n// Load environment variables if needed\ndotenv.config();\n\n// Initialize and configure the MCP server\nconst app = new Server(\"adk-web-tool-mcp-server\");\n\n// Define ADK tools to expose\nconsole.log(\"Initializing ADK loadWebPage tool...\");\nconst adkWebTool = new FunctionTool({\n  func: loadWebPage\n});\nconsole.log(`ADK tool '${adkWebTool.name}' initialized.`);\n\n// Convert ADK tool schema to MCP tool format\nfunction adkToolToMcpTool(adkTool: FunctionTool): McpTool {\n  const declaration = adkTool.getDeclaration();\n\n  return {\n    name: declaration.name,\n    description: declaration.description || '',\n    inputSchema: declaration.parameters,\n    // For simplicity, we won't define a specific output schema\n    outputSchema: undefined\n  };\n}\n\n// Handler for listTools MCP method\napp.listTools(async () =&gt; {\n  console.log(\"MCP Server: Received list_tools request.\");\n  const mcpToolSchema = adkToolToMcpTool(adkWebTool);\n  console.log(`MCP Server: Advertising tool: ${mcpToolSchema.name}`);\n  return [mcpToolSchema];\n});\n\n// Handler for callTool MCP method\napp.callTool(async (request) =&gt; {\n  const { name, arguments: args } = request;\n  console.log(`MCP Server: Received call_tool request for '${name}' with args:`, args);\n\n  // Check if the requested tool name matches our wrapped ADK tool\n  if (name === adkWebTool.name) {\n    try {\n      // Execute the ADK tool - note we don't have a full ADK context here\n      const adkResponse = await adkWebTool.execute(args, null);\n      console.log(`MCP Server: ADK tool '${name}' executed successfully.`);\n\n      // Format the ADK tool's response into MCP format\n      const responseText = JSON.stringify(adkResponse, null, 2);\n      return [{ \n        type: \"text\", \n        text: responseText \n      } as TextContent];\n    } catch (e) {\n      console.error(`MCP Server: Error executing ADK tool '${name}':`, e);\n      const errorText = JSON.stringify({\n        error: `Failed to execute tool '${name}': ${e.message}`\n      });\n      return [{ \n        type: \"text\", \n        text: errorText \n      } as TextContent];\n    }\n  } else {\n    console.log(`MCP Server: Tool '${name}' not found.`);\n    const errorText = JSON.stringify({\n      error: `Tool '${name}' not implemented.`\n    });\n    return [{ \n      type: \"text\", \n      text: errorText \n    } as TextContent];\n  }\n});\n\n// Start the server\nasync function startServer() {\n  try {\n    console.log(\"Starting MCP server over stdio...\");\n    await app.run();\n    console.log(\"MCP Server run loop finished.\");\n  } catch (error) {\n    console.error(\"MCP Server error:\", error);\n  }\n}\n\n// Run the server\nstartServer().catch(console.error);\n</code></pre>"},{"location":"tools/mcp-tools/#step-3-test-your-mcp-server-with-adk","title":"Step 3: Test your MCP Server with ADK","text":"<p>Create a client that connects to your MCP server. You'll create an ADK agent that uses your custom MCP server via the MCPToolset:</p> <pre><code>// mcp_client.ts\nimport { \n  Agent, \n  MCPToolset, \n  StdioServerParameters,\n  Runner, \n  InMemorySessionService \n} from 'adk-typescript';\n\nasync function main() {\n  // Connect to our custom MCP server\n  console.log(\"Connecting to custom ADK MCP Server...\");\n\n  const toolset = new MCPToolset({\n    connectionParams: {\n      command: 'node', // Or 'ts-node' depending on your setup\n      args: [\n        \"./adk_mcp_server.js\" // Path to your compiled server or use ts-node with .ts file\n      ]\n    }\n  });\n\n  const tools = await toolset.getTools();\n\n  console.log(`Connected to MCP Server, discovered ${tools.length} tools`);\n\n  // Create an agent with the MCP tools\n  const agent = new Agent({\n    name: \"web_agent\",\n    model: \"gemini-2.0-flash\",\n    instruction: \"You can help users browse web pages by fetching their content.\",\n    tools: tools\n  });\n\n  // Setup session and runner\n  const sessionService = new InMemorySessionService();\n  const session = await sessionService.createSession({\n    appName: \"mcp_client_demo\",\n    userId: \"test_user\"\n  });\n\n  const runner = new Runner({\n    appName: \"mcp_client_demo\",\n    agent: agent,\n    sessionService: sessionService\n  });\n\n  // Test with a query\n  const query = \"Can you fetch the content of the webpage https://example.com?\";\n  console.log(`User query: \"${query}\"`);\n\n  try {\n    // Run the agent\n    for await (const event of runner.runAsync({\n      sessionId: session.id,\n      userId: session.userId,\n      newMessage: {\n        role: \"user\",\n        parts: [{ text: query }]\n      }\n    })) {\n      console.log(`Event: ${JSON.stringify(event)}`);\n    }\n  } finally {\n    // Clean up\n    console.log(\"Cleaning up MCP connection...\");\n    await exitStack.close();\n  }\n}\n\nmain().catch(console.error);\n</code></pre> <p>To run this test:</p> <pre><code># Compile and run (or use ts-node)\nnpx tsc adk_mcp_server.ts\nnpx tsc mcp_client.ts\nnode mcp_client.js\n</code></pre>"},{"location":"tools/mcp-tools/#mcp-with-adk-web-ui","title":"MCP with ADK Web UI","text":"<p>You can also define your agent with MCP tools, and then interact with your agent with the ADK Web UI. </p> <pre><code>// agent.ts\nimport { Agent, MCPToolset, StdioServerParameters } from 'adk-typescript';\n\nexport async function createAgent() {\n  const { tools, exitStack } = await MCPToolset.fromServer({\n    connectionParams: new StdioServerParameters({\n      command: 'npx',\n      args: [\n        \"-y\",\n        \"@modelcontextprotocol/server-filesystem\",\n        // Change to your directory\n        \"/path/to/your/folder\"\n      ]\n    })\n  });\n\n  const agent = new Agent({\n    model: 'gemini-2.0-flash',\n    name: 'filesystem_assistant',\n    instruction: 'Help user interact with the local filesystem using available tools.',\n    tools: tools\n  });\n\n  // Store exitStack for cleanup\n  // In a real application, you need to manage this resource carefully\n  (global as any).mcpExitStack = exitStack;\n\n  return agent;\n}\n\n// This function is used when the app is shutting down\nexport async function cleanupAgent() {\n  const exitStack = (global as any).mcpExitStack;\n  if (exitStack) {\n    await exitStack.close();\n    console.log(\"MCP connections closed\");\n  }\n}\n\n// For adk-typescript web UI, export an async function that returns the agent\nexport default createAgent;\n</code></pre> <p>Configure your web server to properly handle the lifecycle of the MCP connections, ensuring they're cleaned up when sessions end.</p>"},{"location":"tools/mcp-tools/#key-considerations","title":"Key considerations","text":"<p>When working with MCP and ADK, keep these points in mind:</p> <ul> <li> <p>Protocol vs. Library: MCP is a protocol specification, defining communication rules. ADK is a framework for building agents. MCPToolset bridges these by implementing the client side of the MCP protocol within the ADK framework.</p> </li> <li> <p>ADK Tools vs. MCP Tools:</p> <ul> <li>ADK Tools (BaseTool, FunctionTool, AgentTool, etc.) are objects designed for direct use within the ADK's Agent and Runner.  </li> <li>MCP Tools are capabilities exposed by an MCP Server according to the protocol's schema. MCPToolset makes these look like ADK tools to an Agent.  </li> <li>Langchain/CrewAI Tools are specific implementations within those libraries, often simple functions or classes, lacking the server/protocol structure of MCP. ADK offers wrappers (LangchainTool, CrewaiTool) for some interoperability.</li> </ul> </li> <li> <p>Asynchronous nature: Both ADK and the MCP libraries are heavily based on asynchronous programming. Tool implementations and server handlers should generally be async functions.</p> </li> <li> <p>Stateful sessions (MCP): MCP establishes stateful, persistent connections between a client and server instance. This differs from typical stateless REST APIs.</p> <ul> <li>Deployment: This statefulness can pose challenges for scaling and deployment, especially for remote servers handling many users. The original MCP design often assumed client and server were co-located. Managing these persistent connections requires careful infrastructure considerations (e.g., load balancing, session affinity).  </li> <li>ADK MCPToolset: Manages this connection lifecycle. The exitStack pattern shown in the examples is crucial for ensuring the connection (and potentially the server process) is properly terminated when the ADK agent finishes.</li> </ul> </li> </ul>"},{"location":"tools/mcp-tools/#further-resources","title":"Further Resources","text":"<ul> <li>Model Context Protocol Documentation</li> <li>MCP Specification </li> <li>MCP Examples and SDKs</li> </ul>"},{"location":"tools/openapi-tools/","title":"OpenAPI Integration","text":""},{"location":"tools/openapi-tools/#integrating-rest-apis-with-openapi","title":"Integrating REST APIs with OpenAPI","text":"<p>ADK simplifies interacting with external REST APIs by automatically generating callable tools directly from an OpenAPI Specification (v3.x). This eliminates the need to manually define individual function tools for each API endpoint.</p> <p>Core Benefit</p> <p>Use <code>OpenAPIToolset</code> to instantly create agent tools (<code>RestApiTool</code>) from your existing API documentation (OpenAPI spec), enabling agents to seamlessly call your web services.</p>"},{"location":"tools/openapi-tools/#key-components","title":"Key Components","text":"<ul> <li><code>OpenAPIToolset</code>: This is the primary class you'll use. You initialize it with your OpenAPI specification, and it handles the parsing and generation of tools.</li> <li><code>RestApiTool</code>: This class represents a single, callable API operation (like <code>GET /pets/{petId}</code> or <code>POST /pets</code>). <code>OpenAPIToolset</code> creates one <code>RestApiTool</code> instance for each operation defined in your spec.</li> </ul>"},{"location":"tools/openapi-tools/#how-it-works","title":"How it Works","text":"<p>The process involves these main steps when you use <code>OpenAPIToolset</code>:</p> <ol> <li> <p>Initialization &amp; Parsing:</p> <ul> <li>You provide the OpenAPI specification to <code>OpenAPIToolset</code> either as a JavaScript object, a JSON string, or a YAML string.</li> <li>The toolset internally parses the spec, resolving any internal references (<code>$ref</code>) to understand the complete API structure.</li> </ul> </li> <li> <p>Operation Discovery:</p> <ul> <li>It identifies all valid API operations (e.g., <code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code>) defined within the <code>paths</code> object of your specification.</li> </ul> </li> <li> <p>Tool Generation:</p> <ul> <li>For each discovered operation, <code>OpenAPIToolset</code> automatically creates a corresponding <code>RestApiTool</code> instance.</li> <li>Tool Name: Derived from the <code>operationId</code> in the spec (converted to camelCase). If <code>operationId</code> is missing, a name is generated from the method and path.</li> <li>Tool Description: Uses the <code>summary</code> or <code>description</code> from the operation for the LLM.</li> <li>API Details: Stores the required HTTP method, path, server base URL, parameters (path, query, header, cookie), and request body schema internally.</li> </ul> </li> <li> <p><code>RestApiTool</code> Functionality: Each generated <code>RestApiTool</code>:</p> <ul> <li>Schema Generation: Dynamically creates a <code>FunctionDeclaration</code> based on the operation's parameters and request body. This schema tells the LLM how to call the tool (what arguments are expected).</li> <li>Execution: When called by the LLM, it constructs the correct HTTP request (URL, headers, query params, body) using the arguments provided by the LLM and the details from the OpenAPI spec. It handles authentication (if configured) and executes the API call.</li> <li>Response Handling: Returns the API response (typically JSON) back to the agent flow.</li> </ul> </li> <li> <p>Authentication: You can configure global authentication (like API keys or OAuth - see Authentication for details) when initializing <code>OpenAPIToolset</code>. This authentication configuration is automatically applied to all generated <code>RestApiTool</code> instances.</p> </li> </ol>"},{"location":"tools/openapi-tools/#usage-workflow","title":"Usage Workflow","text":"<p>Follow these steps to integrate an OpenAPI spec into your agent:</p> <ol> <li>Obtain Spec: Get your OpenAPI specification document (e.g., load from a <code>.json</code> or <code>.yaml</code> file, fetch from a URL).</li> <li> <p>Instantiate Toolset: Create an <code>OpenAPIToolset</code> instance, passing the spec content and type (<code>specStr</code>/<code>specDict</code>, <code>specStrType</code>). Provide authentication details (<code>authScheme</code>, <code>authCredential</code>) if required by the API.</p> <pre><code>import { OpenAPIToolset } from 'adk-typescript';\nimport * as fs from 'fs';\n\n// Example with a JSON string\nconst openApiSpecJson = '...'; // Your OpenAPI JSON string\nconst toolset = new OpenAPIToolset({\n  specStr: openApiSpecJson, \n  specStrType: 'json'\n});\n\n// Example loading from file\nconst openApiSpecYaml = fs.readFileSync('petstore.yaml', 'utf8');\nconst toolsetFromFile = new OpenAPIToolset({\n  specStr: openApiSpecYaml,\n  specStrType: 'yaml'\n});\n\n// Example with a JavaScript object\n// const openApiSpecObj = {...}; // Your OpenAPI spec as an object\n// const toolsetFromObj = new OpenAPIToolset({\n//   specDict: openApiSpecObj\n// });\n</code></pre> </li> <li> <p>Retrieve Tools: Get the list of generated <code>RestApiTool</code> instances from the toolset.</p> <pre><code>const apiTools = toolset.getTools();\n// Or get a specific tool by its generated name (camelCase operationId)\n// const specificTool = toolset.getTool(\"listPets\");\n</code></pre> </li> <li> <p>Add to Agent: Include the retrieved tools in your <code>Agent</code>'s <code>tools</code> list.</p> <pre><code>import { Agent } from 'adk-typescript';\n\nconst myAgent = new Agent({\n  name: \"api_interacting_agent\",\n  model: \"gemini-2.0-flash\", // Or your preferred model\n  tools: apiTools, // Pass the list of generated tools\n  // ... other agent config ...\n});\n</code></pre> </li> <li> <p>Instruct Agent: Update your agent's instructions to inform it about the new API capabilities and the names of the tools it can use (e.g., <code>listPets</code>, <code>createPet</code>). The tool descriptions generated from the spec will also help the LLM.</p> </li> <li>Run Agent: Execute your agent using the <code>Runner</code>. When the LLM determines it needs to call one of the APIs, it will generate a function call targeting the appropriate <code>RestApiTool</code>, which will then handle the HTTP request automatically.</li> </ol>"},{"location":"tools/openapi-tools/#example","title":"Example","text":"<p>This example demonstrates generating tools from a simple Pet Store OpenAPI spec (using <code>httpbin.org</code> for mock responses) and interacting with them via an agent.</p> Code: Pet Store API openapi_example.ts<pre><code>import { \n  OpenAPIToolset, \n  Agent, \n  Runner, \n  InMemorySessionService,\n  Content \n} from 'adk-typescript';\nimport * as fs from 'fs';\n\nasync function main() {\n  // 1. Load the OpenAPI specification\n  // This simplified pet store spec points to httpbin.org to simulate actual API responses\n  const spec = `\n  openapi: 3.0.0\n  info:\n    title: Simplified Pet Store API\n    version: 1.0.0\n    description: A simplified pet store API for demonstration\n  servers:\n    - url: https://httpbin.org\n  paths:\n    /anything/pets:\n      get:\n        operationId: listPets\n        summary: List all pets\n        description: Returns a list of all available pets\n        responses:\n          '200':\n            description: A list of pets\n    /anything/pets/{petId}:\n      get:\n        operationId: getPetById\n        summary: Get a pet by ID\n        description: Returns details for a specific pet\n        parameters:\n          - name: petId\n            in: path\n            required: true\n            schema:\n              type: string\n            description: The ID of the pet to retrieve\n        responses:\n          '200':\n            description: Pet details\n  `;\n\n  // 2. Create the OpenAPIToolset\n  const toolset = new OpenAPIToolset({\n    specStr: spec,\n    specStrType: 'yaml'\n  });\n\n  // 3. Get the generated API tools\n  const apiTools = toolset.getTools();\n  console.log(`Generated ${apiTools.length} API tools:`);\n  apiTools.forEach(tool =&gt; {\n    console.log(`- ${tool.name}: ${tool.description}`);\n  });\n\n  // 4. Create an agent with the API tools\n  const agent = new Agent({\n    name: \"pet_store_agent\",\n    model: \"gemini-2.0-flash\",\n    description: \"An agent that can interact with the Pet Store API\",\n    instruction: `You can help users interact with the Pet Store API.\n      You can list all pets and get details for a specific pet by ID.\n      Use the appropriate API tool when a user asks about pets.`,\n    tools: apiTools\n  });\n\n  // 5. Set up a session and runner\n  const sessionService = new InMemorySessionService();\n  const session = await sessionService.createSession({\n    appName: \"pet_store_demo\",\n    userId: \"user123\"\n  });\n\n  const runner = new Runner({\n    appName: \"pet_store_demo\",\n    agent: agent,\n    sessionService: sessionService\n  });\n\n  // 6. Function to process user queries\n  async function processQuery(query: string) {\n    console.log(`\\nUser Query: ${query}`);\n\n    const content = {\n      role: \"user\",\n      parts: [{ text: query }]\n    };\n\n    for await (const event of runner.runAsync({\n      sessionId: session.id,\n      userId: \"user123\",\n      newMessage: content\n    })) {\n      if (event.content?.parts?.[0]?.text) {\n        console.log(`Agent: ${event.content.parts[0].text}`);\n      }\n    }\n  }\n\n  // 7. Run some example queries\n  await processQuery(\"Can you show me all the available pets?\");\n  await processQuery(\"Get details for pet with ID 123\");\n}\n\nmain().catch(console.error);\n</code></pre>"},{"location":"tools/third-party-tools/","title":"Third Party Tools","text":"<p>ADK is designed to be highly extensible, allowing you to seamlessly integrate tools from other AI Agent frameworks like CrewAI and LangChain. This interoperability is crucial because it allows for faster development time and allows you to reuse existing tools.</p>"},{"location":"tools/third-party-tools/#1-using-langchain-tools","title":"1. Using LangChain Tools","text":"<p>ADK provides the <code>LangchainTool</code> wrapper to integrate tools from the LangChain ecosystem into your agents.</p>"},{"location":"tools/third-party-tools/#example-web-search-using-langchains-tavily-tool","title":"Example: Web Search using LangChain's Tavily tool","text":"<p>Tavily provides a search API that returns answers derived from real-time search results, intended for use by applications like AI agents.</p> <ol> <li> <p>Follow ADK installation and setup guide.</p> </li> <li> <p>Install Dependencies: Ensure you have the necessary LangChain packages installed. For example, to use the Tavily search tool, install its specific dependencies:</p> <pre><code>npm install adk-typescript langchain @langchain/community tavily-js\n</code></pre> </li> <li> <p>Obtain a Tavily API KEY and set it as an environment variable.</p> <pre><code># For Node.js\nprocess.env.TAVILY_API_KEY = \"&lt;REPLACE_WITH_API_KEY&gt;\";\n\n# Or set it before running your application\nexport TAVILY_API_KEY=&lt;REPLACE_WITH_API_KEY&gt;\n</code></pre> </li> <li> <p>Import: Import the <code>LangchainTool</code> wrapper from ADK and the specific <code>LangChain</code> tool you wish to use (e.g, <code>TavilySearchResults</code>).</p> <pre><code>import { LangchainTool } from 'adk-typescript';\nimport { TavilySearchResults } from '@langchain/community/tools/tavily_search';\n</code></pre> </li> <li> <p>Instantiate &amp; Wrap: Create an instance of your LangChain tool and pass it to the <code>LangchainTool</code> constructor.</p> <pre><code>// Instantiate the LangChain tool\nconst tavilyToolInstance = new TavilySearchResults({\n  maxResults: 5,\n  searchDepth: \"advanced\",\n  includeAnswer: true,\n  includeRawContent: true,\n  includeImages: true,\n});\n\n// Wrap it with LangchainTool for ADK\nconst adkTavilyTool = new LangchainTool({\n  tool: tavilyToolInstance\n});\n</code></pre> </li> <li> <p>Add to Agent: Include the wrapped <code>LangchainTool</code> instance in your agent's <code>tools</code> list during definition.</p> <pre><code>import { Agent } from 'adk-typescript';\n\n// Define the ADK agent, including the wrapped tool\nconst myAgent = new Agent({\n  name: \"langchain_tool_agent\",\n  model: \"gemini-2.0-flash\",\n  description: \"Agent to answer questions using TavilySearch.\",\n  instruction: \"I can answer your questions by searching the internet. Just ask me anything!\",\n  tools: [adkTavilyTool] // Add the wrapped tool here\n});\n</code></pre> </li> </ol>"},{"location":"tools/third-party-tools/#full-example-tavily-search","title":"Full Example: Tavily Search","text":"<p>Here's the full code combining the steps above to create and run an agent using the LangChain Tavily search tool.</p> <pre><code>// Import necessary modules\nimport { Agent, LangchainTool, Runner, InMemorySessionService } from 'adk-typescript';\nimport { TavilySearchResults } from '@langchain/community/tools/tavily_search';\n\n// Set your API key\n// In a real application, use environment variables or secure configuration\nprocess.env.TAVILY_API_KEY = \"your-tavily-api-key\";\n\nasync function main() {\n  // Instantiate the Tavily search tool from LangChain\n  const tavilyTool = new TavilySearchResults({\n    maxResults: 5,\n    searchDepth: \"advanced\",\n    includeAnswer: true,\n    includeRawContent: true,\n    includeImages: true,\n  });\n\n  // Wrap it with LangchainTool for ADK\n  const adkTavilyTool = new LangchainTool({\n    tool: tavilyTool\n  });\n\n  // Create an agent with the tool\n  const agent = new Agent({\n    name: \"search_agent\",\n    model: \"gemini-2.0-flash\",\n    description: \"Agent to answer questions using Tavily web search.\",\n    instruction: \"I can answer your questions by searching the internet. Just ask me anything!\",\n    tools: [adkTavilyTool]\n  });\n\n  // Set up session service and runner\n  const sessionService = new InMemorySessionService();\n  const session = await sessionService.createSession({\n    appName: \"tavily_search_demo\",\n    userId: \"user123\"\n  });\n\n  const runner = new Runner({\n    appName: \"tavily_search_demo\",\n    agent: agent,\n    sessionService: sessionService\n  });\n\n  // Function to run a query\n  async function runQuery(query: string) {\n    console.log(`\\nUser Query: ${query}\\n`);\n\n    // Create a content object for the query\n    const content = {\n      role: \"user\",\n      parts: [{ text: query }]\n    };\n\n    // Run the agent\n    for await (const event of runner.runAsync({\n      sessionId: session.id,\n      userId: \"user123\",\n      newMessage: content\n    })) {\n      if (event.content) {\n        console.log(\"Agent Response:\", event.content.parts[0]?.text || \"No text response\");\n      }\n    }\n  }\n\n  // Run a sample query\n  await runQuery(\"What are the latest developments in quantum computing?\");\n}\n\n// Run the main function\nmain().catch(error =&gt; console.error(\"Error:\", error));\n</code></pre>"},{"location":"tools/third-party-tools/#2-using-crewai-tools","title":"2. Using CrewAI tools","text":"<p>ADK provides the <code>CrewaiTool</code> wrapper to integrate tools from the CrewAI library.</p>"},{"location":"tools/third-party-tools/#example-web-search-using-crewais-serper-api","title":"Example: Web Search using CrewAI's Serper API","text":"<p>Serper API provides access to Google Search results programmatically. It allows applications, like AI agents, to perform real-time Google searches (including news, images, etc.) and get structured data back without needing to scrape web pages directly.</p> <ol> <li> <p>Follow ADK installation and setup guide.</p> </li> <li> <p>Install Dependencies: Install the necessary CrewAI tools package. For example, to use the SerperDevTool:</p> <pre><code>npm install adk-typescript crewai-tools\n</code></pre> </li> <li> <p>Obtain a Serper API KEY and set it as an environment variable.</p> <pre><code>// In your application\nprocess.env.SERPER_API_KEY = \"&lt;REPLACE_WITH_API_KEY&gt;\";\n\n// Or set it before running your application\n// export SERPER_API_KEY=&lt;REPLACE_WITH_API_KEY&gt;\n</code></pre> </li> <li> <p>Import: Import <code>CrewaiTool</code> from ADK and the desired CrewAI tool (e.g, <code>SerperDevTool</code>).</p> <pre><code>import { CrewaiTool } from 'adk-typescript';\nimport { SerperDevTool } from 'crewai-tools';\n</code></pre> </li> <li> <p>Instantiate &amp; Wrap: Create an instance of the CrewAI tool. Pass it to the <code>CrewaiTool</code> constructor. Crucially, you must provide a name and description to the ADK wrapper, as these are used by ADK's underlying model to understand when to use the tool.</p> <pre><code>// Instantiate the CrewAI tool\nconst serperToolInstance = new SerperDevTool({\n  nResults: 10,\n  saveFile: false,\n  searchType: \"news\",\n});\n\n// Wrap it with CrewaiTool for ADK, providing name and description\nconst adkSerperTool = new CrewaiTool({\n  name: \"InternetNewsSearch\",\n  description: \"Searches the internet specifically for recent news articles using Serper.\",\n  tool: serperToolInstance\n});\n</code></pre> </li> <li> <p>Add to Agent: Include the wrapped <code>CrewaiTool</code> instance in your agent's <code>tools</code> list.</p> <pre><code>import { Agent } from 'adk-typescript';\n\n// Define the ADK agent\nconst myAgent = new Agent({\n  name: \"crewai_search_agent\",\n  model: \"gemini-2.0-flash\",\n  description: \"Agent to find recent news using the Serper search tool.\",\n  instruction: \"I can find the latest news for you. What topic are you interested in?\",\n  tools: [adkSerperTool] // Add the wrapped tool here\n});\n</code></pre> </li> </ol>"},{"location":"tools/third-party-tools/#full-example-serper-api","title":"Full Example: Serper API","text":"<p>Here's the full code combining the steps above to create and run an agent using the CrewAI Serper API search tool.</p> <pre><code>// Import necessary modules\nimport { Agent, CrewaiTool, Runner, InMemorySessionService } from 'adk-typescript';\nimport { SerperDevTool } from 'crewai-tools';\n\n// Set your API key\n// In a real application, use environment variables or secure configuration\nprocess.env.SERPER_API_KEY = \"your-serper-api-key\";\n\nasync function main() {\n  // Instantiate the SerperDev tool from CrewAI\n  const serperTool = new SerperDevTool({\n    nResults: 10,\n    saveFile: false,\n    searchType: \"news\",\n  });\n\n  // Wrap it with CrewaiTool for ADK\n  const adkSerperTool = new CrewaiTool({\n    name: \"InternetNewsSearch\",\n    description: \"Searches the internet specifically for recent news articles using Serper.\",\n    tool: serperTool\n  });\n\n  // Create an agent with the tool\n  const agent = new Agent({\n    name: \"news_search_agent\",\n    model: \"gemini-2.0-flash\",\n    description: \"Agent to find recent news using the Serper search tool.\",\n    instruction: \"I can find the latest news for you. What topic are you interested in?\",\n    tools: [adkSerperTool]\n  });\n\n  // Set up session service and runner\n  const sessionService = new InMemorySessionService();\n  const session = await sessionService.createSession({\n    appName: \"serper_news_demo\",\n    userId: \"user123\"\n  });\n\n  const runner = new Runner({\n    appName: \"serper_news_demo\",\n    agent: agent,\n    sessionService: sessionService\n  });\n\n  // Function to run a query\n  async function runQuery(query: string) {\n    console.log(`\\nUser Query: ${query}\\n`);\n\n    // Create a content object for the query\n    const content = {\n      role: \"user\",\n      parts: [{ text: query }]\n    };\n\n    // Run the agent\n    for await (const event of runner.runAsync({\n      sessionId: session.id,\n      userId: \"user123\",\n      newMessage: content\n    })) {\n      if (event.content) {\n        console.log(\"Agent Response:\", event.content.parts[0]?.text || \"No text response\");\n      }\n    }\n  }\n\n  // Run a sample query\n  await runQuery(\"What's happening with climate change initiatives?\");\n}\n\n// Run the main function\nmain().catch(error =&gt; console.error(\"Error:\", error));\n</code></pre>"},{"location":"tutorials/","title":"ADK Tutorials!","text":"<p>Get started with the Agent Development Kit (ADK) through our collection of practical guides. These tutorials are designed in a simple, progressive, step-by-step fashion, introducing you to different ADK features and capabilities.</p> <p>This approach allows you to learn and build incrementally \u2013 starting with foundational concepts and gradually tackling more advanced agent development techniques. You'll explore how to apply these features effectively across various use cases, equipping you to build your own sophisticated agentic applications with ADK. Explore our collection below and happy building:</p> <ul> <li> <p> Agent Team</p> <p>Learn to build an intelligent multi-agent weather bot and master key ADK features: defining Tools, using multiple LLMs (Gemini, GPT, Claude) with LiteLLM, orchestrating agent delegation, adding memory with session state, and ensuring safety via callbacks.</p> <p> Start learning here</p> </li> </ul>"},{"location":"tutorials/agent-team/","title":"Build Your First Intelligent Agent Team: A Progressive Weather Bot with ADK","text":"<p>This tutorial extends from the Quickstart example for Agent Development Kit. Now, you're ready to dive deeper and construct a more sophisticated, multi-agent system.</p> <p>We'll embark on building a Weather Bot agent team, progressively layering advanced features onto a simple foundation. Starting with a single agent that can look up weather, we will incrementally add capabilities like:</p> <ul> <li>Leveraging different AI models (Gemini, GPT, Claude).</li> <li>Designing specialized sub-agents for distinct tasks (like greetings and farewells).</li> <li>Enabling intelligent delegation between agents.</li> <li>Giving agents memory using persistent session state.</li> <li>Implementing crucial safety guardrails using callbacks.</li> </ul> <p>Why a Weather Bot Team?</p> <p>This use case, while seemingly simple, provides a practical and relatable canvas to explore core ADK concepts essential for building complex, real-world agentic applications. You'll learn how to structure interactions, manage state, ensure safety, and orchestrate multiple AI \"brains\" working together.</p> <p>What is ADK Again?</p> <p>As a reminder, ADK is a TypeScript framework designed to streamline the development of applications powered by Large Language Models (LLMs). It offers robust building blocks for creating agents that can reason, plan, utilize tools, interact dynamically with users, and collaborate effectively within a team.</p> <p>In this advanced tutorial, you will master:</p> <ul> <li>\u2705 Tool Definition &amp; Usage: Crafting TypeScript functions (<code>tools</code>) that grant agents specific abilities (like fetching data) and instructing agents on how to use them effectively.</li> <li>\u2705 Multi-LLM Flexibility: Configuring agents to utilize various leading LLMs (Gemini, GPT-4o, Claude Sonnet) via LlmRegistry integration, allowing you to choose the best model for each task.</li> <li>\u2705 Agent Delegation &amp; Collaboration: Designing specialized sub-agents and enabling automatic routing (<code>auto flow</code>) of user requests to the most appropriate agent within a team.</li> <li>\u2705 Session State for Memory: Utilizing <code>Session</code> and <code>ToolContext</code> to enable agents to remember information across conversational turns, leading to more contextual interactions.</li> <li>\u2705 Safety Guardrails with Callbacks: Implementing <code>beforeModelCallback</code> and <code>beforeToolCallback</code> to inspect, modify, or block requests/tool usage based on predefined rules, enhancing application safety and control.</li> </ul> <p>Note on Execution Environment:</p> <p>This tutorial is structured for Node.js environments. Please keep the following in mind:</p> <ul> <li> <p>Asynchronous Code in TypeScript vs Python: Unlike Python which requires the <code>asyncio</code> library for asynchronous operations, TypeScript has native support for async/await patterns as part of the language. In the TypeScript version of ADK:</p> <ul> <li>No need to import <code>asyncio</code> - this was only required in the Python version</li> <li>Use <code>async</code>/<code>await</code> directly for asynchronous functions </li> <li>Use <code>for await (const event of generator)</code> syntax for async generators instead of Python's <code>async for event in generator</code></li> <li>Functions return <code>Promise&lt;T&gt;</code> instead of Python's coroutines</li> <li>Methods are marked with <code>async *</code> for async generator methods instead of Python's <code>async def</code> with <code>yield</code></li> </ul> </li> <li> <p>Manual Runner/Session Setup: The steps involve explicitly creating <code>InMemoryRunner</code> and session instances. This approach is shown because it gives you fine-grained control over the agent's execution lifecycle, session management, and state persistence.</p> </li> </ul> <p>Ready to build your agent team? Let's dive in!</p> <pre><code>// Step 0: Setup and Installation\n// Install ADK using npm\n\n// In your project directory, run:\n// npm install adk-typescript\n</code></pre> <pre><code>// Import necessary libraries\nimport { LlmAgent } from 'adk-typescript';\nimport { LlmRegistry } from 'adk-typescript/models';\nimport { InMemorySessionService } from 'adk-typescript/sessions';\nimport { Runner, InMemoryRunner } from 'adk-typescript';\nimport { Content, Part } from 'adk-typescript/models/types';\n\nconsole.log(\"Libraries imported.\");\n</code></pre> <pre><code>// Configure API Keys (Replace with your actual keys!)\n\n// --- IMPORTANT: Replace placeholders with your real API keys ---\n// Configure your .env file or set environment variables directly\n\n// Gemini API Key (Get from Google AI Studio: https://aistudio.google.com/app/apikey)\nprocess.env.GOOGLE_API_KEY = \"YOUR_GOOGLE_API_KEY\"; // &lt;--- REPLACE\n\n// [Optional]\n// OpenAI API Key (Get from OpenAI Platform: https://platform.openai.com/api-keys)\nprocess.env.OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'; // &lt;--- REPLACE\n\n// [Optional]\n// Anthropic API Key (Get from Anthropic Console: https://console.anthropic.com/settings/keys)\nprocess.env.ANTHROPIC_API_KEY = 'YOUR_ANTHROPIC_API_KEY'; // &lt;--- REPLACE\n\n// --- Verify Keys (Optional Check) ---\nconsole.log(\"API Keys Set:\");\nconsole.log(`Google API Key set: ${process.env.GOOGLE_API_KEY &amp;&amp; process.env.GOOGLE_API_KEY !== 'YOUR_GOOGLE_API_KEY' ? 'Yes' : 'No (REPLACE PLACEHOLDER!)'}`);\nconsole.log(`OpenAI API Key set: ${process.env.OPENAI_API_KEY &amp;&amp; process.env.OPENAI_API_KEY !== 'YOUR_OPENAI_API_KEY' ? 'Yes' : 'No (REPLACE PLACEHOLDER!)'}`);\nconsole.log(`Anthropic API Key set: ${process.env.ANTHROPIC_API_KEY &amp;&amp; process.env.ANTHROPIC_API_KEY !== 'YOUR_ANTHROPIC_API_KEY' ? 'Yes' : 'No (REPLACE PLACEHOLDER!)'}`);\n\n// --- Define Model Constants for easier use ---\n\nconst MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\";\n\n// Note: Specific model names might change. Refer to LlmRegistry documentation.\nconst MODEL_GPT_4O = \"openai/gpt-4o\";\nconst MODEL_CLAUDE_SONNET = \"anthropic/claude-3-sonnet-20240229\";\n\nconsole.log(\"\\nEnvironment configured.\");\n</code></pre>"},{"location":"tutorials/agent-team/#step-1-your-first-agent-basic-weather-lookup","title":"Step 1: Your First Agent - Basic Weather Lookup","text":"<p>Let's begin by building the fundamental component of our Weather Bot: a single agent capable of performing a specific task \u2013 looking up weather information. This involves creating two core pieces:</p> <ol> <li>A Tool: A TypeScript function that equips the agent with the ability to fetch weather data.  </li> <li>An Agent: The AI \"brain\" that understands the user's request, knows it has a weather tool, and decides when and how to use it.</li> </ol> <p>1. Define the Tool (<code>get_weather</code>)</p> <p>In ADK, Tools are the building blocks that give agents concrete capabilities beyond just text generation. They are typically regular TypeScript functions that perform specific actions, like calling an API, querying a database, or performing calculations.</p> <p>Our first tool will provide a mock weather report. This allows us to focus on the agent structure without needing external API keys yet. Later, you could easily swap this mock function with one that calls a real weather service.</p> <p>Key Concept: Docstrings are Crucial! The agent's LLM relies heavily on the function's docstring to understand:</p> <ul> <li>What the tool does.  </li> <li>When to use it.  </li> <li>What arguments it requires (<code>city: string</code>).  </li> <li>What information it returns.</li> </ul> <p>Best Practice: Write clear, descriptive, and accurate docstrings for your tools. This is essential for the LLM to use the tool correctly.</p> <pre><code>// @title Define the get_weather Tool\nasync function get_weather(\n    params: Record&lt;string, any&gt;,\n    context?: ToolContext\n): Promise&lt;any&gt; {\n    const city = params.city;\n    console.log(`--- Tool: get_weather called for city: ${city} ---`); // Log tool execution\n    const cityNormalized = city.toLowerCase().replace(\" \", \"\"); // Basic normalization\n\n    // Mock weather data\n    const mock_weather_db: Record&lt;string, any&gt; = {\n        \"newyork\": { status: \"success\", report: \"The weather in New York is sunny with a temperature of 25\u00b0C.\" },\n        \"london\": { status: \"success\", report: \"It's cloudy in London with a temperature of 15\u00b0C.\" },\n        \"tokyo\": { status: \"success\", report: \"Tokyo is experiencing light rain and a temperature of 18\u00b0C.\" },\n    };\n\n    if (mock_weather_db[cityNormalized]) {\n        return mock_weather_db[cityNormalized];\n    } else {\n        return { \n            status: \"error\", \n            error_message: `Sorry, I don't have weather information for '${city}'` \n        };\n    }\n}\n\n// Create a FunctionTool wrapper for our weather function\nconst weatherTool = new FunctionTool({\n    name: 'get_weather',\n    description: 'Gets the current weather for a specific location.',\n    fn: get_weather,\n    functionDeclaration: {\n        name: 'get_weather',\n        description: 'Gets the current weather for a specific location.',\n        parameters: {\n            type: 'object',\n            properties: {\n                city: {\n                    type: 'string',\n                    description: 'The city, address, or general location to get weather for.',\n                },\n            },\n            required: ['city'],\n        },\n    },\n});\n\n// Example tool usage (optional test) - this would be different in real code\nget_weather({ city: \"New York\" }, undefined).then(console.log);\nget_weather({ city: \"Paris\" }, undefined).then(console.log);\n</code></pre> <p>2. Define the Agent (<code>weather_agent</code>)</p> <p>Now, let's create the Agent itself. An <code>Agent</code> in ADK orchestrates the interaction between the user, the LLM, and the available tools.</p> <p>We configure it with several key parameters:</p> <ul> <li><code>name</code>: A unique identifier for this agent (e.g., \"weather_agent_v1\").  </li> <li><code>model</code>: Specifies which LLM to use (e.g., <code>MODEL_GEMINI_2_0_FLASH</code>). We'll start with a specific Gemini model.  </li> <li><code>description</code>: A concise summary of the agent's overall purpose. This becomes crucial later when other agents need to decide whether to delegate tasks to this agent.  </li> <li><code>instruction</code>: Detailed guidance for the LLM on how to behave, its persona, its goals, and specifically how and when to utilize its assigned <code>tools</code>.  </li> <li><code>tools</code>: A list containing the actual TypeScript tool functions the agent is allowed to use (e.g., <code>[get_weather]</code>).</li> </ul> <p>Best Practice: Provide clear and specific <code>instruction</code> prompts. The more detailed the instructions, the better the LLM can understand its role and how to use its tools effectively. Be explicit about error handling if needed.</p> <p>Best Practice: Choose descriptive <code>name</code> and <code>description</code> values. These are used internally by ADK and are vital for features like automatic delegation (covered later).</p> <pre><code>// @title Define the Weather Agent\n// Use one of the model constants defined earlier\nconst AGENT_MODEL = MODEL_GEMINI_2_0_FLASH; // Starting with Gemini\n\n// Import FunctionTool to wrap our function\nimport { FunctionTool } from 'adk-typescript/tools';\n\n// Create a FunctionTool wrapper for our weather function\nconst weatherTool = new FunctionTool({\n    name: 'get_weather',\n    description: 'Gets the current weather for a specific location.',\n    fn: get_weather,\n    functionDeclaration: {\n        name: 'get_weather',\n        description: 'Gets the current weather for a specific location.',\n        parameters: {\n            type: 'object',\n            properties: {\n                city: {\n                    type: 'string',\n                    description: 'The city, address, or general location to get weather for.',\n                },\n            },\n            required: ['city'],\n        },\n    },\n});\n\nconst weather_agent = new LlmAgent({\n    name: \"weather_agent_v1\",\n    model: AGENT_MODEL, // Can be a string for Gemini or an LlmRegistry object\n    description: \"Provides weather information for specific cities.\",\n    instruction: \"You are a helpful weather assistant. \"\n               + \"When the user asks for the weather in a specific city, \"\n               + \"use the 'get_weather' tool to find the information. \"\n               + \"If the tool returns an error, inform the user politely. \"\n               + \"If the tool is successful, present the weather report clearly.\",\n    tools: [weatherTool], // Pass the FunctionTool wrapper\n});\n\nconsole.log(`Agent '${weather_agent.name}' created using model '${AGENT_MODEL}'`);\n</code></pre> <p>3. Setup Runner and Session Service</p> <p>To manage conversations and execute the agent, we need two more components:</p> <ul> <li><code>Session</code>: Responsible for managing conversation history and state for different users and sessions. The <code>InMemorySessionService</code> is a simple implementation that stores everything in memory, suitable for testing and simple applications. It keeps track of the messages exchanged. We'll explore state persistence more in Step 4.  </li> <li><code>Runner</code>: The engine that orchestrates the interaction flow. It takes user input, routes it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the <code>Session</code>, and yields events representing the progress of the interaction.</li> </ul> <pre><code>// @title Setup Session Service and Runner\n\n// --- Session Management ---\n// Key Concept: Session stores conversation history &amp; state.\n// InMemorySessionService is simple, non-persistent storage for this tutorial.\nconst session_service = new InMemorySessionService();\n\n// Define constants for identifying the interaction context\nconst APP_NAME = \"weather_tutorial_app\";\nconst USER_ID = \"user_1\";\nconst SESSION_ID = \"session_001\"; // Using a fixed ID for simplicity\n\n// Create the specific session where the conversation will happen\nconst session = session_service.createSession(\n    APP_NAME,\n    USER_ID,\n    SESSION_ID\n);\nconsole.log(`Session created: App='${APP_NAME}', User='${USER_ID}', Session='${SESSION_ID}'`);\n\n// --- Runner ---\n// Key Concept: Runner orchestrates the agent execution loop.\nconst runner = new InMemoryRunner({\n    agent: weather_agent, // The agent we want to run\n    app_name: APP_NAME,   // Associates runs with our app\n    session_service: session_service // Uses our session manager\n});\nconsole.log(`Runner created for agent '${runner.agent.name}'`);\n</code></pre> <p>4. Interact with the Agent</p> <p>We need a way to send messages to our agent and receive its responses. Since LLM calls and tool executions can take time, ADK's <code>Runner</code> operates asynchronously.</p> <p>We'll define an <code>async</code> helper function (<code>call_agent_async</code>) that:</p> <ol> <li>Takes a user query string.  </li> <li>Packages it into the ADK <code>Content</code> format.  </li> <li>Calls <code>runner.runAsync</code>, providing the user/session context and the new message.  </li> <li>Iterates through the Events yielded by the runner. Events represent steps in the agent's execution (e.g., tool call requested, tool result received, intermediate LLM thought, final response).  </li> <li>Identifies and prints the final response event using <code>event.isFinalResponse()</code>.</li> </ol> <p>Why <code>async</code>? Interactions with LLMs and potentially tools (like external APIs) are I/O-bound operations. Using TypeScript's async/await pattern allows the program to handle these operations efficiently without blocking execution.</p> <pre><code>// @title Define Agent Interaction Function\n\nimport { LlmAgent } from 'adk-typescript';\nimport { Content, Part } from 'adk-typescript/models/types'; // For creating message Content/Parts\n\nasync function call_agent_async(query: string, runner: Runner, user_id: string, session_id: string): Promise&lt;any&gt; {\n  console.log(`\\n&gt;&gt;&gt; User Query: ${query}`);\n\n  // Prepare the user's message in ADK format\n  const content = new Content({ \n    role: 'user', \n    parts: [new Part({ text: query })]\n  });\n\n  let final_response_text = \"Agent did not produce a final response.\"; // Default\n\n  // Key Concept: runAsync executes the agent logic and yields Events.\n  // We iterate through events to find the final answer.\n  for await (const event of runner.runAsync({\n    userId: user_id,\n    sessionId: session_id,\n    content: content\n  })) {\n    // You can uncomment the line below to see *all* events during execution\n    // console.log(`  [Event] Author: ${event.author}, Type: ${event.constructor.name}, Final: ${event.isFinalResponse()}, Content: ${event.content}`);\n\n    // Key Concept: isFinalResponse() marks the concluding message for the turn.\n    if (event.isFinalResponse()) {\n      if (event.content &amp;&amp; event.content.parts) {\n         // Assuming text response in the first part\n         final_response_text = event.content.parts[0].text;\n      } else if (event.actions &amp;&amp; event.actions.escalate) { // Handle potential errors/escalations\n         final_response_text = `Agent escalated: ${event.errorMessage || 'No specific message.'}`;\n      }\n      // Add more checks here if needed (e.g., specific error codes)\n      break; // Stop processing events once the final response is found\n    }\n  }\n\n  console.log(`&lt;&lt;&lt; Agent Response: ${final_response_text}`);\n  return final_response_text;\n}\n</code></pre> <p>5. Run the Conversation</p> <p>Finally, let's test our setup by sending a few queries to the agent. We wrap our <code>async</code> calls in a main <code>async</code> function and run it using <code>await</code>.</p> <p>Watch the output:</p> <ul> <li>See the user queries.  </li> <li>Notice the <code>--- Tool: get_weather called... ---</code> logs when the agent uses the tool.  </li> <li>Observe the agent's final responses, including how it handles the case where weather data isn't available (for Paris).</li> </ul> <pre><code>// @title Run the Initial Conversation\n\n// We need an async function to await our interaction helper\nasync function run_conversation() {\n    await call_agent_async(\"What is the weather like in London?\",\n                                       runner,\n                                       USER_ID,\n                                       SESSION_ID);\n\n    await call_agent_async(\"How about Paris?\",\n                                       runner,\n                                       USER_ID,\n                                       SESSION_ID); // Expecting the tool's error message\n\n    await call_agent_async(\"Tell me the weather in New York\",\n                                       runner,\n                                       USER_ID,\n                                       SESSION_ID);\n}\n\n// Execute the conversation using then/catch as this is TypeScript\nrun_conversation().then(result =&gt; {\n    console.log(result);\n}).catch(error =&gt; {\n    console.error(`An error occurred: ${error}`);\n});\n\n// --- OR ---\n\n// Uncomment the following lines if running as a standard Node.js script (.ts file):\n// if (require.main === module) {\n//     run_conversation().then(() =&gt; {\n//         console.log(\"Conversation completed\");\n//     }).catch(error =&gt; {\n//         console.error(`An error occurred: ${error}`);\n//     });\n// }\n</code></pre> <p>Congratulations! You've successfully built and interacted with your first ADK agent. It understands the user's request, uses a tool to find information, and responds appropriately based on the tool's result.</p> <p>In the next step, we'll explore how to easily switch the underlying Language Model powering this agent.</p>"},{"location":"tutorials/agent-team/#step-2-going-multi-model-with-litellm-optional","title":"Step 2: Going Multi-Model with LiteLLM [Optional]","text":"<p>In Step 1, we built a functional Weather Agent powered by a specific Gemini model. While effective, real-world applications often benefit from the flexibility to use different Large Language Models (LLMs). Why?</p> <ul> <li>Performance: Some models excel at specific tasks (e.g., coding, reasoning, creative writing).</li> <li>Cost: Different models have varying price points.</li> <li>Capabilities: Models offer diverse features, context window sizes, and fine-tuning options.</li> <li>Availability/Redundancy: Having alternatives ensures your application remains functional even if one provider experiences issues.</li> </ul> <p>ADK makes switching between models seamless through its integration with the LiteLLM library. LiteLLM acts as a consistent interface to over 100 different LLMs.</p> <p>In this step, we will:</p> <ol> <li>Learn how to configure an ADK <code>Agent</code> to use models from providers like OpenAI (GPT) and Anthropic (Claude) using the <code>LiteLlm</code> wrapper.</li> <li>Define, configure (with their own sessions and runners), and immediately test instances of our Weather Agent, each backed by a different LLM.</li> <li>Interact with these different agents to observe potential variations in their responses, even when using the same underlying tool.</li> </ol> <p>1. Import <code>LiteLlm</code></p> <p>We imported this during the initial setup (Step 0), but it's the key component for multi-model support:</p> <pre><code>// @title 1. Import LiteLlm\nimport { LiteLlm } from 'adk-typescript/models';\n</code></pre> <p>2. Define and Test Multi-Model Agents</p> <p>Instead of passing only a model name string (which defaults to Google's Gemini models), we wrap the desired model identifier string within the <code>LiteLlm</code> class.</p> <ul> <li>Key Concept: <code>LiteLlm</code> Wrapper: The <code>LiteLlm(model=\"provider/model_name\")</code> syntax tells ADK to route requests for this agent through the LiteLLM library to the specified model provider.</li> </ul> <p>Make sure you have configured the necessary API keys for OpenAI and Anthropic in Step 0. We'll use the <code>call_agent_async</code> function (defined earlier, which now accepts <code>runner</code>, <code>user_id</code>, and <code>session_id</code>) to interact with each agent immediately after its setup.</p> <p>Each block below will: *   Define the agent using a specific LiteLLM model (<code>MODEL_GPT_4O</code> or <code>MODEL_CLAUDE_SONNET</code>). *   Create a new, separate <code>InMemorySessionService</code> and session specifically for that agent's test run. This keeps the conversation histories isolated for this demonstration. *   Create a <code>Runner</code> configured for the specific agent and its session service. *   Immediately call <code>call_agent_async</code> to send a query and test the agent.</p> <p>Best Practice: Use constants for model names (like <code>MODEL_GPT_4O</code>, <code>MODEL_CLAUDE_SONNET</code> defined in Step 0) to avoid typos and make code easier to manage.</p> <p>Error Handling: We wrap the agent definitions in <code>try...catch</code> blocks. This prevents the entire code cell from failing if an API key for a specific provider is missing or invalid, allowing the tutorial to proceed with the models that are configured.</p> <p>First, let's create and test the agent using OpenAI's GPT-4o.</p> <pre><code>// @title Define and Test GPT Agent\n\n// Make sure 'get_weather' function from Step 1 is defined in your environment.\n// Make sure 'call_agent_async' is defined from earlier.\n\n// --- Agent using GPT-4o ---\nlet weather_agent_gpt: LlmAgent | null = null; // Initialize to null\nlet runner_gpt: InMemoryRunner | null = null;      // Initialize runner to null\n\ntry {\n    weather_agent_gpt = new LlmAgent({\n        name: \"weather_agent_gpt\",\n        // Key change: Wrap the LiteLLM model identifier\n        model: new LiteLlm({ model: MODEL_GPT_4O }),\n        description: \"Provides weather information (using GPT-4o).\",\n        instruction: \"You are a helpful weather assistant powered by GPT-4o. \"\n                   + \"Use the 'get_weather' tool for city weather requests. \"\n                   + \"Clearly present successful reports or polite error messages based on the tool's output status.\",\n        tools: [weatherTool], // Use the same FunctionTool\n    });\n    console.log(`Agent '${weather_agent_gpt.name}' created using model '${MODEL_GPT_4O}'`);\n\n    // InMemorySessionService is simple, non-persistent storage for this tutorial.\n    const session_service_gpt = new InMemorySessionService(); // Create a dedicated service\n\n    // Define constants for identifying the interaction context\n    const APP_NAME_GPT = \"weather_tutorial_app_gpt\"; // Unique app name for this test\n    const USER_ID_GPT = \"user_1_gpt\";\n    const SESSION_ID_GPT = \"session_001_gpt\"; // Using a fixed ID for simplicity\n\n    // Create the specific session where the conversation will happen\n    const session_gpt = session_service_gpt.createSession({\n        appName: APP_NAME_GPT,\n        userId: USER_ID_GPT,\n        sessionId: SESSION_ID_GPT\n    });\n    console.log(`Session created: App='${APP_NAME_GPT}', User='${USER_ID_GPT}', Session='${SESSION_ID_GPT}'`);\n\n    // Create a runner specific to this agent and its session service\n    runner_gpt = new Runner({\n        agent: weather_agent_gpt,\n        appName: APP_NAME_GPT,       // Use the specific app name\n        sessionService: session_service_gpt // Use the specific session service\n    });\n    console.log(`Runner created for agent '${runner_gpt.agent.name}'`);\n\n    // --- Test the GPT Agent ---\n    console.log(\"\\n--- Testing GPT Agent ---\");\n    // Call the agent with the appropriate runner and session info\n    call_agent_async(\"What's the weather in Tokyo?\", runner_gpt, USER_ID_GPT, SESSION_ID_GPT).then(result =&gt; {\n        console.log(result);\n    }).catch(error =&gt; {\n        console.error(`An error occurred: ${error}`);\n    });\n\n} catch (error) {\n    console.error(`\u274c Could not create or run GPT agent '${MODEL_GPT_4O}'. Check API Key and model name. Error: ${error}`);\n}\n</code></pre> <p>Next, we'll do the same for Anthropic's Claude Sonnet.</p> <pre><code>// @title Define and Test Claude Agent\n\n// Make sure 'get_weather' function from Step 1 is defined in your environment.\n// Make sure 'call_agent_async' is defined from earlier.\n\n// --- Agent using Claude Sonnet ---\nlet weather_agent_claude: LlmAgent | null = null; // Initialize to null\nlet runner_claude: InMemoryRunner | null = null;      // Initialize runner to null\n\ntry {\n    weather_agent_claude = new LlmAgent({\n        name: \"weather_agent_claude\",\n        // Key change: Wrap the LiteLLM model identifier\n        model: new LiteLlm({ model: MODEL_CLAUDE_SONNET }),\n        description: \"Provides weather information (using Claude Sonnet).\",\n        instruction: \"You are a helpful weather assistant powered by Claude Sonnet. \"\n                    \"Use the 'get_weather' tool for city weather requests. \"\n                    \"Analyze the tool's dictionary output ('status', 'report'/'error_message'). \"\n                    \"Clearly present successful reports or polite error messages.\",\n        tools: [weatherTool], // Use the same FunctionTool\n    });\n    console.log(`Agent '${weather_agent_claude.name}' created using model '${MODEL_CLAUDE_SONNET}'`);\n\n    // InMemorySessionService is simple, non-persistent storage for this tutorial.\n    const session_service_claude = new InMemorySessionService(); // Create a dedicated service\n\n    // Define constants for identifying the interaction context\n    const APP_NAME_CLAUDE = \"weather_tutorial_app_claude\"; // Unique app name\n    const USER_ID_CLAUDE = \"user_1_claude\";\n    const SESSION_ID_CLAUDE = \"session_001_claude\"; // Using a fixed ID for simplicity\n\n    // Create the specific session where the conversation will happen\n    const session_claude = session_service_claude.createSession({\n        appName: APP_NAME_CLAUDE,\n        userId: USER_ID_CLAUDE,\n        sessionId: SESSION_ID_CLAUDE\n    });\n    console.log(`Session created: App='${APP_NAME_CLAUDE}', User='${USER_ID_CLAUDE}', Session='${SESSION_ID_CLAUDE}'`);\n\n    // Create a runner specific to this agent and its session service\n    runner_claude = new Runner({\n        agent: weather_agent_claude,\n        appName: APP_NAME_CLAUDE,       // Use the specific app name\n        sessionService: session_service_claude // Use the specific session service\n    });\n    console.log(`Runner created for agent '${runner_claude.agent.name}'`);\n\n    // --- Test the Claude Agent ---\n    console.log(\"\\n--- Testing Claude Agent ---\");\n    // Call the agent with the appropriate runner and session info\n    call_agent_async(\"Weather in London please.\", runner_claude, USER_ID_CLAUDE, SESSION_ID_CLAUDE).then(result =&gt; {\n        console.log(result);\n    }).catch(error =&gt; {\n        console.error(`An error occurred: ${error}`);\n    });\n\n} catch (error) {\n    console.error(`\u274c Could not create or run Claude agent '${MODEL_CLAUDE_SONNET}'. Check API Key and model name. Error: ${error}`);\n}\n</code></pre> <p>Observe the output carefully from both code blocks. You should see:</p> <ol> <li>Each agent (<code>weather_agent_gpt</code>, <code>weather_agent_claude</code>) is created successfully (if API keys are valid).</li> <li>A dedicated session and runner are set up for each.</li> <li>Each agent correctly identifies the need to use the <code>get_weather</code> tool when processing the query (you'll see the <code>--- Tool: get_weather called... ---</code> log).</li> <li>The underlying tool logic remains identical, always returning our mock data.</li> <li>However, the final textual response generated by each agent might differ slightly in phrasing, tone, or formatting. This is because the instruction prompt is interpreted and executed by different LLMs (GPT-4o vs. Claude Sonnet).</li> </ol> <p>This step demonstrates the power and flexibility ADK + LiteLLM provide. You can easily experiment with and deploy agents using various LLMs while keeping your core application logic (tools, fundamental agent structure) consistent.</p> <p>In the next step, we'll move beyond a single agent and build a small team where agents can delegate tasks to each other!</p>"},{"location":"tutorials/agent-team/#step-3-building-an-agent-team-delegation-for-greetings-farewells","title":"Step 3: Building an Agent Team - Delegation for Greetings &amp; Farewells","text":"<p>In Steps 1 and 2, we built and experimented with a single agent focused solely on weather lookups. While effective for its specific task, real-world applications often involve handling a wider variety of user interactions. We could keep adding more tools and complex instructions to our single weather agent, but this can quickly become unmanageable and less efficient.</p> <p>A more robust approach is to build an Agent Team. This involves:</p> <ol> <li>Creating multiple, specialized agents, each designed for a specific capability (e.g., one for weather, one for greetings, one for calculations).  </li> <li>Designating a root agent (or orchestrator) that receives the initial user request.  </li> <li>Enabling the root agent to delegate the request to the most appropriate specialized sub-agent based on the user's intent.</li> </ol> <p>Why build an Agent Team?</p> <ul> <li>Modularity: Easier to develop, test, and maintain individual agents.  </li> <li>Specialization: Each agent can be fine-tuned (instructions, model choice) for its specific task.  </li> <li>Scalability: Simpler to add new capabilities by adding new agents.  </li> <li>Efficiency: Allows using potentially simpler/cheaper models for simpler tasks (like greetings).</li> </ul> <p>In this step, we will:</p> <ol> <li>Define simple tools for handling greetings (<code>say_hello</code>) and farewells (<code>say_goodbye</code>).  </li> <li>Create two new specialized sub-agents: <code>greeting_agent</code> and <code>farewell_agent</code>.  </li> <li>Update our main weather agent (<code>weather_agent_v2</code>) to act as the root agent.  </li> <li>Configure the root agent with its sub-agents, enabling automatic delegation.  </li> <li>Test the delegation flow by sending different types of requests to the root agent.</li> </ol> <p>1. Define Tools for Sub-Agents</p> <p>First, let's create the simple TypeScript functions that will serve as tools for our new specialist agents. Remember, clear docstrings are vital for the agents that will use them.</p> <pre><code>// @title Define Tools for Greeting and Farewell Agents\n\n// Greeting function with proper parameters structure\nasync function say_hello(\n    params: Record&lt;string, any&gt;,\n    context?: ToolContext\n): Promise&lt;string&gt; {\n    const name = params.name || \"there\"; // Default to \"there\" if not provided\n    console.log(`--- Tool: say_hello called with name: ${name} ---`);\n    return `Hello, ${name}!`;\n}\n\n// Farewell function with proper parameters structure\nasync function say_goodbye(\n    params: Record&lt;string, any&gt;,\n    context?: ToolContext\n): Promise&lt;string&gt; {\n    console.log(`--- Tool: say_goodbye called ---`);\n    return \"Goodbye! Have a great day.\";\n}\n\n// Create FunctionTool wrappers\nconst helloTool = new FunctionTool({\n    name: 'say_hello',\n    description: 'Provides a simple greeting, optionally addressing the user by name.',\n    fn: say_hello,\n    functionDeclaration: {\n        name: 'say_hello',\n        description: 'Provides a simple greeting, optionally addressing the user by name.',\n        parameters: {\n            type: 'object',\n            properties: {\n                name: {\n                    type: 'string',\n                    description: 'The name of the person to greet. Defaults to \"there\" if not provided.'\n                }\n            },\n            required: []\n        }\n    }\n});\n\nconst goodbyeTool = new FunctionTool({\n    name: 'say_goodbye',\n    description: 'Provides a simple farewell message to conclude the conversation.',\n    fn: say_goodbye,\n    functionDeclaration: {\n        name: 'say_goodbye',\n        description: 'Provides a simple farewell message to conclude the conversation.',\n        parameters: {\n            type: 'object',\n            properties: {},\n            required: []\n        }\n    }\n});\n\nconsole.log(\"Greeting and Farewell tools defined.\");\n\n// Example tool usage (optional test)\nsay_hello({ name: \"Alice\" }, undefined).then(console.log);\nsay_goodbye({}, undefined).then(console.log);\n</code></pre> <p>2. Define the Sub-Agents (Greeting &amp; Farewell)</p> <p>Now, create the <code>Agent</code> instances for our specialists. Notice their highly focused <code>instruction</code> and, critically, their clear <code>description</code>. The <code>description</code> is the primary information the root agent uses to decide when to delegate to these sub-agents.</p> <p>Best Practice: Sub-agent <code>description</code> fields should accurately and concisely summarize their specific capability. This is crucial for effective automatic delegation.</p> <p>Best Practice: Sub-agent <code>instruction</code> fields should be tailored to their limited scope, telling them exactly what to do and what not to do (e.g., \"Your only task is...\").</p> <pre><code>// @title Define Greeting and Farewell Sub-Agents\n\n// --- Greeting Agent ---\nlet greeting_agent: LlmAgent | null = null;\ntry {\n    greeting_agent = new LlmAgent({\n        // Using a potentially different/cheaper model for a simple task\n        model: MODEL_GEMINI_2_0_FLASH,\n        // model: new LiteLlm({ model: MODEL_GPT_4O }), // If you would like to experiment with other models\n        name: \"greeting_agent\",\n        instruction: \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \"\n                   + \"Use the 'say_hello' tool to generate the greeting. \"\n                   + \"If the user provides their name, make sure to pass it to the tool. \"\n                   + \"Do not engage in any other conversation or tasks.\",\n        description: \"Handles simple greetings and hellos using the 'say_hello' tool.\", // Crucial for delegation\n        tools: [helloTool], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Agent '${greeting_agent.name}' created using model '${greeting_agent.model}'`);\n} catch (error) {\n    console.error(`\u274c Could not create Greeting agent. Check API Key (${greeting_agent?.model}). Error: ${error}`);\n}\n\n// --- Farewell Agent ---\nlet farewell_agent: LlmAgent | null = null;\ntry {\n    farewell_agent = new LlmAgent({\n        // Can use the same or a different model\n        model: MODEL_GEMINI_2_0_FLASH,\n        // model: new LiteLlm({ model: MODEL_GPT_4O }), // If you would like to experiment with other models\n        name: \"farewell_agent\",\n        instruction: \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \"\n                   + \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \"\n                   + \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \"\n                   + \"Do not perform any other actions.\",\n        description: \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\", // Crucial for delegation\n        tools: [goodbyeTool], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Agent '${farewell_agent.name}' created using model '${farewell_agent.model}'`);\n} catch (error) {\n    console.error(`\u274c Could not create Farewell agent. Check API Key (${farewell_agent?.model}). Error: ${error}`);\n}\n</code></pre> <p>3. Define the Root Agent (Weather Agent v2) with Sub-Agents</p> <p>Now, we upgrade our <code>weather_agent</code>. The key changes are:</p> <ul> <li>Adding the <code>sub_agents</code> parameter: We pass a list containing the <code>greeting_agent</code> and <code>farewell_agent</code> instances we just created.  </li> <li>Updating the <code>instruction</code>: We explicitly tell the root agent about its sub-agents and when it should delegate tasks to them.</li> </ul> <p>Key Concept: Automatic Delegation (Auto Flow) By providing the <code>sub_agents</code> list, ADK enables automatic delegation. When the root agent receives a user query, its LLM considers not only its own instructions and tools but also the <code>description</code> of each sub-agent. If the LLM determines that a query aligns better with a sub-agent's described capability (e.g., \"Handles simple greetings\"), it will automatically generate a special internal action to transfer control to that sub-agent for that turn. The sub-agent then processes the query using its own model, instructions, and tools.</p> <p>Best Practice: Ensure the root agent's instructions clearly guide its delegation decisions. Mention the sub-agents by name and describe the conditions under which delegation should occur.</p> <pre><code>// @title Define the Root Agent with Sub-Agents\n\n// Ensure sub-agents were created successfully before defining the root agent.\n// Also ensure the original 'get_weather' tool is defined.\nlet root_agent: LlmAgent | null = null;\nlet runner_root: InMemoryRunner | null = null; // Initialize runner\n\nif (greeting_agent &amp;&amp; farewell_agent &amp;&amp; 'get_weather' in globalThis) {\n    // Let's use a capable Gemini model for the root agent to handle orchestration\n    const root_agent_model = MODEL_GEMINI_2_0_FLASH;\n\n    const weather_agent_team = new LlmAgent({\n        name: \"weather_agent_v2\", // Give it a new version name\n        model: root_agent_model,\n        description: \"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\",\n        instruction: \"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \"\n                    \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \"\n                    \"You have specialized sub-agents: \"\n                    \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \"\n                    \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \"\n                    \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \"\n                    \"If it's a weather request, handle it yourself using 'get_weather'. \"\n                    \"For anything else, respond appropriately or state you cannot handle it.\",\n        tools: [weatherTool], // Root agent still needs the weather tool for its core task\n        // Key change: Link the sub-agents here!\n        sub_agents: [greeting_agent, farewell_agent]\n    });\n    console.log(`\u2705 Root Agent '${weather_agent_team.name}' created using model '${root_agent_model}' with sub-agents: [${weather_agent_team.sub_agents.map(sa =&gt; sa.name).join(', ')}]`);\n\n} else {\n    console.error(\"\u274c Cannot create root agent because one or more sub-agents failed to initialize or 'get_weather' tool is missing.\");\n    if (!greeting_agent) console.error(\" - Greeting Agent is missing.\");\n    if (!farewell_agent) console.error(\" - Farewell Agent is missing.\");\n    if (!'get_weather' in globalThis) console.error(\" - get_weather function is missing.\");\n}\n</code></pre> <p>4. Interact with the Agent Team</p> <p>Now that we've defined our root agent (<code>weather_agent_team</code> - Note: Ensure this variable name matches the one defined in the previous code block, likely <code># @title Define the Root Agent with Sub-Agents</code>, which might have named it <code>root_agent</code>) with its specialized sub-agents, let's test the delegation mechanism.</p> <p>The following code block will:</p> <ol> <li>Define an <code>async</code> function <code>run_team_conversation</code>.</li> <li>Inside this function, create a new, dedicated <code>InMemorySessionService</code> and a specific session (<code>session_001_agent_team</code>) just for this test run. This isolates the conversation history for testing the team dynamics.</li> <li>Create a <code>Runner</code> (<code>runner_agent_team</code>) configured to use our <code>weather_agent_team</code> (the root agent) and the dedicated session service.</li> <li>Use our updated <code>call_agent_async</code> function to send different types of queries (greeting, weather request, farewell) to the <code>runner_agent_team</code>. We explicitly pass the runner, user ID, and session ID for this specific test.</li> <li>Immediately execute the <code>run_team_conversation</code> function.</li> </ol> <p>We expect the following flow:</p> <ol> <li>The \"Hello there!\" query goes to <code>runner_agent_team</code>.</li> <li>The root agent (<code>weather_agent_team</code>) receives it and, based on its instructions and the <code>greeting_agent</code>'s description, delegates the task.</li> <li><code>greeting_agent</code> handles the query, calls its <code>say_hello</code> tool, and generates the response.</li> <li>The \"What is the weather in New York?\" query is not delegated and is handled directly by the root agent using its <code>get_weather</code> tool.</li> <li>The \"Thanks, bye!\" query is delegated to the <code>farewell_agent</code>, which uses its <code>say_goodbye</code> tool.</li> </ol> <pre><code>// @title Interact with the Agent Team\n\n// Ensure the root agent (e.g., 'weather_agent_team' or 'root_agent' from the previous cell) is defined.\n// Ensure the call_agent_async function is defined.\n\n// Check if the root agent variable exists before defining the conversation function\nlet root_agent_var_name = 'root_agent'; // Default name from Step 3 guide\nif ('weather_agent_team' in globalThis) { // Check if user used this name instead\n    root_agent_var_name = 'weather_agent_team';\n} else if (!('root_agent' in globalThis)) {\n    console.warn(\"\u26a0\ufe0f Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\");\n    // Assign a dummy value to prevent NameError later if the code block runs anyway\n    root_agent = null; // Or set a flag to prevent execution\n}\n\n// Only define and run if the root agent exists\nif (root_agent_var_name in globalThis &amp;&amp; globalThis[root_agent_var_name]) {\n    // Define the main async function for the conversation logic.\n    // The 'await' keywords INSIDE this function are necessary for async operations.\n    async function run_team_conversation() {\n        console.log(\"\\n--- Testing Agent Team Delegation ---\");\n        const session_service = new InMemorySessionService();\n        const APP_NAME = \"weather_tutorial_agent_team\";\n        const USER_ID = \"user_1_agent_team\";\n        const SESSION_ID = \"session_001_agent_team\";\n        const session = session_service.createSession(\n            APP_NAME,\n            USER_ID,\n            SESSION_ID\n        );\n        console.log(`Session created: App='${APP_NAME}', User='${USER_ID}', Session='${SESSION_ID}'`);\n\n        const actual_root_agent = globalThis[root_agent_var_name];\n        const runner_agent_team = new InMemoryRunner({\n            agent: actual_root_agent,\n            app_name: APP_NAME,\n            session_service: session_service // Uses our session manager\n        });\n        console.log(`Runner created for agent '${actual_root_agent.name}'`);\n\n        // --- Interactions using await (correct within async function) ---\n        await call_agent_async(\"Hello there!\", runner_agent_team, USER_ID, SESSION_ID);\n        await call_agent_async(\"What is the weather in New York?\", runner_agent_team, USER_ID, SESSION_ID);\n        await call_agent_async(\"Thanks, bye!\", runner_agent_team, USER_ID, SESSION_ID);\n    }\n\n    // --- Execute the `run_team_conversation` async function ---\n    // Choose ONE of the methods below based on your environment.\n    // Note: This may require API keys for the models used!\n\n    // METHOD 1: Direct Promise handling (Default for Node.js/TypeScript)\n    console.log(\"Executing run_team_conversation using Promise...\");\n    run_team_conversation().then(() =&gt; {\n        console.log(\"Team conversation completed successfully\");\n    }).catch(error =&gt; {\n        console.error(`An error occurred: ${error}`);\n    });\n\n    // METHOD 2: For Standard Node.js Scripts (.ts)\n    // If running this code as a standard Node.js script from your terminal\n    // To use this method:\n    // 1. Comment out the Promise-based execution above\n    // 2. Uncomment the following block:\n    /**\n    if (require.main === module) {\n        console.log(\"Executing run_team_conversation as main module...\");\n        run_team_conversation().then(() =&gt; {\n            console.log(\"Team conversation completed successfully\");\n        }).catch(error =&gt; {\n            console.error(`An error occurred: ${error}`);\n        });\n    }\n    */\n}\n</code></pre> <p>Look closely at the output logs, especially the <code>--- Tool: ... called ---</code> messages. You should observe:</p> <ul> <li>For \"Hello there!\", the <code>say_hello</code> tool was called (indicating <code>greeting_agent</code> handled it).</li> <li>For \"What is the weather in New York?\", the <code>get_weather</code> tool was called (indicating the root agent handled it).</li> <li>For \"Thanks, bye!\", the <code>say_goodbye</code> tool was called (indicating <code>farewell_agent</code> handled it).</li> </ul> <p>This confirms successful automatic delegation! The root agent, guided by its instructions and the <code>description</code>s of its <code>sub_agents</code>, correctly routed user requests to the appropriate specialist agent within the team.</p> <p>You've now structured your application with multiple collaborating agents. This modular design is fundamental for building more complex and capable agent systems. In the next step, we'll give our agents the ability to remember information across turns using session state.</p>"},{"location":"tutorials/agent-team/#step-4-adding-memory-and-personalization-with-session-state","title":"Step 4: Adding Memory and Personalization with Session State","text":"<p>So far, our agent team can handle different tasks through delegation, but each interaction starts fresh \u2013 the agents have no memory of past conversations or user preferences within a session. To create more sophisticated and context-aware experiences, agents need memory. ADK provides this through Session State.</p> <p>What is Session State?</p> <ul> <li>It's a TypeScript dictionary (<code>session.state</code>) tied to a specific user session (identified by <code>APP_NAME</code>, <code>USER_ID</code>, <code>SESSION_ID</code>).  </li> <li>It persists information across multiple conversational turns within that session.  </li> <li>Agents and Tools can read from and write to this state, allowing them to remember details, adapt behavior, and personalize responses.</li> </ul> <p>How Agents Interact with State:</p> <ol> <li><code>ToolContext</code> (Primary Method): Tools can accept a <code>ToolContext</code> object (automatically provided by ADK if declared as the last argument). This object gives direct access to the session state via <code>tool_context.state</code>, allowing tools to read preferences or save results during execution.  </li> <li><code>output_key</code> (Auto-Save Agent Response): An <code>Agent</code> can be configured with an <code>output_key=\"your_key\"</code>. ADK will then automatically save the agent's final textual response for a turn into <code>session.state[\"your_key\"]</code>.</li> </ol> <p>In this step, we will enhance our Weather Bot team by:</p> <ol> <li>Using a new <code>InMemorySessionService</code> to demonstrate state in isolation.  </li> <li>Initializing session state with a user preference for <code>temperature_unit</code>.  </li> <li>Creating a state-aware version of the weather tool (<code>get_weather_stateful</code>) that reads this preference via <code>ToolContext</code> and adjusts its output format (Celsius/Fahrenheit).  </li> <li>Updating the root agent to use this stateful tool and configuring it with an <code>output_key</code> to automatically save its final weather report to the session state.  </li> <li>Running a conversation to observe how the initial state affects the tool, how manual state changes alter subsequent behavior, and how <code>output_key</code> persists the agent's response.</li> </ol> <p>1. Initialize New Session Service and State</p> <p>To clearly demonstrate state management without interference from prior steps, we'll instantiate a new <code>InMemorySessionService</code>. We'll also create a session with an initial state defining the user's preferred temperature unit.</p> <pre><code>// @title 1. Initialize New Session Service and State\n\n// Import necessary session components\nimport { InMemorySessionService } from 'adk-typescript/sessions';\n\n// Create a NEW session service instance for this state demonstration\nconst session_service_stateful = new InMemorySessionService();\nconsole.log(\"\u2705 New InMemorySessionService created for state demonstration.\");\n\n// Define a NEW session ID for this part of the tutorial\nconst SESSION_ID_STATEFUL = \"session_state_demo_001\";\nconst USER_ID_STATEFUL = \"user_state_demo\";\n\n// Define initial state data - user prefers Celsius initially\nconst initial_state = {\n    \"user_preference_temperature_unit\": \"Celsius\"\n};\n\n// Create the session, providing the initial state\nconst session_stateful = session_service_stateful.createSession({\n    appName: APP_NAME, // Use the consistent app name\n    userId: USER_ID_STATEFUL,\n    sessionId: SESSION_ID_STATEFUL,\n    state: initial_state // Initialize state during creation\n});\nconsole.log(`\u2705 Session '${SESSION_ID_STATEFUL}' created for user '${USER_ID_STATEFUL}'`);\n\n// Verify the initial state was set correctly\nsession_service_stateful.getSession({\n    appName: APP_NAME,\n    userId: USER_ID_STATEFUL,\n    sessionId: SESSION_ID_STATEFUL\n}).then(retrieved_session =&gt; {\n    console.log(\"\\n--- Initial Session State ---\");\n    if (retrieved_session) {\n        console.log(retrieved_session.state);\n    } else {\n        console.error(\"Error: Could not retrieve session.\");\n    }\n});\n</code></pre> <p>2. Create State-Aware Weather Tool (<code>get_weather_stateful</code>)</p> <p>Now, we create a new version of the weather tool. Its key feature is accepting <code>tool_context: ToolContext</code> which allows it to access <code>tool_context.state</code>. It will read the <code>user_preference_temperature_unit</code> and format the temperature accordingly.</p> <ul> <li> <p>Key Concept: <code>ToolContext</code> This object is the bridge allowing your tool logic to interact with the session's context, including reading and writing state variables. ADK injects it automatically if defined as the last parameter of your tool function.</p> </li> <li> <p>Best Practice: When reading from state, use <code>dictionary.get('key', default_value)</code> to handle cases where the key might not exist yet, ensuring your tool doesn't crash.</p> </li> </ul> <pre><code>// Define stateful weather tool\nimport { ToolContext } from 'adk-typescript/tools';\n\nasync function get_weather_stateful(\n    params: Record&lt;string, any&gt;,\n    toolContext: ToolContext\n): Promise&lt;any&gt; {\n    const city = params.city;\n    console.log(`--- Tool: get_weather_stateful called for ${city} ---`);\n\n    // --- Read preference from state ---\n    const preferred_unit = toolContext.state.get(\"user_preference_temperature_unit\", \"Celsius\"); // Default to Celsius\n    console.log(`--- Tool: Reading state 'user_preference_temperature_unit': ${preferred_unit} ---`);\n\n    const cityNormalized = city.toLowerCase().replace(\" \", \"\");\n\n    // Mock weather data (always stored in Celsius internally)\n    const mock_weather_db: Record&lt;string, any&gt; = {\n        \"newyork\": { temp_c: 25, condition: \"sunny\" },\n        \"london\": { temp_c: 15, condition: \"cloudy\" },\n        \"tokyo\": { temp_c: 18, condition: \"light rain\" },\n    };\n\n    if (mock_weather_db[cityNormalized]) {\n        const data = mock_weather_db[cityNormalized];\n        const temp_c = data.temp_c;\n        const condition = data.condition;\n\n        // Format temperature based on state preference\n        let temp_value: number;\n        let temp_unit: string;\n        if (preferred_unit === \"Fahrenheit\") {\n            temp_value = (temp_c * 9/5) + 32; // Calculate Fahrenheit\n            temp_unit = \"\u00b0F\";\n        } else { // Default to Celsius\n            temp_value = temp_c;\n            temp_unit = \"\u00b0C\";\n        }\n\n        const report = `The weather in ${city.charAt(0).toUpperCase() + city.slice(1)} is ${condition} with a temperature of ${temp_value.toFixed(0)}${temp_unit}.`;\n        const result = { status: \"success\", report: report };\n        console.log(`--- Tool: Generated report in ${preferred_unit}. Result: ${JSON.stringify(result)} ---`);\n\n        // Example of writing back to state (optional for this tool)\n        toolContext.state[\"last_city_checked_stateful\"] = city;\n        console.log(`--- Tool: Updated state 'last_city_checked_stateful': ${city} ---`);\n\n        return result;\n    } else {\n        // Handle city not found\n        const error_msg = `Sorry, I don't have weather information for '${city}'`;\n        console.log(`--- Tool: City '${city}' not found. ---`);\n        return { status: \"error\", error_message: error_msg };\n    }\n}\n\n// Create a FunctionTool wrapper for the stateful weather function\nconst weatherStatefulTool = new FunctionTool({\n    name: 'get_weather_stateful',\n    description: 'Gets the current weather for a specific location, using unit preferences from state.',\n    fn: get_weather_stateful,\n    functionDeclaration: {\n        name: 'get_weather_stateful',\n        description: 'Gets the current weather for a specific location, using unit preferences from state.',\n        parameters: {\n            type: 'object',\n            properties: {\n                city: {\n                    type: 'string',\n                    description: 'The city, address, or general location to get weather for.',\n                }\n            },\n            required: ['city']\n        }\n    }\n});\n\n// We would use this tool in our agent like this:\n// const agent = new LlmAgent({\n//     ...\n//     tools: [weatherStatefulTool],\n//     ...\n// });\n</code></pre> <p>3. Redefine Sub-Agents and Update Root Agent</p> <p>To ensure this step is self-contained and builds correctly, we first redefine the <code>greeting_agent</code> and <code>farewell_agent</code> exactly as they were in Step 3. Then, we define our new root agent (<code>weather_agent_v4_stateful</code>):</p> <ul> <li>It uses the new <code>get_weather_stateful</code> tool.  </li> <li>It includes the greeting and farewell sub-agents for delegation.  </li> <li>Crucially, it sets <code>output_key=\"last_weather_report\"</code> which automatically saves its final weather response to the session state.</li> </ul> <pre><code>// @title 3. Redefine Sub-Agents and Update Root Agent with output_key\n\n// Ensure necessary imports: Agent, LiteLlm, Runner\nimport { LlmAgent } from 'adk-typescript';\nimport { LiteLlm } from 'adk-typescript/models';\nimport { InMemoryRunner } from 'adk-typescript';\n// Ensure tools 'say_hello', 'say_goodbye' are defined (from Step 3)\n// Ensure model constants MODEL_GPT_4O, MODEL_GEMINI_2_0_FLASH etc. are defined\n\n// --- Redefine Greeting Agent (from Step 3) ---\nlet greeting_agent: LlmAgent | null = null;\ntry {\n    greeting_agent = new LlmAgent({\n        model: MODEL_GEMINI_2_0_FLASH,\n        name: \"greeting_agent\",\n        instruction: \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n        description: \"Handles simple greetings and hellos using the 'say_hello' tool.\",\n        tools: [say_hello], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Agent '${greeting_agent.name}' redefined.`);\n} catch (error) {\n    console.error(`\u274c Could not redefine Greeting agent. Error: ${error}`);\n}\n\n// --- Redefine Farewell Agent (from Step 3) ---\nlet farewell_agent: LlmAgent | null = null;\ntry {\n    farewell_agent = new LlmAgent({\n        model: MODEL_GEMINI_2_0_FLASH,\n        name: \"farewell_agent\",\n        instruction: \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n        description: \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n        tools: [say_goodbye], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Agent '${farewell_agent.name}' redefined.`);\n} catch (error) {\n    console.error(`\u274c Could not redefine Farewell agent. Error: ${error}`);\n}\n\n// --- Define the Updated Root Agent ---\nlet root_agent_stateful: LlmAgent | null = null;\nlet runner_root_stateful: InMemoryRunner | null = null; // Initialize runner\n\n// Check prerequisites before creating the root agent\nif (greeting_agent &amp;&amp; farewell_agent &amp;&amp; 'get_weather_stateful' in globalThis) {\n\n    const root_agent_model = MODEL_GEMINI_2_0_FLASH; // Choose orchestration model\n\n    root_agent_stateful = new LlmAgent({\n        name: \"weather_agent_v4_stateful\", // New version name\n        model: root_agent_model,\n        description: \"Main agent: Provides weather (state-aware unit), delegates greetings/farewells, saves report to state.\",\n        instruction: \"You are the main Weather Agent. Your job is to provide weather using 'get_weather_stateful'. \"\n                    \"The tool will format the temperature based on user preference stored in state. \"\n                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n                    \"Handle only weather requests, greetings, and farewells.\",\n        tools: [get_weather_stateful], // Use the state-aware tool\n        sub_agents: [greeting_agent, farewell_agent], // Include sub-agents\n        output_key: \"last_weather_report\" // &lt;&lt;&lt; Auto-save agent's final weather response\n    });\n    console.log(`\u2705 Root Agent '${root_agent_stateful.name}' created using stateful tool and output_key.`);\n\n    // --- Create Runner for this Root Agent &amp; NEW Session Service ---\n    runner_root_stateful = new InMemoryRunner({\n        agent: root_agent_stateful,\n        app_name: APP_NAME,\n        session_service: session_service_stateful // Use the NEW stateful session service\n    });\n    console.log(`\u2705 Runner created for stateful root agent '${runner_root_stateful.agent.name}' using stateful session service.`);\n\n} else {\n    console.error(\"\u274c Cannot create stateful root agent. Prerequisites missing.\");\n    if (!greeting_agent) console.error(\" - greeting_agent definition missing.\");\n    if (!farewell_agent) console.error(\" - farewell_agent definition missing.\");\n    if (!'get_weather_stateful' in globalThis) console.error(\" - get_weather_stateful tool missing.\");\n}\n</code></pre> <p>4. Interact and Test State Flow</p> <p>Now, let's execute a conversation designed to test the state interactions using the <code>runner_root_stateful</code> (associated with our stateful agent and the <code>session_service_stateful</code>). We'll use the <code>call_agent_async</code> function defined earlier, ensuring we pass the correct runner, user ID (<code>USER_ID_STATEFUL</code>), and session ID (<code>SESSION_ID_STATEFUL</code>).</p> <p>The conversation flow will be:</p> <ol> <li>Check weather (London): The <code>get_weather_stateful</code> tool should read the initial \"Celsius\" preference from the session state initialized in Section 1. The root agent's final response (the weather report in Celsius) should get saved to <code>state['last_weather_report']</code> via the <code>output_key</code> configuration.</li> <li>Manually update state: We will directly modify the state stored within the <code>InMemorySessionService</code> instance (<code>session_service_stateful</code>).<ul> <li>Why direct modification? The <code>session_service.getSession()</code> method returns a copy of the session. Modifying that copy wouldn't affect the state used in subsequent agent runs. For this testing scenario with <code>InMemorySessionService</code>, we access the internal <code>sessions</code> dictionary to change the actual stored state value for <code>user_preference_temperature_unit</code> to \"Fahrenheit\". Note: In real applications, state changes are typically triggered by tools or agent logic returning <code>EventActions(state_delta=...)</code>, not direct manual updates.</li> </ul> </li> <li>Check weather again (New York): The <code>get_weather_stateful</code> tool should now read the updated \"Fahrenheit\" preference from the state and convert the temperature accordingly. The root agent's new response (weather in Fahrenheit) will overwrite the previous value in <code>state['last_weather_report']</code> due to the <code>output_key</code>.</li> <li>Greet the agent: Verify that delegation to the <code>greeting_agent</code> still works correctly alongside the stateful operations. This interaction will become the last response saved by <code>output_key</code> in this specific sequence.</li> <li>Inspect final state: After the conversation, we retrieve the session one last time (getting a copy) and print its state to confirm the <code>user_preference_temperature_unit</code> is indeed \"Fahrenheit\", observe the final value saved by <code>output_key</code> (which will be the greeting in this run), and see the <code>last_city_checked_stateful</code> value written by the tool.</li> </ol> <pre><code>// @title 4. Interact to Test State Flow and output_key\n\n// Ensure the stateful runner (runner_root_stateful) is available from the previous cell\n// Ensure call_agent_async, USER_ID_STATEFUL, SESSION_ID_STATEFUL, APP_NAME are defined\n\nif ('runner_root_stateful' in globalThis &amp;&amp; runner_root_stateful) {\n    // Define the main async function for the stateful conversation logic.\n    async function run_stateful_conversation() {\n        console.log(\"\\n--- Testing State: Temp Unit Conversion &amp; output_key ---\");\n\n        // 1. Check weather (Uses initial state: Celsius)\n        console.log(\"--- Turn 1: Requesting weather in London (expect Celsius) ---\");\n        await call_agent_async(\"What's the weather in London?\", runner_root_stateful, USER_ID_STATEFUL, SESSION_ID_STATEFUL);\n\n        // 2. Manually update state preference to Fahrenheit - DIRECTLY MODIFY STORAGE\n        console.log(\"\\n--- Manually Updating State: Setting unit to Fahrenheit ---\");\n        try {\n            // Access the internal storage directly - THIS IS SPECIFIC TO InMemorySessionService for testing\n            // NOTE: In production with persistent services (Database, VertexAI), you would\n            // typically update state via agent actions or specific service APIs if available,\n            // not by direct manipulation of internal storage.\n            const stored_session = session_service_stateful.sessions[APP_NAME][USER_ID_STATEFUL][SESSION_ID_STATEFUL];\n            stored_session.state[\"user_preference_temperature_unit\"] = \"Fahrenheit\";\n            // Optional: You might want to update the timestamp as well if any logic depends on it\n            // stored_session.last_update_time = Date.now();\n            console.log(`--- Stored session state updated. Current 'user_preference_temperature_unit': ${stored_session.state.get('user_preference_temperature_unit', 'Not Set')}`); // Added .get for safety\n        } catch (error) {\n            console.error(`--- Error: Could not retrieve session '${SESSION_ID_STATEFUL}' from internal storage for user '${USER_ID_STATEFUL}' in app '${APP_NAME}' to update state. Check IDs and if session was created. ---`);\n        }\n\n        // 3. Check weather again (Tool should now use Fahrenheit)\n        // This will also update 'last_weather_report' via output_key\n        console.log(\"\\n--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\");\n        await call_agent_async(\"Tell me the weather in New York.\", runner_root_stateful, USER_ID_STATEFUL, SESSION_ID_STATEFUL);\n\n        // 4. Test basic delegation (should still work)\n        // This will update 'last_weather_report' again, overwriting the NY weather report\n        console.log(\"\\n--- Turn 3: Sending a greeting ---\");\n        await call_agent_async(\"Hi!\", runner_root_stateful, USER_ID_STATEFUL, SESSION_ID_STATEFUL);\n    }\n\n    // --- Execute the `run_stateful_conversation` async function ---\n    // Choose ONE of the methods below based on your environment.\n\n    // METHOD 1: Direct Promise handling (Default for Node.js/TypeScript)\n    console.log(\"Executing run_stateful_conversation using Promise...\");\n    run_stateful_conversation().then(() =&gt; {\n        console.log(\"Stateful conversation completed successfully\");\n    }).catch(error =&gt; {\n        console.error(`An error occurred: ${error}`);\n    });\n\n    // METHOD 2: For Standard Node.js Scripts (.ts)\n    // If running this code as a standard Node.js script from your terminal\n    // To use this method:\n    // 1. Comment out the Promise-based execution above\n    // 2. Uncomment the following block:\n    /**\n    if (require.main === module) {\n        console.log(\"Executing run_stateful_conversation as main module...\");\n        run_stateful_conversation().then(() =&gt; {\n            console.log(\"Stateful conversation completed successfully\");\n        }).catch(error =&gt; {\n            console.error(`An error occurred: ${error}`);\n        });\n    }\n    */\n\n    // --- Inspect final session state after the conversation ---\n    // This block runs after either execution method completes.\n    console.log(\"\\n--- Inspecting Final Session State ---\");\n    session_service_stateful.getSession(APP_NAME, USER_ID_STATEFUL, SESSION_ID_STATEFUL).then(final_session =&gt; {\n        // Use .get() for safer access to potentially missing keys\n        console.log(`Final Preference: ${final_session.state.get('user_preference_temperature_unit', 'Not Set')}`);\n        console.log(`Final Last Weather Report (from output_key): ${final_session.state.get('last_weather_report', 'Not Set')}`);\n        console.log(`Final Last City Checked (by tool): ${final_session.state.get('last_city_checked_stateful', 'Not Set')}`);\n        // Print full state for detailed view\n        // console.log(`Full State Dict: ${JSON.stringify(final_session.state)}`); // Use as_dict() for clarity\n    }).catch(error =&gt; {\n        console.error(`\\n\u274c Error: Could not retrieve final session state. Error: ${error}`);\n    });\n\n} else {\n    console.warn(\"\\n\u26a0\ufe0f Skipping state test conversation. Stateful root agent runner ('runner_root_stateful') is not available.\");\n}\n</code></pre> <p>By reviewing the conversation flow and the final session state printout, you can confirm:</p> <ul> <li>State Read: The weather tool (<code>get_weather_stateful</code>) correctly read <code>user_preference_temperature_unit</code> from state, initially using \"Celsius\" for London.</li> <li>State Update: The direct modification successfully changed the stored preference to \"Fahrenheit\".</li> <li>State Read (Updated): The tool subsequently read \"Fahrenheit\" when asked for New York's weather and performed the conversion.</li> <li>Tool State Write: The tool successfully wrote the <code>last_city_checked_stateful</code> (\"New York\" after the second weather check) into the state via <code>tool_context.state</code>.</li> <li>Delegation: The delegation to the <code>greeting_agent</code> for \"Hi!\" functioned correctly even after state modifications.</li> <li><code>output_key</code>: The <code>output_key=\"last_weather_report\"</code> successfully saved the root agent's final response for each turn where the root agent was the one ultimately responding. In this sequence, the last response was the greeting (\"Hello, there!\"), so that overwrote the weather report in the state key.</li> <li>Final State: The final check confirms the preference persisted as \"Fahrenheit\".</li> </ul> <p>You've now successfully integrated session state to personalize agent behavior using <code>ToolContext</code>, manually manipulated state for testing <code>InMemorySessionService</code>, and observed how <code>output_key</code> provides a simple mechanism for saving the agent's last response to state. This foundational understanding of state management is key as we proceed to implement safety guardrails using callbacks in the next steps.</p>"},{"location":"tutorials/agent-team/#step-5-adding-safety-input-guardrail-with-beforemodelcallback","title":"Step 5: Adding Safety - Input Guardrail with <code>beforeModelCallback</code>","text":"<p>Our agent team is becoming more capable, remembering preferences and using tools effectively. However, in real-world scenarios, we often need safety mechanisms to control the agent's behavior before potentially problematic requests even reach the core Large Language Model (LLM).</p> <p>ADK provides Callbacks \u2013 functions that allow you to hook into specific points in the agent's execution lifecycle. The <code>beforeModelCallback</code> is particularly useful for input safety.</p> <p>What is <code>beforeModelCallback</code>?</p> <ul> <li>It's a TypeScript function you define that ADK executes just before an agent sends its compiled request (including conversation history, instructions, and the latest user message) to the underlying LLM.  </li> <li>Purpose: Inspect the request, modify it if necessary, or block it entirely based on predefined rules.</li> </ul> <p>Common Use Cases:</p> <ul> <li>Input Validation/Filtering: Check if user input meets criteria or contains disallowed content (like PII or keywords).  </li> <li>Guardrails: Prevent harmful, off-topic, or policy-violating requests from being processed by the LLM.  </li> <li>Dynamic Prompt Modification: Add timely information (e.g., from session state) to the LLM request context just before sending.</li> </ul> <p>How it Works:</p> <ol> <li>Define a function accepting <code>callback_context: CallbackContext</code> and <code>llm_request: LlmRequest</code>.  </li> <li><code>callback_context</code>: Provides access to agent info, session state (<code>callback_context.state</code>), etc.  </li> <li><code>llm_request</code>: Contains the full payload intended for the LLM (<code>contents</code>, <code>config</code>).  </li> <li>Inside the function:  </li> <li>Inspect: Examine <code>llm_request.contents</code> (especially the last user message).  </li> <li>Modify (Use Caution): You can change parts of <code>llm_request</code>.  </li> <li>Block (Guardrail): Return an <code>LlmResponse</code> object. ADK will send this response back immediately, skipping the LLM call for that turn.  </li> <li>Allow: Return <code>None</code>. ADK proceeds to call the LLM with the (potentially modified) request.</li> </ol> <p>In this step, we will:</p> <ol> <li>Define a <code>beforeModelCallback</code> function (<code>block_keyword_guardrail</code>) that checks the user's input for a specific keyword (\"BLOCK\").  </li> <li>Update our stateful root agent (<code>weather_agent_v4_stateful</code> from Step 4) to use this callback.  </li> <li>Create a new runner associated with this updated agent but using the same stateful session service to maintain state continuity.  </li> <li>Test the guardrail by sending both normal and keyword-containing requests.</li> </ol> <p>1. Define the Guardrail Callback Function</p> <p>This function will inspect the last user message within the <code>llm_request</code> content. If it finds \"BLOCK\" (case-insensitive), it constructs and returns an <code>LlmResponse</code> to block the flow; otherwise, it returns <code>None</code>.  </p> <pre><code>// @title 1. Define the beforeModelCallback Guardrail\n\n// Ensure necessary imports are available\nimport { CallbackContext } from 'adk-typescript/agents';\nimport { LlmRequest } from 'adk-typescript/models';\nimport { LlmResponse } from 'adk-typescript/models';\nimport { Content, Part } from 'adk-typescript/models/types'; // For creating response content\nimport { Optional } from 'typescript';\n\nfunction block_keyword_guardrail(\n    callbackContext: CallbackContext, \n    llmRequest: LlmRequest\n): LlmResponse | undefined {\n    /**\n     * Inspects the latest user message for 'BLOCK'. If found, blocks the LLM call\n     * and returns a predefined LlmResponse. Otherwise, returns undefined to proceed.\n     */\n    const agentName = callbackContext.agentName; // Get the name of the agent whose model call is being intercepted\n    console.log(`--- Callback: block_keyword_guardrail running for agent: ${agentName} ---`);\n\n    // Extract the text from the latest user message in the request history\n    let lastUserMessageText = \"\";\n    if (llmRequest.contents) {\n        // Find the most recent message with role 'user'\n        for (let i = llmRequest.contents.length - 1; i &gt;= 0; i--) {\n            const content = llmRequest.contents[i];\n            if (content.role === 'user' &amp;&amp; content.parts &amp;&amp; content.parts.length &gt; 0) {\n                // Assuming text is in the first part for simplicity\n                if (content.parts[0].text) {\n                    lastUserMessageText = content.parts[0].text;\n                    break; // Found the last user message text\n                }\n            }\n        }\n    }\n\n    console.log(`--- Callback: Inspecting last user message: '${lastUserMessageText.slice(0, 100)}...' ---`); // Log first 100 chars\n\n    // --- Guardrail Logic ---\n    const keywordToBlock = \"BLOCK\";\n    if (lastUserMessageText.toUpperCase().includes(keywordToBlock)) { // Case-insensitive check\n        console.log(`--- Callback: Found '${keywordToBlock}'. Blocking LLM call! ---`);\n        // Optionally, set a flag in state to record the block event\n        callbackContext.state[\"guardrail_block_keyword_triggered\"] = true;\n        console.log(`--- Callback: Set state 'guardrail_block_keyword_triggered': true ---`);\n\n        // Construct and return an LlmResponse to stop the flow and send this back instead\n        return new LlmResponse({\n            content: new Content({\n                role: \"model\", // Mimic a response from the agent's perspective\n                parts: [new Part({ \n                    text: `I cannot process this request because it contains the blocked keyword '${keywordToBlock}'.` \n                })],\n            })\n            // Note: You could also set an errorMessage field here if needed\n        });\n    } else {\n        // Keyword not found, allow the request to proceed to the LLM\n        console.log(`--- Callback: Keyword not found. Allowing LLM call for ${agentName}. ---`);\n        return undefined; // Returning undefined signals ADK to continue normally\n    }\n}\n\nconsole.log(\"\u2705 block_keyword_guardrail function defined.\");\n</code></pre> <p>2. Update Root Agent to Use the Callback</p> <p>We redefine the root agent, adding the <code>beforeModelCallback</code> parameter and pointing it to our new guardrail function. We'll give it a new version name for clarity.</p> <p>Important: We need to redefine the sub-agents (<code>greeting_agent</code>, <code>farewell_agent</code>) and the stateful tool (<code>get_weather_stateful</code>) within this context if they are not already available from previous steps, ensuring the root agent definition has access to all its components.</p> <pre><code>// @title 2. Update Root Agent with beforeModelCallback\n\n\n// --- Redefine Sub-Agents (Ensures they exist in this context) ---\nlet greeting_agent: LlmAgent | null = null;\ntry {\n    // Use a defined model constant\n    greeting_agent = new LlmAgent({\n        model: MODEL_GEMINI_2_0_FLASH,\n        name: \"greeting_agent\", // Keep original name for consistency\n        instruction: \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n        description: \"Handles simple greetings and hellos using the 'say_hello' tool.\",\n        tools: [say_hello], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Sub-Agent '${greeting_agent.name}' redefined.`);\n} catch (error) {\n    console.error(`\u274c Could not redefine Greeting agent. Check Model/API Key (${greeting_agent?.model}). Error: ${error}`);\n}\n\nfarewell_agent = null;\ntry {\n    // Use a defined model constant\n    farewell_agent = new LlmAgent({\n        model: MODEL_GEMINI_2_0_FLASH,\n        name: \"farewell_agent\", // Keep original name\n        instruction: \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n        description: \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n        tools: [say_goodbye], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Sub-Agent '${farewell_agent.name}' redefined.`);\n} catch (error) {\n    console.error(`\u274c Could not redefine Farewell agent. Check Model/API Key (${farewell_agent?.model}). Error: ${error}`);\n}\n\n\n// --- Define the Root Agent with the Callback ---\nlet root_agent_model_guardrail: LlmAgent | null = null;\nlet runner_root_model_guardrail: InMemoryRunner | null = null;\n\n// Check all components before proceeding\nif (greeting_agent &amp;&amp; farewell_agent &amp;&amp; 'get_weather_stateful' in globalThis &amp;&amp; 'block_keyword_guardrail' in globalThis) {\n\n    // Use a defined model constant\n    const root_agent_model = MODEL_GEMINI_2_0_FLASH;\n\n    root_agent_model_guardrail = new LlmAgent({\n        name: \"weather_agent_v5_model_guardrail\", // New version name for clarity\n        model: root_agent_model,\n        description: \"Main agent: Handles weather, delegates greetings/farewells, includes input keyword guardrail.\",\n        instruction: \"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n                    \"Handle only weather requests, greetings, and farewells.\",\n        tools: [weatherTool],\n        sub_agents: [greeting_agent, farewell_agent], // Reference the redefined sub-agents\n        output_key: \"last_weather_report\", // Keep output_key from Step 4\n        beforeModelCallback: block_keyword_guardrail // &lt;&lt;&lt; Assign the guardrail callback\n    });\n    console.log(`\u2705 Root Agent '${root_agent_model_guardrail.name}' created with beforeModelCallback.`);\n\n    // --- Create Runner for this Agent, Using SAME Stateful Session Service ---\n    // Ensure session_service_stateful exists from Step 4\n    if ('session_service_stateful' in globalThis) {\n        runner_root_model_guardrail = new InMemoryRunner({\n            agent: root_agent_model_guardrail,\n            app_name: APP_NAME, // Use consistent APP_NAME\n            session_service: session_service_stateful // &lt;&lt;&lt; Use the service from Step 4\n        });\n        console.log(`\u2705 Runner created for guardrail agent '${runner_root_model_guardrail.agent.name}', using stateful session service.`);\n    } else {\n        console.error(\"\u274c Cannot create runner. 'session_service_stateful' from Step 4 is missing.\");\n    }\n\n} else {\n    console.error(\"\u274c Cannot create root agent with model guardrail. One or more prerequisites are missing or failed initialization:\");\n    if (!greeting_agent) console.error(\"   - Greeting Agent\");\n    if (!farewell_agent) console.error(\"   - Farewell Agent\");\n    if (!'get_weather_stateful' in globalThis) console.error(\"   - 'get_weather_stateful' tool\");\n    if (!'block_keyword_guardrail' in globalThis) console.error(\"   - 'block_keyword_guardrail' callback\");\n}\n</code></pre> <p>3. Interact to Test the Guardrail</p> <p>Let's test the guardrail's behavior. We'll use the same session (<code>SESSION_ID_STATEFUL</code>) as in Step 4 to show that state persists across these changes.</p> <ol> <li>Send a normal weather request (should pass the guardrail and execute).  </li> <li>Send a request containing \"BLOCK\" (should be intercepted by the callback).  </li> <li>Send a greeting (should pass the root agent's guardrail, be delegated, and execute normally).</li> </ol>"},{"location":"tutorials/agent-team/#title-3-interact-to-test-the-model-input-guardrail-ensure-the-runner-for-the-guardrail-agent-is-available-if-runner_root_model_guardrail-in-globalthis-runner_root_model_guardrail-define-the-main-async-function-for-the-guardrail-test-conversation-the-await-keywords-inside-this-function-are-necessary-for-async-operations-async-function-run_guardrail_test_conversation-consolelogn-testing-model-input-guardrail-use-the-runner-for-the-agent-with-the-callback-and-the-existing-stateful-session-id-define-a-helper-lambda-for-cleaner-interaction-calls-const-interaction_func-query-string-call_agent_asyncquery-runner_root_model_guardrail-user_id_stateful-use-existing-user-id-session_id_stateful-use-existing-session-id-1-normal-request-callback-allows-should-use-fahrenheit-from-previous-state-change-consolelog-turn-1-requesting-weather-in-london-expect-allowed-fahrenheit-interaction_funcwhat-is-the-weather-in-londonthenresult-consolelogresult-catcherror-consoleerroran-error-occurred-error-2-request-containing-the-blocked-keyword-callback-intercepts-consolelogn-turn-2-requesting-with-blocked-keyword-expect-blocked-interaction_funcblock-the-request-for-weather-in-tokyothenresult-consolelogresult-catcherror-consoleerroran-error-occurred-error-3-normal-greeting-callback-allows-root-agent-delegation-happens-consolelogn-turn-3-sending-a-greeting-expect-allowed-interaction_funchello-againthenresult-consolelogresult-catcherror-consoleerroran-error-occurred-error-execute-the-run_guardrail_test_conversation-async-function-choose-one-of-the-methods-below-based-on-your-environment-method-1-direct-promise-handling-default-for-nodejstypescript-consolelogexecuting-run_guardrail_test_conversation-using-promise-run_guardrail_test_conversationthen-consolelogguardrail-test-conversation-completed-successfully-catcherror-consoleerroran-error-occurred-error-method-2-for-standard-nodejs-scripts-ts-if-running-this-code-as-a-standard-nodejs-script-from-your-terminal-to-use-this-method-1-comment-out-the-promise-based-execution-above-2-uncomment-the-following-block-if-requiremain-module-consolelogexecuting-run_guardrail_test_conversation-as-main-module-run_guardrail_test_conversationthen-consolelogguardrail-test-conversation-completed-successfully-catcherror-consoleerroran-error-occurred-error-inspect-final-session-state-after-the-conversation-this-block-runs-after-either-execution-method-completes-optional-check-state-for-the-trigger-flag-set-by-the-callback-consolelogn-inspecting-final-session-state-after-guardrail-test-use-the-session-service-instance-associated-with-this-stateful-session-session_service_statefulgetsession-appname-app_name-userid-user_id_stateful-sessionid-session_id_stateful-thenfinalsession-use-get-for-safer-access-consolelogguardrail-triggered-flag-finalsessionstategetguardrail_block_keyword_triggered-not-set-or-false-consoleloglast-weather-report-finalsessionstategetlast_weather_report-not-set-should-be-london-weather-if-successful-consolelogtemperature-unit-finalsessionstategetuser_preference_temperature_unit-not-set-should-be-fahrenheit-catcherror-consoleerrorn-error-could-not-retrieve-final-session-state-error-error-else-consolewarnn-skipping-model-guardrail-test-runner-runner_root_model_guardrail-is-not-available","title":"<pre><code>// @title 3. Interact to Test the Model Input Guardrail\n\n// Ensure the runner for the guardrail agent is available\nif ('runner_root_model_guardrail' in globalThis &amp;&amp; runner_root_model_guardrail) {\n    // Define the main async function for the guardrail test conversation.\n    // The 'await' keywords INSIDE this function are necessary for async operations.\n    async function run_guardrail_test_conversation() {\n        console.log(\"\\n--- Testing Model Input Guardrail ---\");\n\n        // Use the runner for the agent with the callback and the existing stateful session ID\n        // Define a helper lambda for cleaner interaction calls\n        const interaction_func = (query: string) =&gt; call_agent_async(query,\n                                                                 runner_root_model_guardrail,\n                                                                 USER_ID_STATEFUL, // Use existing user ID\n                                                                 SESSION_ID_STATEFUL // Use existing session ID\n                                                                );\n        // 1. Normal request (Callback allows, should use Fahrenheit from previous state change)\n        console.log(\"--- Turn 1: Requesting weather in London (expect allowed, Fahrenheit) ---\");\n        interaction_func(\"What is the weather in London?\").then(result =&gt; {\n            console.log(result);\n        }).catch(error =&gt; {\n            console.error(`An error occurred: ${error}`);\n        });\n\n        // 2. Request containing the blocked keyword (Callback intercepts)\n        console.log(\"\\n--- Turn 2: Requesting with blocked keyword (expect blocked) ---\");\n        interaction_func(\"BLOCK the request for weather in Tokyo\").then(result =&gt; {\n            console.log(result);\n        }).catch(error =&gt; {\n            console.error(`An error occurred: ${error}`);\n        });\n\n        // 3. Normal greeting (Callback allows root agent, delegation happens)\n        console.log(\"\\n--- Turn 3: Sending a greeting (expect allowed) ---\");\n        interaction_func(\"Hello again\").then(result =&gt; {\n            console.log(result);\n        }).catch(error =&gt; {\n            console.error(`An error occurred: ${error}`);\n        });\n    }\n\n    // --- Execute the `run_guardrail_test_conversation` async function ---\n    // Choose ONE of the methods below based on your environment.\n\n    // METHOD 1: Direct Promise handling (Default for Node.js/TypeScript)\n    console.log(\"Executing run_guardrail_test_conversation using Promise...\");\n    run_guardrail_test_conversation().then(() =&gt; {\n        console.log(\"Guardrail test conversation completed successfully\");\n    }).catch(error =&gt; {\n        console.error(`An error occurred: ${error}`);\n    });\n\n    // METHOD 2: For Standard Node.js Scripts (.ts)\n    // If running this code as a standard Node.js script from your terminal\n    // To use this method:\n    // 1. Comment out the Promise-based execution above\n    // 2. Uncomment the following block:\n    /**\n    if (require.main === module) {\n        console.log(\"Executing run_guardrail_test_conversation as main module...\");\n        run_guardrail_test_conversation().then(() =&gt; {\n            console.log(\"Guardrail test conversation completed successfully\");\n        }).catch(error =&gt; {\n            console.error(`An error occurred: ${error}`);\n        });\n    }\n    */\n\n    // --- Inspect final session state after the conversation ---\n    // This block runs after either execution method completes.\n    // Optional: Check state for the trigger flag set by the callback\n    console.log(\"\\n--- Inspecting Final Session State (After Guardrail Test) ---\");\n    // Use the session service instance associated with this stateful session\n    session_service_stateful.getSession({\n        appName: APP_NAME, \n        userId: USER_ID_STATEFUL, \n        sessionId: SESSION_ID_STATEFUL\n    }).then(finalSession =&gt; {\n        // Use .get() for safer access\n        console.log(`Guardrail Triggered Flag: ${finalSession.state.get('guardrail_block_keyword_triggered', 'Not Set (or False)')}`)\n        console.log(`Last Weather Report: ${finalSession.state.get('last_weather_report', 'Not Set')}`); // Should be London weather if successful\n        console.log(`Temperature Unit: ${finalSession.state.get('user_preference_temperature_unit', 'Not Set')}`); // Should be Fahrenheit\n    }).catch(error =&gt; {\n        console.error(`\\n\u274c Error: Could not retrieve final session state. Error: ${error}`);\n    });\n\n} else {\n    console.warn(\"\\n\u26a0\ufe0f Skipping model guardrail test. Runner ('runner_root_model_guardrail') is not available.\");\n}\n</code></pre>","text":"<p>Observe the execution flow:</p> <ol> <li>London Weather: The callback runs for <code>weather_agent_v5_model_guardrail</code>, inspects the message, prints \"Keyword not found. Allowing LLM call.\", and returns <code>None</code>. The agent proceeds, calls the <code>get_weather_stateful</code> tool (which uses the \"Fahrenheit\" preference from Step 4's state change), and returns the weather. This response updates <code>last_weather_report</code> via <code>output_key</code>.  </li> <li>BLOCK Request: The callback runs again for <code>weather_agent_v5_model_guardrail</code>, inspects the message, finds \"BLOCK\", prints \"Blocking LLM call!\", sets the state flag, and returns the predefined <code>LlmResponse</code>. The agent's underlying LLM is never called for this turn. The user sees the callback's blocking message.  </li> <li>Hello Again: The callback runs for <code>weather_agent_v5_model_guardrail</code>, allows the request. The root agent then delegates to <code>greeting_agent</code>. Note: The <code>beforeModelCallback</code> defined on the root agent does NOT automatically apply to sub-agents. The <code>greeting_agent</code> proceeds normally, calls its <code>say_hello</code> tool, and returns the greeting.</li> </ol> <p>You have successfully implemented an input safety layer! The <code>beforeModelCallback</code> provides a powerful mechanism to enforce rules and control agent behavior before expensive or potentially risky LLM calls are made. Next, we'll apply a similar concept to add guardrails around tool usage itself.</p>"},{"location":"tutorials/agent-team/#step-6-adding-safety-tool-argument-guardrail-beforetoolcallback","title":"Step 6: Adding Safety - Tool Argument Guardrail (<code>beforeToolCallback</code>)","text":"<p>In Step 5, we added a guardrail to inspect and potentially block user input before it reached the LLM. Now, we'll add another layer of control after the LLM has decided to use a tool but before that tool actually executes. This is useful for validating the arguments the LLM wants to pass to the tool.</p> <p>ADK provides the <code>beforeToolCallback</code> for this precise purpose.</p> <p>What is <code>beforeToolCallback</code>?</p> <ul> <li>It's a TypeScript function executed just before a specific tool function runs, after the LLM has requested its use and decided on the arguments.  </li> <li>Purpose: Validate tool arguments, prevent tool execution based on specific inputs, modify arguments dynamically, or enforce resource usage policies.</li> </ul> <p>Common Use Cases:</p> <ul> <li>Argument Validation: Check if arguments provided by the LLM are valid, within allowed ranges, or conform to expected formats.  </li> <li>Resource Protection: Prevent tools from being called with inputs that might be costly, access restricted data, or cause unwanted side effects (e.g., blocking API calls for certain parameters).  </li> <li>Dynamic Argument Modification: Adjust arguments based on session state or other contextual information before the tool runs.</li> </ul> <p>How it Works:</p> <ol> <li>Define a function accepting <code>tool: BaseTool</code>, <code>args: Record&lt;string, any&gt;</code>, and <code>tool_context: ToolContext</code>.  </li> <li><code>tool</code>: The tool object about to be called (inspect <code>tool.name</code>).  </li> <li><code>args</code>: The dictionary of arguments the LLM generated for the tool.  </li> <li><code>tool_context</code>: Provides access to session state (<code>tool_context.state</code>), agent info, etc.  </li> <li>Inside the function:  </li> <li>Inspect: Examine the <code>tool.name</code> and the <code>args</code> dictionary.  </li> <li>Modify: Change values within the <code>args</code> dictionary directly. If you return <code>None</code>, the tool runs with these modified args.  </li> <li>Block/Override (Guardrail): Return a dictionary. ADK treats this dictionary as the result of the tool call, completely skipping the execution of the original tool function. The dictionary should ideally match the expected return format of the tool it's blocking.  </li> <li>Allow: Return <code>None</code>. ADK proceeds to execute the actual tool function with the (potentially modified) arguments.</li> </ol> <p>In this step, we will:</p> <ol> <li>Define a <code>beforeToolCallback</code> function (<code>block_paris_tool_guardrail</code>) that specifically checks if the <code>get_weather_stateful</code> tool is called with the city \"Paris\".  </li> <li>If \"Paris\" is detected, the callback will block the tool and return a custom error dictionary.  </li> <li>Update our root agent (<code>weather_agent_v6_tool_guardrail</code>) to include both the <code>beforeModelCallback</code> and this new <code>beforeToolCallback</code>.  </li> <li>Create a new runner for this agent, using the same stateful session service.  </li> <li>Test the flow by requesting weather for allowed cities and the blocked city (\"Paris\").</li> </ol> <p>1. Define the Tool Guardrail Callback Function</p> <p>This function targets the <code>get_weather_stateful</code> tool. It checks the <code>city</code> argument. If it's \"Paris\", it returns an error dictionary that looks like the tool's own error response. Otherwise, it allows the tool to run by returning <code>None</code>.</p> <pre><code>// @title 1. Define the beforeToolCallback Guardrail\n\n// Ensure necessary imports are available\nimport { BaseTool } from 'adk-typescript/tools';\nimport { ToolContext } from 'adk-typescript/tools';\nimport { Optional } from 'typescript';\n\nfunction block_paris_tool_guardrail(\n    tool: BaseTool, \n    args: Record&lt;string, any&gt;, \n    toolContext: ToolContext\n): Record&lt;string, any&gt; | undefined {\n    /**\n     * Checks if 'get_weather_stateful' is called for 'Paris'.\n     * If so, blocks the tool execution and returns a specific error dictionary.\n     * Otherwise, allows the tool call to proceed by returning undefined.\n     */\n    const toolName = tool.name;\n    const agentName = toolContext.agentName; // Agent attempting the tool call\n    console.log(`--- Callback: block_paris_tool_guardrail running for tool '${toolName}' in agent '${agentName}' ---`);\n    console.log(`--- Callback: Inspecting args: ${JSON.stringify(args)} ---`);\n\n    // --- Guardrail Logic ---\n    const targetToolName = \"get_weather_stateful\"; // Match the function name used by FunctionTool\n    const blockedCity = \"paris\";\n\n    // Check if it's the correct tool and the city argument matches the blocked city\n    if (toolName === targetToolName) {\n        const cityArgument = args.city; // Get the 'city' argument\n        if (cityArgument &amp;&amp; typeof cityArgument === 'string' &amp;&amp; cityArgument.toLowerCase() === blockedCity) {\n            console.log(`--- Callback: Detected blocked city '${cityArgument}'. Blocking tool execution! ---`);\n            // Optionally update state\n            toolContext.state[\"guardrail_tool_block_triggered\"] = true;\n            console.log(`--- Callback: Set state 'guardrail_tool_block_triggered': true ---`);\n\n            // Return a dictionary matching the tool's expected output format for errors\n            // This dictionary becomes the tool's result, skipping the actual tool run.\n            return {\n                status: \"error\",\n                error_message: `Policy restriction: Weather checks for '${cityArgument.charAt(0).toUpperCase() + cityArgument.slice(1)}' are currently disabled by a tool guardrail.`\n            };\n        } else {\n            console.log(`--- Callback: City '${cityArgument}' is allowed for tool '${toolName}'. ---`);\n        }\n    } else {\n        console.log(`--- Callback: Tool '${toolName}' is not the target tool. Allowing. ---`);\n    }\n\n    // If the checks above didn't return a dictionary, allow the tool to execute\n    console.log(`--- Callback: Allowing tool '${toolName}' to proceed. ---`);\n    return undefined; // Returning undefined allows the actual tool function to run\n}\n\nconsole.log(\"\u2705 block_paris_tool_guardrail function defined.\");\n</code></pre> <p>2. Update Root Agent to Use Both Callbacks</p> <p>We redefine the root agent again (<code>weather_agent_v6_tool_guardrail</code>), this time adding the <code>beforeToolCallback</code> parameter alongside the <code>beforeModelCallback</code> from Step 5.</p> <p>Self-Contained Execution Note: Similar to Step 5, ensure all prerequisites (sub-agents, tools, <code>beforeModelCallback</code>) are defined or available in the execution context before defining this agent.</p> <pre><code>// @title 2. Update Root Agent with BOTH Callbacks (Self-Contained)\n\n// --- Ensure Prerequisites are Defined ---\n// (Include or ensure execution of definitions for: Agent, LiteLlm, Runner, ToolContext,\n//  MODEL constants, say_hello, say_goodbye, greeting_agent, farewell_agent,\n//  get_weather_stateful, block_keyword_guardrail, block_paris_tool_guardrail)\n\n// --- Redefine Sub-Agents (Ensures they exist in this context) ---\nlet greeting_agent: LlmAgent | null = null;\ntry {\n    // Use a defined model constant\n    greeting_agent = new LlmAgent({\n        model: MODEL_GEMINI_2_0_FLASH,\n        name: \"greeting_agent\", // Keep original name for consistency\n        instruction: \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n        description: \"Handles simple greetings and hellos using the 'say_hello' tool.\",\n        tools: [say_hello], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Sub-Agent '${greeting_agent.name}' redefined.`);\n} catch (error) {\n    console.error(`\u274c Could not redefine Greeting agent. Check Model/API Key (${greeting_agent?.model}). Error: ${error}`);\n}\n\nfarewell_agent = null;\ntry {\n    // Use a defined model constant\n    farewell_agent = new LlmAgent({\n        model: MODEL_GEMINI_2_0_FLASH,\n        name: \"farewell_agent\", // Keep original name\n        instruction: \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n        description: \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n        tools: [say_goodbye], // Use the FunctionTool wrapper\n    });\n    console.log(`\u2705 Sub-Agent '${farewell_agent.name}' redefined.`);\n} catch (error) {\n    console.error(`\u274c Could not redefine Farewell agent. Check Model/API Key (${farewell_agent?.model}). Error: ${error}`);\n}\n\n// --- Define the Root Agent with Both Callbacks ---\nlet rootAgentToolGuardrail: LlmAgent | null = null;\nlet runnerRootToolGuardrail: Runner | null = null;\n\nif ('greeting_agent' in globalThis &amp;&amp; greeting_agent &amp;&amp;\n    'farewell_agent' in globalThis &amp;&amp; farewell_agent &amp;&amp;\n    'get_weather_stateful' in globalThis &amp;&amp;\n    'block_keyword_guardrail' in globalThis &amp;&amp;\n    'block_paris_tool_guardrail' in globalThis) {\n\n    const rootAgentModel = MODEL_GEMINI_2_0_FLASH;\n\n    // Create a FunctionTool wrapper for the stateful weather function\n    const weatherStatefulTool = new FunctionTool({\n        name: 'get_weather_stateful',\n        description: 'Gets the current weather for a specific location, using unit preferences from state.',\n        fn: get_weather_stateful,\n        functionDeclaration: {\n            name: 'get_weather_stateful',\n            description: 'Gets the current weather for a specific location, using unit preferences from state.',\n            parameters: {\n                type: 'object',\n                properties: {\n                    city: {\n                        type: 'string',\n                        description: 'The city, address, or general location to get weather for.',\n                    }\n                },\n                required: ['city']\n            }\n        }\n    });\n\n    root_agent_tool_guardrail = new LlmAgent({\n        name: \"weather_agent_v6_tool_guardrail\", // New version name\n        model: root_agent_model,\n        description: \"Main agent: Handles weather, delegates, includes input AND tool guardrails.\",\n        instruction: \"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n                   + \"Delegate greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n                   + \"Handle only weather, greetings, and farewells.\",\n        tools: [weatherStatefulTool],\n        subAgents: [greeting_agent, farewell_agent],\n        outputKey: \"last_weather_report\",\n        beforeModelCallback: block_keyword_guardrail, // Keep model guardrail\n        beforeToolCallback: block_paris_tool_guardrail // Add tool guardrail\n    });\n    console.log(`\u2705 Root Agent '${root_agent_tool_guardrail.name}' created with BOTH callbacks.`);\n\n    // --- Create Runner, Using SAME Stateful Session Service ---\n    if ('session_service_stateful' in globalThis) {\n        runner_root_tool_guardrail = new Runner({\n            agent: root_agent_tool_guardrail,\n            appName: APP_NAME, // Use consistent APP_NAME\n            sessionService: session_service_stateful // Use the service from Step 4/5\n        });\n        console.log(`\u2705 Runner created for tool guardrail agent '${runner_root_tool_guardrail.agent.name}', using stateful session service.`);\n    } else {\n        console.error(\"\u274c Cannot create runner. 'session_service_stateful' from Step 4/5 is missing.\");\n    }\n\n} else {\n    console.error(\"\u274c Cannot create root agent with tool guardrail. Prerequisites missing.\");\n}\n</code></pre> <p>3. Interact to Test the Tool Guardrail</p> <p>Let's test the interaction flow, again using the same stateful session (<code>SESSION_ID_STATEFUL</code>) from the previous steps.</p> <ol> <li>Request weather for \"New York\": Passes both callbacks, tool executes (using Fahrenheit preference from state).  </li> <li>Request weather for \"Paris\": Passes <code>beforeModelCallback</code>. LLM decides to call <code>get_weather_stateful(city='Paris')</code>. <code>beforeToolCallback</code> intercepts, blocks the tool, and returns the error dictionary. Agent relays this error.  </li> <li>Request weather for \"London\": Passes both callbacks, tool executes normally.</li> </ol> <pre><code>// @title 3. Interact to Test the Tool Argument Guardrail\n\n// Ensure the runner for the tool guardrail agent is available\nif ('rootAgentToolGuardrail' in globalThis &amp;&amp; runnerRootToolGuardrail) {\n    // Define the main async function for the tool guardrail test conversation.\n    // The 'await' keywords INSIDE this function are necessary for async operations.\n    async function runToolGuardrailTest() {\n        console.log(\"\\n--- Testing Tool Argument Guardrail ('Paris' blocked) ---\");\n\n        // Use the runner for the agent with both callbacks and the existing stateful session\n        // Define a helper lambda for cleaner interaction calls\n        const interactionFunc = (query: string) =&gt; call_agent_async(query,\n                                                                 runnerRootToolGuardrail,\n                                                                 USER_ID_STATEFUL, // Use existing user ID\n                                                                 SESSION_ID_STATEFUL // Use existing session ID\n                                                                );\n        // 1. Allowed city (Should pass both callbacks, use Fahrenheit state)\n        console.log(\"--- Turn 1: Requesting weather in New York (expect allowed) ---\");\n        await interactionFunc(\"What's the weather in New York?\");\n\n        // 2. Blocked city (Should pass model callback, but be blocked by tool callback)\n        console.log(\"\\n--- Turn 2: Requesting weather in Paris (expect blocked by tool guardrail) ---\");\n        await interactionFunc(\"How about Paris?\"); // Tool callback should intercept this\n\n        // 3. Another allowed city (Should work normally again)\n        console.log(\"\\n--- Turn 3: Requesting weather in London (expect allowed) ---\");\n        await interactionFunc(\"Tell me the weather in London.\");\n    }\n\n    // --- Execute the `runToolGuardrailTest` async function ---\n    // Choose ONE of the methods below based on your environment.\n\n    // METHOD 1: Direct Promise handling (Default for Node.js/TypeScript)\n    console.log(\"Executing runToolGuardrailTest using Promise...\");\n    runToolGuardrailTest().then(() =&gt; {\n        console.log(\"Tool guardrail test conversation completed successfully\");\n    }).catch(error =&gt; {\n        console.error(`An error occurred: ${error}`);\n    });\n\n    // METHOD 2: For Standard Node.js Scripts (.ts)\n    // If running this code as a standard Node.js script from your terminal\n    // To use this method:\n    // 1. Comment out the Promise-based execution above\n    // 2. Uncomment the following block:\n    /**\n    if (require.main === module) {\n        console.log(\"Executing runToolGuardrailTest as main module...\");\n        runToolGuardrailTest().then(() =&gt; {\n            console.log(\"Tool guardrail test conversation completed successfully\");\n        }).catch(error =&gt; {\n            console.error(`An error occurred: ${error}`);\n        });\n    }\n    */\n\n    // --- Inspect final session state after the conversation ---\n    // This block runs after either execution method completes.\n    // Optional: Check state for the tool block trigger flag\n    console.log(\"\\n--- Inspecting Final Session State (After Tool Guardrail Test) ---\");\n    // Use the session service instance associated with this stateful session\n    session_service_stateful.getSession(APP_NAME, USER_ID_STATEFUL, SESSION_ID_STATEFUL).then(final_session =&gt; {\n        // Use .get() for safer access\n        console.log(`Tool Guardrail Triggered Flag: ${final_session.state.get('guardrail_tool_block_triggered', 'Not Set (or False)')}`)\n        console.log(`Last Weather Report: ${final_session.state.get('last_weather_report', 'Not Set')}`); // Should be London weather if successful\n        console.log(`Temperature Unit: ${final_session.state.get('user_preference_temperature_unit', 'Not Set')}`); // Should be Fahrenheit\n        // console.log(`Full State Dict: ${JSON.stringify(final_session.state)}`); // For detailed view\n    }).catch(error =&gt; {\n        console.error(`\\n\u274c Error: Could not retrieve final session state. Error: ${error}`);\n    });\n\n} else {\n    console.warn(\"\\n\u26a0\ufe0f Skipping tool guardrail test. Runner ('runnerRootToolGuardrail') is not available.\");\n}\n</code></pre> <p>Analyze the output:</p> <ol> <li>New York: The <code>beforeModelCallback</code> allows the request. The LLM requests <code>get_weather_stateful</code>. The <code>beforeToolCallback</code> runs, inspects the args (<code>{'city': 'New York'}</code>), sees it's not \"Paris\", prints \"Allowing tool...\" and returns <code>None</code>. The actual <code>get_weather_stateful</code> function executes, reads \"Fahrenheit\" from state, and returns the weather report. The agent relays this, and it gets saved via <code>output_key</code>.  </li> <li>Paris: The <code>beforeModelCallback</code> allows the request. The LLM requests <code>get_weather_stateful(city='Paris')</code>. The <code>beforeToolCallback</code> runs, inspects the args, detects \"Paris\", prints \"Blocking tool execution!\", sets the state flag, and returns the error dictionary <code>{'status': 'error', 'error_message': 'Policy restriction...'}</code>. The actual <code>get_weather_stateful</code> function is never executed. The agent receives the error dictionary as if it were the tool's output and formulates a response based on that error message.  </li> <li>London: Behaves like New York, passing both callbacks and executing the tool successfully. The new London weather report overwrites the <code>last_weather_report</code> in the state.</li> </ol> <p>You've now added a crucial safety layer controlling not just what reaches the LLM, but also how the agent's tools can be used based on the specific arguments generated by the LLM. Callbacks like <code>beforeModelCallback</code> and <code>beforeToolCallback</code> are essential for building robust, safe, and policy-compliant agent applications.</p>"},{"location":"tutorials/agent-team/#conclusion-your-agent-team-is-ready","title":"Conclusion: Your Agent Team is Ready!","text":"<p>Congratulations! You've successfully journeyed from building a single, basic weather agent to constructing a sophisticated, multi-agent team using the Agent Development Kit (ADK).</p> <p>Let's recap what you've accomplished:</p> <ul> <li>You started with a fundamental agent equipped with a single tool (<code>get_weather</code>).</li> <li>You explored ADK's multi-model flexibility using LiteLLM, running the same core logic with different LLMs like Gemini, GPT-4o, and Claude.</li> <li>You embraced modularity by creating specialized sub-agents (<code>greeting_agent</code>, <code>farewell_agent</code>) and enabling automatic delegation from a root agent.</li> <li>You gave your agents memory using Session State, allowing them to remember user preferences (<code>temperature_unit</code>) and past interactions (<code>output_key</code>).</li> <li>You implemented crucial safety guardrails using both <code>beforeModelCallback</code> (blocking specific input keywords) and <code>beforeToolCallback</code> (blocking tool execution based on arguments like the city \"Paris\").</li> </ul> <p>Through building this progressive Weather Bot team, you've gained hands-on experience with core ADK concepts essential for developing complex, intelligent applications.</p> <p>Key Takeaways:</p> <ul> <li>Agents &amp; Tools: The fundamental building blocks for defining capabilities and reasoning. Clear instructions and docstrings are paramount.</li> <li>Runners &amp; Session Services: The engine and memory management system that orchestrate agent execution and maintain conversational context.</li> <li>Delegation: Designing multi-agent teams allows for specialization, modularity, and better management of complex tasks. Agent <code>description</code> is key for auto-flow.</li> <li>Session State (<code>ToolContext</code>, <code>output_key</code>): Essential for creating context-aware, personalized, and multi-turn conversational agents.</li> <li>Callbacks (<code>beforeModel</code>, <code>beforeTool</code>): Powerful hooks for implementing safety, validation, policy enforcement, and dynamic modifications before critical operations (LLM calls or tool execution).</li> <li>Flexibility (<code>LiteLlm</code>): ADK empowers you to choose the best LLM for the job, balancing performance, cost, and features.</li> </ul> <p>Where to Go Next?</p> <p>Your Weather Bot team is a great starting point. Here are some ideas to further explore ADK and enhance your application:</p> <ol> <li>Real Weather API: Replace the <code>mock_weather_db</code> in your <code>get_weather</code> tool with a call to a real weather API (like OpenWeatherMap, WeatherAPI).</li> <li>More Complex State: Store more user preferences (e.g., preferred location, notification settings) or conversation summaries in the session state.</li> <li>Refine Delegation: Experiment with different root agent instructions or sub-agent descriptions to fine-tune the delegation logic. Could you add a \"forecast\" agent?</li> <li>Advanced Callbacks:<ul> <li>Use <code>afterModelCallback</code> to potentially reformat or sanitize the LLM's response after it's generated.</li> <li>Use <code>afterToolCallback</code> to process or log the results returned by a tool.</li> <li>Implement <code>beforeAgentCallback</code> or <code>afterAgentCallback</code> for agent-level entry/exit logic.</li> </ul> </li> <li>Error Handling: Improve how the agent handles tool errors or unexpected API responses. Maybe add retry logic within a tool.</li> <li>Persistent Session Storage: Explore alternatives to <code>InMemorySessionService</code> for storing session state persistently (e.g., using databases like Firestore or Cloud SQL \u2013 requires custom implementation or future ADK integrations).</li> <li>Streaming UI: Integrate your agent team with a web framework (like FastAPI, as shown in the ADK Streaming Quickstart) to create a real-time chat interface.</li> </ol> <p>The Agent Development Kit provides a robust foundation for building sophisticated LLM-powered applications. By mastering the concepts covered in this tutorial \u2013 tools, state, delegation, and callbacks \u2013 you are well-equipped to tackle increasingly complex agentic systems.</p> <p>Happy building!</p>"}]}